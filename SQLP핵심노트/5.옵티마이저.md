# SQL 옵티마이저

1. 옵티마이징 원리

규칙기반 옵티마이저는 미리 정해놓은 우선순위 규칙에 따라 액세스 경로를 평가한다.
비용기반 옵티마이저는 미리 수집해 둔 통계정보를 이용해 액세스 경로를 평가한다.
규칙기반 옵티마이저는 통계정보를 활용하지않는다.
비용기반 옵티마이저도 내부적으로 규칙을 사용한다.

---

비용기반 옵티마이저는 사용자 쿼리를 위해 후보군이 될만한 실행계획들을 도출하고,
데이터 딕셔너리에 미리 수집해 둔 통계정보를 이용해 각 실행계획의 예상비용을 산정하고,
그 중 가장 낮은 비용의 실행계획 하나를 선택하는 옵티마이저다.
비용기반 옵티마이저(cbo)가 사용하는 통계정보로는 데이터양, 컬럼 값의 수, 컬럼 값 분포, 인덱스 높이, 클러스터링 팩터 등이 있다.

비용기반 옵티마이저도 규칙을 갖고 있다. 예를 들어, 어떤 인덱스를 사용하든 비용이 동일 하다면 알파벳 순으로 인덱스를 선택한다.
옵티마이저 모드가 first_rows인 경우, order by 컬럼에 인덱스가 있으면 인덱스를 사용한다.
규칙기반 옵티마이저는 통계정보를 전혀 활용하지 않고 단순한 규칙에만 의존한다.

2. 규칙기반 옵티마이저

\- 캐싱 효과를 고려하지 않는다, 즉, 모든 블록을 디스크에서 읽는다고 가정한다.

이는 오라클 비용기반 옵티마이저의 한계를 설명한 것이다.
실행계획에 표시되는 COST는 예상 디스크 I/O call 횟수를 의미한다. 캐싱효과를 고려하지 않고 디스크 I/O call 횟수로 실행계획을 선택하는 것이다.
최근 방식인 cpu 비용 모델에서는 예상 I/O 발생량을 디스크에서 단일 블록으로 읽을 때의 시간으로 환산한 cost를 사용하므로 이 역시 캐싱 효과를 고려하지 않고 있다.
참고로, optimizer_index_caching 파라미터를 통해 일부 캐싱 효과를 고려하도록 설정할 수 있다.

\- 조걸절에 인덱스가 있으면 무조건 인덱스를 사용한다.

규칙기반 옵티마이저에서 FULL TABLE SCAN은 순위가 15위로 가장 낮기 때문에 무조건 인덱스를 사용한다.
고객유형 조건을 만족하는 고객이 전체에서 90%를 차지한다면 무조건 인덱스를 사용하는건 좋은 선택이 아니다.

\- order by 절에 인덱스가 있으면 무조건 인덱스를 사용해 소트 연산을 생략한다.

인덱스 컬럼에 대한 order by는 full table scan 순위보다 한 단계 더 높기 때문에 무조건 인덱스를 사용한다.
부분범위처리가 가능한 상황에서 인덱스를 이용해 소트 연산을 생략한다면 성능을 높이는 데 도움이 되지만, 그러지 못한 상황에서
인덱스로 전체 레코드를 엑세스하는 것은 좋은 선택이 아니다.

\- 부등화 조건절과 between 조건절 모두에 인덱스가 있으면 between 조건절의 인덱스르 사용한다.

인덱스 컬럼에 대한 Between 조건이 부등호 조건보다 높기때문에 연본 인덱스르 사용한다. between 은 닫힌 범위검색 조건이고, 부등호는 열린 범위검색 조건이므로
between이 더 유리하다는 규칙은 타당하다. 하지만 조건에 해당하는 데이터 수에 따라 이는 틀린 가정이 될 수 있다.

3. 비용기반 옵티마이저

옵티마이저가 최적화를 수행할 때 세부적으로 아래 3개의 서브 엔진을 사용한다.

\- query transformer

사용자로부터 전달받은 Sql을 그대로 최적화하지 않고 우선 최적화에 유리한 형태로 변환을 시도한다.

\- estimator

쿼리 오퍼레이션 각 단계의 선택도, 카디널리티, 비용을 곗간하고, 궁극적으로 실행계획 전체에 대한 총 비용을 계산한다.

\- plan generator

하나의 쿼리를 수행하는데 있어, 후보군이 될만한 실행계획들을 생성해 낸다.

옵티마이저는 가장 비용이 적게드는 액세스 경롤를 선택한다. 그런데 사용자가 특정 인덱스를 특정 스캔방식으로 사용하도록 힌트를 지정했다면 옵티마이저는 비용이 더 높음에도 그 경로를 선택한다.
그렇지 않고 사용자가 지시한 경로와 스스로 선택한 경로의 비용을 비교해 최종 하나를 선택한다면, 비용이 낮은 경로가 선택된다.
옵티마이저가 실제로 이렇게 작동한다면 사용자가 지정한 경로를 옵티마이저가 미리 생각해 내지 못한 경우가 아닌이상, 사용자 힌트는 항상 무시될 것이다.
옵티마이저에 영향을 미치는 요소가 여러가지 있지만, 힌트는 그중에서 가장 강력한 영향을 미치는 요소이다. 힌트는 옵션이 아니라 명령어이다. 몇몇 예외적인 경우가 아니면, 옵티마이저는 힌트를 그대로 따른다.

4. 옵티마이저 힌트

옵티마이저 힌트가 무시되는 경우는 아래와 같다.

\- 문법적으로 맞지 않게 힌트 기술
\- 잘못된 참조 사용
\- 논리적으로 불가능한 액세스 경로
\- 의미적으로 맞지 않게 힌트 기술
\- 옵티마이저에 의해 내부적으로 쿼리벼ㅓㄴ환
\- 버그

사용자가 정확한 힌트를 제공하면 옵티마이저는 성능에 상관없이 그대로 따른다.

5. self-learning optimizer

'bind viariable peeking'은 sql이 첫 번째 수행될 때 함께 딸려 온 바인드 변수 값을 훔쳐보고,
그 값에 대한 컬럼 분포를 잉요해 실행계획을 결정하는 기능이다.
이는 바인드 변수를 사용하면 히스토그램 정보를 활용하지 못하는 제약을 극복하기 위한 기능에 불과하며, 스스로 학습하는 옵티마이저 기능과는 거리가 멀다.

'adaptive cujrsor sgharing' 은 처음 실행 시 특정 실행계획으로 실행했다가 바인드 변수에 다른 값이 입력됐을 때 예상보다 많은 아이오가 발생하면 다른 실행계획을
추가적으로 생성하고, 바인드 변수 값 분포에 따라 다른 실행계획을 선택적으로 사용하는 기능이다.

'cardinality feedback(statistics feedback)' 은 최초 실행계획을 수립할 때 추정했던 카디널리티와 실제 실행 과정에 읽은 로우 수 간에 차이가 크다고 판단되면, 조정된 카디널리티 값을 어딘가에 저장해 두었다가 다음 번 실행 시에 그것을 사용함으로써 다른 실행계획이 수립되도록 하는 기능이다.

'ADAPTIVE PLANS' 는 런타임에 실행계획을 변경하는 기능들을 포함한다.
예를 들어 통계정보 상 a와 b가 둘 다 작은 집합이라고 판단해서 옵티마이저가 nl 조인을 선택했는데, 실제 실행 과정에 먼저 읽은 a집합에서 예상보다 많은 로우가 반환되면 해시 방식으로 조인 메서드를 변경한다.

6. 비용기반 옵티마이저

옵티마이저가 사용하는 통계정보로는 크게 오브젝트 통계와 시스템 통계가 있다.

오브젝트 통계로는
\- 테이블 통계 (레코드 수, 블록 수, 평균 행 길이 등)
\- 인덱스 통계 (인덱스 높이, 리프 블록 개수, 클러스터링 팩터)
\- 컬럼 통계 (중복을 제거한 컬럼 값의 수, 최소값, 최대값, null 값 개수, 히스토그램 등)

시스템 통계로는
cpu 속도, SIngle block I/o 속도, multiblock i/o 속도, 평균적인 multiblock i/o 개수 등을 관리한다.

오라클 11g에서 도입된 Adaptive Direct Path Read 기능이 Direct path read를 사용할지 여부를 결정할 때 고려하는 항목 중 하나가 버퍼캐시 크기다.
하지만, 이는 실행계획 수립 할 때가 아니라 런타임 시 고려사항이다.

7. 부분범위처리

최초 응답속도 최적화가 효과적인 애플리케이션 아키텍처는 주로 2-tier 환경의 클라이언트 / 서버 구조다.
전체 결과집합이 아무리 많아도 사용자가 스크롤을 통해 일부만 FETCH 하다 멈출 수 있다.
결과집합을 끝까지 FETCH 하거나 다른 쿼리를 수행하기 전까지 SQL 커서는 오픈된 상태를 유지한다.

반면, OLTP성 애플리케이션이더라도 3-tier 구조는 클라이언트와 서버 간 연결을 지속하지 않는 환경이므로 오픈 커서를 계속 유지할 수 없어 일반적으로 페이징 처리 기법을 사용한다.

이를 위해 rownum을 이용해 결과집합을 10건 내지 20건으로 제한하느 쿼리를 사용한다. 대량 데이터 중 일부만 fetch 하고 멈추는 것이아니라 집합 자체를 소량으로 정의해 모두 fetch 한다면, 전체 처리속도 최적화가 더 적절한 설정이다.

결론적으로 oltp성 애플리케이션이더라도 아키텍처에 따라 최적화 목표는 다를 수 있다.

전체처리속도 최적화(ALL_ROWS) 는 쿼리 결과집합 전체를 읽는것을 전제로 시스템 리소스를 가장 적게 사용하는 실행계획을 선택한다.

최초 응답속도 최적화(FIRST_ROWS, FIRST_ROWS_N)은 전체 결과 집합 중 앞쪽 일부만 읽다가 멈추는 것을 전제로 응답속도가 가장 빠른 실행계획을 선택한다.

FIRST_ROWS는 ALL_ROWS에 비해 인덱스를 더 많이 선택하고, 해시조인보다 nl 조인을 더 많이 선택하는 경향을 보인다.

8. 옵티마이저 행동

아래와 같은 요소들이 옵티마이저 행동, 즉 쿼리 성능에 영향을 미친다.

\- 옵티마이징 팩터 : 인덱스, IOT, 클러스터링, 파티셔닝 등 오브젝트 구성
\- DBMS 제약 설정 : PK, FK, CHECK, NOTNULL 등
\- 통계정보
\- 옵티마이저 힌트
\- 옵티마이저 관련 파라미터

네트워크 속도는 옵티마이저 실행계획 생성에 영향을 주지 않는다.

9. 최적 실행계획 생성의 한계

옵티마이저가 항상 최적의 실행계획을 생성하지 못하는 데는 아래와 같은 이유가 있다.

\- 부족한 옵티마이징 팩터 : 인덱스, IoT, 클러스터링, 파티셔닝 등 오브젝트 구성
\- 부정확한 통계 : 정보 수집 및 보관 비용측면의 한계
\- 결합 선택도 산정의 어려움
\- 바인드 변수 사용 시, 히스토그램 사용에 제약
\- 비현실적인 가정과 규칙에 의존
\- 최적화 시간에 허용된 시간 제약

일반적으로 사용하는 온라인 옵티마이저는 정해진 시간 내에 빠르게 최적화를 수행해야 하기 때문에 정보를 충분히 활용하지 못한다.
오라클의 경우 튜닝 모드에서 오프라인 옵티마이저를 구동하면, 시간 졔약 없이 다이나믹 샘플링을 포함한 다양한 정보와 기법을 활용하므로 훨씬 더 완벽한 실행계획을 생성해낸다.

라이브러리 캐시공간의 크기는 옵티마이저가 생성하는 실행계획에 영향을 주지 않는다.
다만 공간이 부족하면 SQL 실행계획이 캐시에서 자주 밀려나므로 파싱과 최적화를 자주 수행함으로 인한 부하가 늘어난다.

10. 선택도 & 카디널리티

선택도란, 전체 레코드 중에서 조건절에 의해 선택되는 레코드 비율을 말한다.
연산자 종류에 따라 선택도를 구하는 방식이 다른데, 가장 단순한 = 조건을 검색하는 경우에

선택도는 '1 / 조건절 컬럼 값의 종류 개수' 를 의미한다

카디널리티란, 전체 레코드 중에서 조건절에 의해 선택되는 레코드 개수이다.

cardinality = 총 로우 수 \* 선택도(selectivity) = 총 로우수 / NDV

```sql
-- 데이터
-- 상품 테이블 총 건수 = 100000
-- 상품분류 = {가전, 의류, 식음료, 생활용품}

select *
from 상품
where 상품분류 = :prd_cls;

```

위 sql 조건절에 의한 선택도(selectivity) 는 0.25 이고
카디널리티는 25000 이다.

11. 선택도 & 카디널리티

```SQL
-- 데이터
-- 사원 테이블 총 건수 = 10,000
-- 직급으로는 부장,과장,대리,사원이 있으며, 히스토그램 상 각각 25% 점유율을 가진다.
-- 히스토그램 상 연봉이 5000 이상인 사원은 10%

select 사원번호, 사원명, 부서번호, 연봉
from 사원
where 직급 = '부장'
and 연봉 >= 5000;
```

선택도

직급 조건 선택도 _ 연봉 조건 선택도 = 0.25 _ 0.1 = 0.025

카디널리티 = 10000 \* 0.025 = 250

12. 컬럼 통계 항목

오라클이 수집하는 컬럼 통계 항목들이다.

\- 중복을 제거한 컬럼 값의 수
\- 최소값
\- 최대값
\- 밀도
\- 평균컬럼길이
\- Null값을 가진 레코드 수

커럼 통계 수집 시 평균 컬럼 길이는 측정하지만, 최소 컬럼 길이와 최대 컬럼 길이는 측정하지 않는다.

13. 시스템 통계

시스템 통계는 애플리케이션 및 하드웨어 성능 특성을 측정한 것이면, 아래 항목들을 포함한다

\- cpu 속도
\- 평균적인 single block i/o 속도
\- 평균적인 multiblock i/o 속도
\- 평균적인 multiblock i/o 개수
\- i/o 서브시스템의 최대 처리량
\- 병렬 slave의 평균적인 처리량

평균적인 Single block i/o 개수는 당연히 1이므로 수집하지 않느다.

MULTIBLOCK I/O 단위를 128로 설정하더라도 실제 평균적인 MULTIBLOCK I/O 개수는 128 미만이 된다.
FULL SCAN 할때 읽어야 할 익스텐트 개수, 익스텐트 크기, 버퍼캐시 히트율에 따라 달라지기 때문이다.

따라서 오라클은 이를 full scan 비용 계산 시 활용하기 위해 별도 시스템 통게항목으로 측정해둔다.

14. 비용 모델

I/O 비용 모델의 비용은 예상되는 디스크 i/O CALL 횟수를 의미한다. 예를 들어, 실행계획 상 COST가 100으로 표시됐다면,
쿼리 수행 과정에 I/O CALL이 100번 발생할 것으로 옵티마이저가 에상한다는 뜻이다.

CPU 비용 모둘에서는 예상 I/O 시간과 예상 CPU 사용시간을 구한 후 SINGLE BLOCK i/o 시간으로 나눈 값을 비용 값으로 사용한다.

즉, 비용을 single block i/o가 소요되는 시간과의 상대적인 시간 비용으로 표현한 것이다.

실행계획상 100으로 포ㅛ시됐다면 '시스템에서 100번 single block i/o하는 정도의 시간이 소요될 것으로 옵티마이저가 예상한다.' 는 뜻이다.

---

I/O 비용 모델의 비용은 예상되는 블록 개수가 아니라 디스크 i/o call 횟수다. single block i/o일 때는 i/o Call 횟수가 읽은 블록 수와 일치하겠지만,
multiblock i/o일때는 읽은 블록 수를 multiblock i/o 단위로 나눈 만큼의 i/o Call이 발생한다.

15. 히스토그램 유형

오라클 12 이상 버전에서 사용하는 히스토그램 유형으로는 아래 4가지가 있다.

\- 도수분포 : 값별로 빈도수 저장
\- 높이균현 : 각 버킷의 높이가 동일하도록 데이터 분포 관리
\- 상위도수분포 : 많은 레코드를 가진 상위 N개 값의 빈도수 저장
\- 하이브리드 : 도수분포와 높이균형 히스토그램의 특성을 결합

16. 인덱스를 이용한 테이블 액세스 비용

비용 = 브랜치 레벨 \+ (리프 블록 수 \* 유효 인덱스 선택도) \+ (클러스터링 팩터 \* 유효 테이블 선택도)

'유효 인덱스 선택도' 는 인덱스 총 레코드 중에서 조건절을 만족할 것으로 예상되는 레코드 비율을 의미한다.
'유효 테이블 선택도' 는 저체 인덱스 레코드 중에서 인덱스 스캔을 완료하고서 테이블을 방문할 것으로 예상되는 레코드 비율을 의미한다.

브랜치 블록 수는 비용 공식에 포함되지 않을 뿐아니라 통계정보로 수집하지도 않는다.

# SQL 공유 및 재사용

17. 라이브러리 캐싱

사용자가 SQL문을 전달하면 DBMS는 SQL을 파싱한 후 해당 SQL이 라이브러리 캐시에 존재하는지 부터 확인한다.
캐시에서 찾으면 곧바로 실행 단계로 넘어가지만, 찾지 못하면 최적화 단계를 거친다.
SQL을 캐시에서 찾아 곧바로 실행단계로 넘어가는 것을 소프트파싱이라 하고, 차즌ㄴ데 실패해 최적화 및 로우 소스 생성 단계까지
모두 거치는 것을 하드 파싱이라고 한다.

\- 소프트 파싱 : SQL과 실행계획을 캐시에서 찾아 곧바로 실행하는 경우
\- 하드 파싱 : SQL과 실행계획을 캐시에서 찾지 못해 최적화 및 로우 소스 생성 과정을 모두 거쳐서 실행하는 경우

18. SQL최적화 과장

옵티마이저가 SQL을 최적화할 때도 데이터베이스 사용자들이 보통 생각하는 것보다 훨씬 많은 일을 수행한다.

\- 테이블 구성, 인덱스 구성, 컬럼 구성에 관한 정보를 조회한다.

\- 옵티마이저 관련 파라미터를 참조한다.

\- 조인순서, 조인 메서드, 테이블 액세스 방식, 인덱스 스캔 방식, 사용 인덱스 등을 결정한다.

SQL을 최적화하는 동안 옵티마이저는 엄청나게 많은 연산을 수행하며, 그 과정에 사용하는 정보는 다음과 같다.

\- 테이블, 컬럼, 인덱스 구성에 관한 기본 정보
\- 오브젝트 통계 : 테이블 통계, 인덱스 통계, 컬럼 통계
\- 시스템 통계 : cpu 속도, single block i/o 속도 , multiblock i/o 속도
\- 옵티마이저 관련 파라미터

하나의 쿼리를 수행하는 데 있어 후보군이 될만한 무수히 많은 실행결로를 도출하고, 딕셔너리와 통계정보를 읽어
각각에 대한 효율성을 판단해야 하므로 하드 파싱 과정에 많은 cpu 자원을 사용한다.

테이블 통계, 인덱스 통계, 컬럼 통계는 하드 파싱 과정에 수집하는 것이 아니라, dba가 설정한 주기에 따라 미리 수집해 둔다.
물론, 다이나믹 샘풀링이 필요한 상황이면 하드 파싱 과정에 통계정보를 수집하기도 하지만, 이를 딕셔너리에 저장하지는 않는다.

19. 공유 가능 SQL

사용자 정의 함수/프로시저, 트리거, 패키지 등은 생성할 때부터 이름을 갖는다.
컴파일한 상태로 딕셔너리에 저장되며, 사용자가 삭제하지 않는 한 영구적으로 보관된다.
실행할 때 라이브러리 캐시에 적재함으로써 여러 사용자가 공유하면서 재상요한다.
반면 SQL은 이름이 따로 없다. 전체 SQL 텍스트가 이름 역할을 한다. 딕셔너리에 저장하지도 않는다.
처음 실행할 때 최적화 과정을 거쳐 동적으로 생성한 내부 프로시저를 라이브러리 캐시에 적재함으로써
여러 사용자가 공유하면서 재사용한다. 캐시 공간이 부족하면 버려졌다가 다음에 다시 실행할 때 똑같은 최적화 과정을 거쳐 캐싱 ㅔ적재한다.
의미가 100% 같더라도 텍스트 중 일부가 다르면, 각각 최적화를 진행하고 라이브러리 캐시에도 별도 공간을 사용한다.

20. 바인드 변수

\- 바인드 변수를 사용하면 한 SQL에 다른 값을 입력하면서 반복 재사용할 수 있다.
\- 바인드 변수를 사용하면 한 SQL에 대한 실행계획을 여러 프로세스가 사용할 수 있다.
\- 바인드 변수를 사용하면 최적화 과정에 컬럼 히스토그램을 사용하지 못한다.

조건절에 상수 값을 사용하면 컬럼 히스토그램을 사용할 수 있어 SQL 최적화에 도움이된다.
반면 , 바인드 변수를 사용하면 컬럼 히스토그램을 사용하지 못하므로 상수 값을 사용할 때보다 다소 안 좋은 실행계획을 수립할 가능성이 있다.

21. 라이브러리 캐시 최적화 방안

커서를 공유할 수 있는 형태로 SQL을 작성한다.
세션 커서 캐싱 기능을 활용한다.
애플리케이션 커서 캐싱 기능을 활용한다.
open_cursors 파라미터를 낮게 설정한다.

---

open_cursors 파라미터는 세션 당 open 할 수 있는 커서의 개수를 제한하는 파라미터이다.

22. 커서

공유 커서는 라이브러리 캐시에 공유된 shared sql area를 말한다.

세션 커서는 pga에 할당된 private sql area를 말한다.

애플리케이션 커서는 세션 커서를 제어하는 클라이언트 측 핸들로서 라이브러리에서 sql을 찾는 작업을 생략하고 반복 수행할 수 있는 커서를 말한다.

명시적 커서는 DECLARE 문으로 SQL 문을 정의하고, 커서의 oipen, fetch, close 를 명시적으로 처리하는 개발 패턴을 말한다.

묵시적 커서는 declare 문을 생략하고, 커서의 open, fetch, close도 dbms가 자동으로 처리하는 개발 패턴을 말한다.

23. 파서 캐싱

\- misses in library cache during parse 를 통해 최초 1회 하드 파싱이 일어난 사실을 알 수 있다.
\- 바인드 변수를 사용하면 커서를 공유할 수 있으므로 하드 파싱이 한번만 일어난다. 하지만 상수 조건으로 반복 실행해도 커서를 공유할 수 있으므로
트레이스 결과만드로 바인드 변수 사용 여부를 알 수 없다.
\- 세션 커서 캐싱의 작동 여부는 트레이스 결과로 알 수 없다. v$open_cursor 뷰에서 해당 sql의 cursor_type이 'session cursor cached' 인지를 통해 확인 가능하다.
\- excute call이 5000번 일어낫는디 parse call 이 1회 일어났다면 애플리케이션 커서를 캐싱한 상태에서 반복 실행했음을 알 수 있다.

24. 정적 sql , 동적 sql

'static sql' 이란 STRING 형 변수에 담지 않고 코드 사이에 직접 기술한 sql문을 말한다.

'dynamic sql' 이란 string 형 변수에 담아서 기술하는 sql문을 말한다. strig 변수를 사용하므로 조건에 따라 sql문을 동적으로 변경할 수 있고,
런타임시에 사용자로부터 sql문의 일부 또는 전부를 입력 받아서 실행할 수 있다.

powerbuilder, pl/sql, pro\*c, sqlj 정도를 제외한 나머지 개발 언어에서 수행하는 sql은 모두 dynamic sql이다.

static, dynamic sql은 애플리케이션 개발 측면에서의 구분일 뿐, dbms 입장에서는 차이가 없다.

쿼리툴, java 환경에서 실행된 sql은 모두 동적 sql이다.

25. cursor_sharing

cursor_sharing 파라미터를 force 로 설정하면, sql에 사용한 상수 값을 바인드 변수로 강제 변환해 줌으로써 상수 값만 다른 동일 sql을 반복해서 하드파싱하는 데 따른 부하를 줄여준다.

조건절을 일일이 바인드 변수로 처리하지 않아도 되므로 편리한 기능이라고 생각할 수 있지만, 그로 인한 부작용에 대해서도 정확히 숙지할 필요가 있다. 대표적인 부작용 두 가지는

sql을 실행할 때마다 상수 값을 바인드 변수로 변환하는 과정에 cpu 자원이 소모된다는 점이다.

컬럼 히스토그램이 도움이 되는 상횡에서도 상수 값을 강제 바인드 변수 처리함으로 인해 비효율적인 실행계획이 수립될 수 있고, 이는 i/o 증가 및 성능 저하로 이어질 수 있다.

예상치 못한 현상이 발생할 수도 있는데, 아래 sql 조건절을 위해 함수기반 인덱스를 생성했는데, 포맷 문자열까지 바인드 변수로 반환되는 바람에 인덱스를 사용하지 못하는 문제가 발생할 수 있다.

```sql
create index emp_x1 on emp(to_char(hiredate, 'YYYYMMDD'));

select * from emp e
where to_char(hiredate, 'YYYYMMDD') >= '19870101';

```

일반적인 상황에서 cursor_sharing 파라미터를 force로 설정하는 건 금물이다. 기본값인 exact로 설정했을 때 발생할 수있는 하드파싱 부하를 우려하기보다 정상적인 방법으로 바인드 변수를 처리하는 것이 올바른 접근방법이다.

# 쿼리변환

26. 쿼리 변한
    쿼리 변환은 옵티마이저가 SQL을 분석해 의미적으로 동일하면서도 더 나은 성능이 기대되는 형태로 재작성하는 것을 말한다.
    결과만 보장된다면 무조건 쿼리 변환을 수행하는 것을 휴리스티 쿼리변환이라 한다.
    예상 비용이 낮을 때만 변환된 쿼리를 사용하는 것을 비용기반 쿼리 변환이라고 한다.

쿼리 변환했을 때 항상 더 나은 성능을 보장하는 일부 경우를 제외하고 대부분 비용기반 쿼리변환으로 동작한다. 따라서 변환 전 쿼리에 대한 후보군 실행계획과 변환 후 쿼리에 대한 후보군 실행계획을 비교해서 그중 가장 비용이 낮은것을 선택한다.

27. 서브쿼리 Unnesting

서브쿼리는 하나의 sql 문장 내에서 괄호로 묶은 별도의 쿼리 블록을 말한다.
인라인 뷰, 중첩된 서브쿼리, 스칼라 서브쿼리가 여기에 속한다.

옵티마이저는 커리 블록 단위로 최적화를 수행하므로 서브쿼리를 그대로 두면 최적화 할 수 있는 대안이 줄어든다.

중첩된 서브쿼리를 unnesting 하지 않으면 메인 쿼리를 기준으로 서브쿼리를 반복 실행하는 필터 방식으로 처리할 수 밖에 없다. 이는 NL조인과 같은 방식이므로 대용량 데이터 처리에 매우 불리하다.

다만 내부적으로 서브쿼리 캐싱 기능을 적용하므로 서브쿼리에 리턴할 수 있는 값의 종류 수가 적을 때 성능이 크게 나쁘지 않을 수 있다.

중첩된 서브쿼리를 unnesting하면 조인 순서를 자유롭게 결정할 수 있고, NL 조인뿐 아니라 해시, 소트머지 조인으로도 처리할 수 있어 성능 최적화에 큰 도움이 된다.

```sql
-- 서브쿼리를 unnesting 하지 않으면, 메인 쿼리와 서브쿼리를 각각 최적화 한다.
-- 서브쿼리를 Unnesting 하지 않으면, 고객을 기준으로 거래 테이블과 nl 방식으로 조인한다.
-- 서브쿼리를 unnesting 하지 않으면, 서브쿼리에 대한 캐싱 기능이 작동한다.
select c.고객번호, c.고객명
from 고객 C
where c.가입일시 >= trunc(add_months(sysdate, -1), 'mm')
and exists (
  select 'x'
  from 거래
  where 고객번호 = c.고객벊
  and 거래일시 >= trunc(sysdate, 'mm')
)

```

서브쿼리를 Unnsting 하면 고객을 먼저 드라이빙할 수도 있고, 거래를 먼저 드라이빙할 수도 있다. 고객을 먼저드라이빙하면 결과집합이 M집합인 거래 단위로 변하지 않도록 semi조인 방식으 사용한다.
거래를 먼저 드라이빙하는 경우 sort unique 연산으 통해 고객 단위의 Unique한 집합을 생성한 후 고객 테이블과 조인한다.

28. subquery unnesting

```sql
select c.고객번호, c.고객명
from 고객 C
where c.가입일시 >= trunc(add_months(sysdate, -1), 'mm')
and exists (
  select 'x'
  from 거래
  where 고객번호 = c.고객벊
  and 거래일시 >= trunc(sysdate, 'mm')
)

-- 서브쿼리를 Unnesting 하지않고 고객을 기준으로 Filter 방식으로 조인했을때의 실행계획
-- EXECUTION PLAN
-- SELECT STATEMENT
--  FILTER
--    TABLE ACCESS FULL OF 고객
--    INDEX RANGE SCAN OF 거래_PK

-- 서브쿼리를 Unnesting 한 후 고객을 기준으로 거래 테이블괴 Nl 세미조인했다.
-- EXECUTION PLAN
-- SELECT STATEMENT
--  NESTED LOOPS(SEMI)
--    TABLE ACCESS FULL OF 고객
--    INDEX RANGE SCAN OF 거래_PK

-- 서브쿼리를 Unnesting 한 후 고객 단위 집합으로 가공한 (sort unique) 거래 데이터를 기준으로 고객 테이블과 조인했다.
-- EXECUTION PLAN
-- SELECT STATEMENT
--  NESTED LOOPS
--    SORT UNIQUE
--      TABLE ACCES BY INDEX ROWID OF 거래
--        INDEX RANGE SCAN of 거래_x01
--    TABLE ACCESS BY INDEX ROWID OR 고객
--      INDEX RANGE SCAN OF 고객_x02

```

서브쿼리를 Unnesting 하지 않으면 거래를 먼저 드라이빙할 수 없다. 항상 메인 쿼리의 고객을 기준으로 서브쿼리의 거래 테이블과 Nl 방식으로 조인한다.

29. no_unnest

```sql
select c.고객번호, c.고객명
from 고객 C
where c.가입일시 >= trunc(add_months(sysdate, -1), 'mm')
and exists (
  select /*+uo_unnest*/
  'x'
  from 거래
  where 고객번호 = c.고객벊
  and 거래일시 >= trunc(sysdate, 'mm')
)

-- execution plan
-- select statement
--    filter
--      table access full of 고객
--      index range scan of 거래_Pk
```

서브쿼리를 Unnesting 하지 않았을 때 나타나는 실행계획이다.
서브쿼리를 Unnesting 하지 않으면 메인 쿼리를 기준으로 서브쿼리를 반복실행하는 Filter 방식으로 처리할 수 밖에 없다.

필터 방식을 쉽게 이해하려면, filter 오퍼레이션을 nested loops 로 치환해서 해석하면 된다.

필터는 기본적으로 nl 조인과 같은 방식이라 대용량 데이터 처리에 매우 불리하지만
내부적으로 서브쿼리 캐싱 기능을 적용하므로 서브쿼리에 입력할 수 있는 값의 종류가 적을 때는 성능이 크게 나쁘지 ㅇ낳다.

캐싱 기능을 이용하기 위해 항상 이 방식으로 실행하도록 강제하려면 no_unnest 힌트를 사용하면 된다.

30. unnest

```sql
select c.고객번호, c.고객명
from 고객 C
where c.가입일시 >= trunc(add_months(sysdate, -1), 'mm')
and exists (
  select /*+unnest nl_sj*/
  'x'
  from 거래
  where 고객번호 = c.고객벊
  and 거래일시 >= trunc(sysdate, 'mm')
)

-- execution plan
-- select statement
--    nested loops(semi)
--      table access full of 고객
--      index range scan of 거래_Pk
```

서브쿼리를 unnesting 햇을 때 나타날 수 있는 여러 실행계획 중 하나다.
서브쿼리를 unnesting 하지 않으면 nl 조인처럼 메인쿼리를 기준으로 서브쿼리를 반복 실행하는 필터 방식으로 처리하지만, Unnesting 하면 nl 조인뿐 아니라 해시 조인, 소트머지조인으로도 처리할 수 있다.

조인 순서도 자유롭게 결정할 수 있는데, 문제의 Sql은 고객을 먼저 드라이빙한다.
고객과 거래는 1:M 관계이므로 그대로 조인하면 결과집합이 고객이 아닌 거래 단위의 집합으로 변화한다.

그래서 세미 조인 방식을 사용했다. 이는 outer 테이블의 한 로우가 inner 테이블의 한 로우와 조인에 성공하는 순간 진행을 멈추고, outer 테이블의 다음 로우를 계속 처리하는 방식이다.

이 방식으로 유도하려면, 우선 서브쿼리가 Unnesting 되지 않도록 Unnest 힌트를 사용하고 nl 세미 조인으로 유도하는 nl_sj 힌트를 사용하면 된다.

31. unnest

```sql
select /*+unnest(@subq) leading(거래@subq) use_nl(c)*/
c.고객번호, c.고객명
from 고객 C
where c.가입일시 >= trunc(add_months(sysdate, -1), 'mm')
and exists (
  select /*+qb_name(subq)*/
  'x'
  from 거래
  where 고객번호 = c.고객벊
  and 거래일시 >= trunc(sysdate, 'mm')
)

-- execution plan
-- select statement
--    nested loops
--      sort unique
--        table access by index rowid of 거래
--          index range scan of 거래_x01
--      table access by index rowid of 고객
--        index range scan of 고객_x02
```

서브쿼리를 Unnesting 했을 때 나타날 수 있는 여러 실행계획 중 하나다.
서브쿼리를 Unnesting 하면 nl조인, 해시 조인, 소트머지조인을 자유롭게 선택할 수 있다.
조인 순서도 자유롭게 결정할 수 있는데, 문제의 sql은 서브쿼리 집합인 거래를 먼저 드라이빙했다.

고객과 거래는 1:M 관계이므로 그대로 조인하면 결과집합이 아닌 거래 단위의 집합으로 변한다.
그래서 sort unique 연산을 통해 고객 단위 Unique 한 집합을 생성한 후 고객 테이블과 조인했다.

이 방식으로 유도하려면 우선 서브커리가 Unnesting 되도록 unnest 힌트를 사용해야한다.
그리고 거래 테이블이 드라이빙이 되도록 leading 힌트를 추가하고 use_nl 힌트로 nl 조인을 유도한다.

qb_name 힌트는 쿼리 블록에 이름을 지정할 때 사용한다. 여기서 unnest 힌트의 대상 서브쿼리 블록을 명시하고, 서브쿼리 내에 위치한 거래 테이블을 leading 힌트에서 명확히 참조하기 위해 사용한다.

32. Unnest

```sql
-- 데이터
-- 고객: 100만 건
-- 거래 : 1000만 건

-- 인덱스 구성
-- 고객_pk : 고객번호
-- 거래_pk : 고객번호 + 거래일시

select count(*)
from 고객 c
where c.가입일시 < trunc(add_months(sysdate, -1))
and not exists (
  select 'x'
  from 거래
  where 고객번호 = c.고객번호
  and rownum <= 1
)

-- execution plan
-- select statement
--  flter
--    table access full of 고객
--    count(stopkey)
--      index range scan of 거래_pk

-- 인덱스 추가
-- 고객_idx1 가입일시

select /*+unnest(@subq) leading(거래@subq) use_nl(c) index(c 고객_idx1)*/
count(*)
from 고객 c
where c.가입일시 < trunc(add_months(sysdate, -1))
and not exists (
  select /*+qb_name(subq)*/
  'x'
  from 거래
  where 고객번호 = c.고객번호
  and rownum <= 1
)
```

가입한 지 1개월이 지났는데 거래내역이 없는 고객 수 조회하는 쿼리
100만 고객 중 거의 대부분은 가입 후 1개월이 지났을 것이므로 고객 테이블은 Full scan으로 처리한다.

거래는 1000만 건짜리 대량 테이블이므로 해시 방식을 ㅈ인한다.

튜닝을 위해서는 서브쿼리의 Rownum 조건을 제거해야 한다. unnesting 하지않은 중첩 서브쿼리는 항상 필터 방식으로 처리되므로 해시 조인을 위해서는 unnesting이 필요한데, 서브쿼리에 rownum을 사용하면 Unnesting이 불가능하다.

서브쿼리 Unnesting을 위해 unnest 힌트를 사용한다. NOT EXISTS 서브쿼리이므로
해시 ANTI 조인으로 유도하기 위해 hash_aj 힌트를 사용한다.

마지막으로, 거래 테이블도 full scan 처리해야하는데, 다행히 인덱스만 읽고서도 처리 가능하다.

INDEX FAST FULL SCAN을 할수 있는 조건을 만족하므로 index_ffs 힌트를 추가한다.

INDEX FAST FULL SCAN은 multiblock i/o 방식을 사용하므로 대량 데이터를 읽을 때 일반 인덱스 스캔보다 빠르다.

```sql
select /*+full(c)*/
count(*)
from 고객 c
where c.가입일시 < trunc(add_months(sysdate, -1))
and not exists (
  select /*+unnest hash_aj index_ffs(거래 거래_pk)*/
  'x'
  from 거래
  where 고객번호 = c.고객번호
  and rownum <= 1
)
```

33. no_unnst push_subq

```sql
-- 인덱스
-- 상품분류_pk : 상품분류코드
-- 상품_pk : 상품번호
-- 주문_pk : 고객번호 + 상품번호 + 주문일시
-- 주문_x1 : 상품번호 + 주문일시

select /*+leading(p) use_nl(t)*/
count(distinct p.상품번호), sum(t.주문금액),
sum(t.주문수량), avg(t.할인율)
from 상품 p, 주문 t
where t.상품번호 = p.상품번호
and t.주문일시 >= trunc(sysdate - 7)
and exists (
  select /*+no_unnest push_subq0*/
  'x'
  from 상품분류
  where 상품분류코드 = p.상품분류코드
  and 상위분류코드 = 'AK'
)

-- 0 statement
-- 1 sort aggregate
-- 3000   filter
-- 60000     nested loops
-- 1000       table acccess full 상품
-- 60000       table access by index rowid 주문
-- 60000         index range scan 주문_X1
-- 1     table access by index rowid 상품분류
-- 3       index unique scan 상품분류_pk
```

unnesting 되지 않은 서브쿼리는 항상 필터 방식으로 처리되며, 실행계획 상에서 맨 마지막에 처리된다.
sql에서 상품으로부터 주문 테이블로 1000 번의 조인 액세스가 있었고 조인에 성공한 데이터는 60,000개다.

조인 과정에서 38,097 개의 블록을 읽었다.

60,000 개의 조인 결과집합은 서브쿼리 filter 후 3000개로 줄었다. 총 읽은 블록수는 38,103이다. 대부분의 i/o가 조인에서 발생했다.

만약 서브쿼리 필터링을 먼저 처리함을써, 조인 단계로 넘어가는 로우 수를 크게 줄일 수 있다면 성능은 그만큼 향상된다. 주문 테이블과 조인하기 전에 서브쿼리 필터링을 먼저 처리하도록 push_subq 힌트를 사용한 한후 수집된 트레이스 결과다.

```sql
-- 0       statement
-- 1        sort aggregate
-- 60000     nested loops
-- 150       table acccess full 상품
-- 1             table access by index rowid 상품분류
-- 3               index unique scan 상품분류_pk
-- 3000           table access by index rowid 상품분류
-- 3000             index unique scan 상품분류_pk
```

서브쿼리로 먼저 필터링한 결과가 150건이므로 주문 테이블과 조인 횟수도 150 번으로 줄었고, 주문 데이터도 3000개만 읽었다. 총 읽은 블록 수도 1903으로 줄었다.

pushing 서브쿼리는 이처럼 서브쿼리 필터링을 가능한 한 앞 단계로 처리하도록 강제하느 기능읻.

이 기능은 Unnesting 되지 않은 서브쿼리에만 작동한다.

ㅅ브쿼리가 unnesting 되면 필터가 아닌 다양한 조인 방식으로 실행된다. Unnesting 되는 순간 push_subq은 무용지물이다. 따라서 push_subq 힌트는 항상 no_unnesti 힌트에 같이 기술하는 것이 바람직하다.

반대로 서브쿼리 필터링을 가능한 한 나중에 처리하려면, No_unnest , no_push_subq 를 같이 사용하면된다.

주문\_x1 인덱스는 문제의 쿼리를 위한 최적의 구성이다.

상품분류는 데이터가 소량이어서 필터 과정에 캐싱 기능이 효과적으로 작동하고 있으므로 굳이 인덱스를 추가할 필요가 없다.

34. 뷰 merging 과 조인 조건 Pushdown

```sql
-- 지난달 부터 가입한 고객중 이번달 거래내역이 있는 고객
select c.고객번호, c.고객명, t.평균거래, t.최소거래, t.최대거래
from  고객 c
,(
  select 고객번호
  , avg(거래금액) 평균거래
  , min(거래금액) 최소거래
  , max(거래금액) 최대거래
  from 거래
  where 거래일시 >= trunc(sysdate, 'mm')
  group by 고객번호
) t
where c.가입일시 >= trunc(add_months(sysdate, -1), 'mm')
and t.고객번호 = c.고객번호
```

최적화 단위가 쿼리 블록이므로 옵티마이저가 뷰 쿼리를 변환하지 않으면 뷰 쿼리 블록을 독립적으로 최적화 한다.

문제의 쿼리를 예로들으 뷰를 독립저으로 최적화하려면 당월 거래 전체를 읽어 고객번호 수준으로 group by한 후 고객테이블과 조인해야 한다.

문제는 고객 테이블에서 전월 이후 가입한 고객을 필터링하는 조건이 인라인 뷰 밖에 있다는 사실이다.

이 조건을 만족하는 데이터가 대다수라면 상관 없지만, 대개는 소수일 것이다. 그런데도 인라인 뷰 안에서 당월에 거래한 모든 고객의 거래 데이터를 읽어야 하므로 비효율적이다.

그럴 때 뷰를 merging 해서 고객 기준으로 거래와 조인한 후 group by 한다면 전월 이후 가입한 고객이 당월에 일으킨 거래 데이터만 읽을 수 있어 효과적이다.

단 이때 부분범위 처리는 불가능하다. group by 이후 데이터를 출력해야 하기 때문이다.

부분범위 처리를 이용해 빠른 응답속도를 내야한다면, view merging을 하지 않은 상태에서 고객을 기준으로 인라인 뷰 집합과 nl 조인하면 된다. 그러면 전월 이후 가입한 고객만을 대상으로 고객번호를 건건이 뷰 안으로 밀어넣으면서 각 고객별 당월 거래 데이터만 읽어서 gourp by 결과를 출력할 수 있다.

이 기능을 조인 조건 Pushdown이라고 한다. 오라클 11g 이후부터 작동하기 시작했다.
이 기능의 특장점은 nl 조인을 수행하는 도중에 멈출 수 있어 부분범위 처리가 가능하다는 점이다.

인라인 뷰를 merging 하지 않고 인라이 뷰 집합을 기준으로 고객과 nl 조인하는 방식은
고객별 거래량이 많고 가입일시 조건을 만족하는 데이터가 많을수록 유리하다.

인라인 뷰를 Merging하지 않으면 메인쿼리와 인라인 뷰를 각각 최적화 한다.

인라인 뷰를 merging 하지 않은 상태에서 인라인뷰를 기준으로 고객과 nl 조인하는 방식은 인라인 뷰에서 읽어온 거래에 속하는 매인쿼리의 고객이 많을 때 유리하다. 즉, 고객별 거래량이 만거나 가입일시 조건을 만족하는 데이터가 많을 때 유리하다.

인라인 뷰를 merging 하지 않은 상태에서 고객 기준으로 인라인 뷰 집합과 Nl 조인할 때
조인조건 pushdown을 통해 부분범위 처리 가능한 방식으로 처리할 수 있다.

인라인 뷰를 merging 하면 전체 결과를 대상으로 Group by해야하므로 부분범위 처리가 불가하다.

35. 조인조건 Push down

```sql
-- 고객_PK : 고객번호
-- 고객_X1: 가입일시
-- 거래_PK : 거래번호
-- 거래_X1 : 거래일시
-- 거래_X2 : 고객번호 + 거래일시

-- 지난달 부터 가입한 고객중 이번달 거래내역이 있는 고객
select c.고객번호, c.고객명, t.평균거래, t.최소거래, t.최대거래
from  고객 c
,(
  select 고객번호
  , avg(거래금액) 평균거래
  , min(거래금액) 최소거래
  , max(거래금액) 최대거래
  from 거래
  where 거래일시 >= trunc(sysdate, 'mm')
  group by 고객번호
) t
where c.가입일시 >= trunc(add_months(sysdate, -1), 'mm')
and t.고객번호 = c.고객번호

-- View merge 안하고 인라인뷰 기준으로 매인쿼리와 nl 조인
-- select statement
--  nested loops
--     view
--      hash group by
--        table access by index rowid of 거래
--          index range scan of 거래_x1
--     table access by index rowid of 고객
--        index unique scan of 고객_Pk

-- View merge 안하고 메인쿼리 기준으로 인라인뷰와 nl 조인
-- 조인조건 push down이 발생하지 않아 고객번호가 인라인뷰의 조건절로 쓰이지 않으므로
-- 고객번호+거래일시 인덱스가 쓰일 수 없다.

-- select statement
--  nested loops
--     table access by index rowid of 고객
--        index unique scan of 고객_x1
--     view
--      sort group by
--        table access by index rowid of 거래
--          index range scan of 거래_x2

-- view mergeing 하고 고객과 거래테이블을 해시 조인 후 group by
-- select statement
--  HASH GROUP BY
--    hash join
--      table access full of 고객
--      Table access full of 거래

-- view merging 하지않은 상태로 조인 조건 Pushdown 방식으로 조인.
-- 이 기능이 작동하면 고객 기준으로 Nl 조인하면서 고객번호를 조건으로 사용할 수 있다.
-- select statement
--  nested loops
--     table access by index rowid of 고객
--        index unique scan of 고객_x1
--     view pushed predicate
--      sort group by
--        table access by index rowid of 거래
--          index range scan of 거래_x2


```

36. no_merge

```sql
select /*+no_merge(t) leading(t) use_nl(c)*/
c.고객번호, c.고객명, t.평균거래, t.최소거래, t.최대거래
from  고객 c
,(
  select
  고객번호
  , avg(거래금액) 평균거래
  , min(거래금액) 최소거래
  , max(거래금액) 최대거래
  from 거래
  where 거래일시 >= trunc(sysdate, 'mm')
  group by 고객번호
) t
where c.가입일시 >= trunc(add_months(sysdate, -1), 'mm')
and t.고객번호 = c.고객번호

-- EXECUTION PLAN
-- SELECT STATEMENT
--  NESTED LOOPS
--    VIEW
--      HASH (GROUP BY)
--        TABLE ACCESS BY INDEX ROWID OF '거래'
--          INDEX RANGE SCAN OF 거래_x1
--    TABLE ACCESS BY INDEX ROWID OF 고객
--      INDEX UNIQUE SCAN OF 고객_pk
```

인라인 뷰에서 당월 거래 전체를 읽어 고객번호 수준으로 Group by한 후 고객 테이블과 조인하는 실행계획이다.

이 방식은 고객별 거래 데이터가 많을때 효과를 발휘한다.

고객 테이블과 조인할 때 고객별로 한번씩만 조인하면 되기 때문이다.

실행계획에 view 오퍼레이션이 나타난다는 것은 뷰를 merging 하지 않았다는 뜻이다.

따라서 뷰 안쪽에 no_merge 힌트를 사용하ㅓ나, 메인 쿼리에 No_mege(view_alias) 힌트를 사용하면 된다.

뷰집합을 먼저 드라이빙했으므로 leading(view_alias) 를 추ㅏ하ㅗ, nl 조인이므로 use_nl 힌트를 추가하면 된다.

37. merge

```sql
select /*+merge(t) leading(c) use_nl(t)*/
c.고객번호, c.고객명, t.평균거래, t.최소거래, t.최대거래
from  고객 c
,(
  select
  고객번호
  , avg(거래금액) 평균거래
  , min(거래금액) 최소거래
  , max(거래금액) 최대거래
  from 거래
  where 거래일시 >= trunc(sysdate, 'mm')
  group by 고객번호
) t
where c.가입일시 >= trunc(add_months(sysdate, -1), 'mm')
and t.고객번호 = c.고객번호

-- EXECUTION PLAN
-- SELECT STATEMENT
--  HASH GROUP BY
--    NESTED LOOPS
--      TABLE ACCESS BY INDEX ROWID OF '거래'
--        INDEX RANGE SCAN OF 거래_x1
--      TABLE ACCESS BY INDEX ROWID OF 고객
--        INDEX UNIQUE SCAN OF 고객_pk
```

뷰를 merging 해서 고객을 기준으로 거래와 조인한 후 group by 하는 실행계획이다.
이 방식으로 저인하면 전월 이후 가입한 고객이 당월에 일으킨 거래 데이터만 읽을 수 있어 효과적이다.

단, 이 경우 부분범위 처리는 불가느하다. Group by 이후 데이터를 출력해야하기 때문이다.

sql에 뷰를 사용했는데 실행계획에 View 오퍼레이션이 나타나지 않은 것은 뷰를 merging했다는 뜻이다.

따라서 뷰 안쪽에 Merge 힌트를 사용하거나, 메인 쿼리에 merge(view_alias) 힌트를 사용하면 된다.

조인 순서는 leading(c) 또는 ordered 힌트로 제어할 수 있다.
nl 조인을 위해서는 Use_nl(t)나 use_nl(t.거래) 힌트를 사용하면 된다.

38. merge

```sql

-- 고객_PK : 고객번호
-- 고객_X1: 가입일시
-- 거래_PK : 거래번호
-- 거래_X1 : 거래일시
-- 거래_X2 : 고객번호 + 거래일시

select /*+no_merge(t) push_pred(t) use_nl(t) index(c 고객_X1) index(t.거래 거래_2)*/
c.고객번호, c.고객명, t.평균거래, t.최소거래, t.최대거래
from  고객 c
,(
  select
  고객번호
  , avg(거래금액) 평균거래
  , min(거래금액) 최소거래
  , max(거래금액) 최대거래
  from 거래
  where 거래일시 >= trunc(sysdate, 'mm')
  group by 고객번호
) t
where c.가입일시 >= trunc(add_months(sysdate, -1), 'mm')
and t.고객번호 = c.고객번호

-- EXECUTION PLAN
-- SELECT STATEMENT
--  NESTED LOOPS
--    TABLE ACCESS BY INDEX ROWID OF 고객
--      INDEX UNIQUE SCAN OF 고객_pk
--    VIEW PUSHED PREDICATE
--      SORT(GROUP BY)
--      TABLE ACCESS BY INDEX ROWID OF '거래'
--        INDEX RANGE SCAN OF 거래_x1

```

뷰를 merging 하지 않은 상태에서 고객을 기준으로 이나인 뷰 집합과 nl 방식으로 조인하는 실행계획이다.

이 방식으로 조인하면 전월 이후 가입한 고객을 대상으로 고객번호를 건건이 뷰 안으로 밀어 넣으면서 각 고객별 당월 거래 데이터만 읽어서 group by 결과를 출력할 수 있다.

이 기능을 조인 조건 pushdown 이라고 하며, 오라클 11g 이후부터 작동하기 시작했다.

이 기능의 특장점은 Nl 조인을 수행하는 도중에 멈출 수 있다는 데 있다. 즉, 부분범위 처리가 가능하다.

실행계획처럼 고객 테이블을 먼저 드라이빙하려면 leading(C) 또는 ordered 힌트가 필요하고 nl 방식으로 실행하려면 use_nl 힌트가 필요하다.

view pushed predicate 오퍼레이션은 조인 조건인 고객번호를 건건이 뷰 안으로 밀어 넣는 방식을 의미하므로 항상 이렇게 실행되게 하려면 push_pred 힌트가 필요하다.

그에 앞서 꼭 추가해야할 힌트가 있다. 바로 no_merge 힌트다. 조인 조건 Pushdown 기능이 작동하려면 뷰가 merge 되지 않아야 하기 때문이다. 만약 view가 merge된다면 push_pred 힌트는 무시된다달

39.

```sql
-- 부분범위 처리가 가능한 상황에서 아래 SQL을 최적화하시오.

-- 고객_PK : 고객번호
-- 고객_X1: 가입일시
-- 거래_PK : 거래번호
-- 거래_X1 : 거래일시
-- 거래_X2 : 고객번호 + 거래일시

-- 조인조건 pushdown 활용
select /*+ leading(c) use_nl(t) index(c 고객_X1) */
c.고객번호, c.고객명, t.평균거래, t.최소거래, t.최대거래
from  고객 c
,(
  select /*+no_merge push_pred index(거래 거래_2)*/
  고객번호
  , avg(거래금액) 평균거래
  , min(거래금액) 최소거래
  , max(거래금액) 최대거래
  from 거래
  where 거래일시 >= trunc(sysdate, 'mm')
  group by 고객번호
) t
where c.가입일시 >= trunc(add_months(sysdate, -1), 'mm')
and t.고객번호 = c.고객번호


-- 스칼라 서브쿼리 활용

select /*+ leading(c) use_nl(t) index(c 고객_X1) */
c.고객번호, c.고객명, t.평균거래, t.최소거래, t.최대거래
from  고객 c
,(
  select /*+no_merge push_pred index(거래 거래_2)*/
  고객번호
  , avg(거래금액) 평균거래
  , min(거래금액) 최소거래
  , max(거래금액) 최대거래
  from 거래
  where 거래일시 >= trunc(sysdate, 'mm')
  group by 고객번호
) t
where c.가입일시 >= trunc(add_months(sysdate, -1), 'mm')
and t.고객번호 = c.고객번호
```

40. 뷰 Merging

```sql
-- index
-- 주문_pk : 주문번호
-- 주문_x1 : 주문일자
-- 주문_x2 : 고객번호 + 주문일자

select 고객번호, 주문금액
from(
  select 고객번호, sum(주문금액) 주문금액
  from 주문
  where 주문일자 Between :Dt1 and :dt2
  group by 고객번호
)
where 고객변호 = :cust_no

-- execution plan

select statement
  sort (group by nosort)
    table access (by index rowid) of 주문
      index range scan of 주문_x2
```

인라인 뷰를 사용했는데 실행계획에 view 가 나타나지 않으면 뷰 merging이 작동한 것이다.

41. 뷰 Merging

```sql
-- index
-- 주문_pk : 주문번호
-- 주문_x1 : 주문일자
-- 주문_x2 : 고객번호 + 주문일자

select 고객번호, 주문금액
from(
  select 고객번호, sum(주문금액) 주문금액
  from 주문
  where 주문일자 Between :Dt1 and :dt2
  group by 고객번호
)
where 고객변호 = :cust_no

-- execution plan

select statement
  view
    sort group by nosort
      table access by index rowid of 주문
        index range scan Of 주문_x2
```

인라인 뷰를 사용했는데 실행계획에 view 가 나타나지 않으면 뷰 merging이 작동한 것이다.
인라인뷰 조건절은 주문일자이므로 주문\_x1 인덱스가 사용됐어야 하는데 주문\_x2 인덱스가 사용된 이유는 조건절 pushdown 쿼리변환이 작동했기 때문이다.
즉, 바깥 쪽 고객번호 조건절을 인라인 뷰 안쪽으로 밀어 넣은 것이다.

42. 조건절 이행

```sql
-- 고객_pk : 고객번호
-- 주문_pk : 주문번호
-- 주문_x1 : 고객번호 + 주문일자
-- 주문_x2 : 주문일자

select *
from 고객 c, 주문 O
where c.고객번호 = 1234
and o.고객번호 = c.고객번호
and o.주문일자 between :ord_dt1 and :ord_dt2

--- select statement
--    hash join
--      table access by index rowid 고객
--        index unique scan 고객_pk
--      table access by index rowid 주문
--        index range scan
```

조건절 이행이라고 불리는 이쿼리 변환은 a = b 이고 b = c 이면 a = c 이다는 추론을 통해 새로운 조건절ㅇ르 내부적으로 생성해주는 쿼리 변환이다
a > b 이고 b > c 이면 a > c이다 라는 추론도 가능하다.
예를 들어, a 테이블에 상요된 필터 조건이 조인 조건절을 타고 반대편 b 테이블에 대한 필터 조건으로 이행 될 수 있다.
한 테이블 내에서 두 컬럼간 관계정보를 이용해 조걸절이 이행되기도 한다.

c.고객번호가 = 1234 이고 o.고객번호 = c.고객번호이므로 o.고객번호 = 1234 라는 추론이 가능하다.
옵티마이저는 이런 추론을 통해 조건절을 아래와 같이 변환할 수 있다.

```sql
where c.고객번호 = 1234
and o.고객번호 = 1234
and o.주문일자 between :ord_dt1 and :ord_dt2
```

주문 쪽 고객번호 조건절이 없는데도 고객번호가 선두인 주문\_x1 인덱스를 사용한 사실을 통해 조건절 이행 쿼리변환이 작동했음을 알 수 있다.
nl조인이라면 주문쪽에 고객번호 조건을 추가하지 않아도 조인과정에 주문\_x1 인덱스를 사용할 수 있지만, 해시 조인은 불가능하다.
만약 해시조인인데 조건절 이행이 작동하지 않았다면 주문x2 인덱스를 사용하거나 table full scan 했을 것이다.

43. or expantion

```sql
-- 인덱스 구성
-- 고객_pk : 고객번호
-- 고객_x1 : 주민번호
-- 고객_x2 : 전화번호
-- 고객_x3 : 고객명

select *
from 고객
where 주민번호 like :reg_no || '%'
and (고객명 = :cust_nm or 전화번호 like :phone_no || '%')

-- select statement
--  concatenation
--    table access by index rowid 고객
--      index range scan 고객_x2
--    table access by index rowid 고객
--      index range scan 고객_x3
```

OR EXPANSION 은 or 조건을 분해해서 union all 형태로 변환해 주는 기능이다.
이 기능이 작동하도록 유도하는 힌트는 use_concat이며, 반대로 이 기능을 방지하는 힌트는 no_expand다

concatenation 오퍼레이션을 통해 OR EXPANSION 이 작동한 사실을 알 수 있다.
OR 조건을 이 방식으로 실행하도록 유도하고자 할때 use_concat 힌트를 사용한다. 만약 이 기능을 방지하기 위해 NO_Expand를 사용한다면,
다음과 같은 실행계획이 나타난다.

```sql
-- select statement
--  table access by index rowid 고객
--    index range scan  고객_x1
```

44. or_expansion

```sql
-- 인덱스 구성
-- 고객_pk : 고객번호
-- 고객_x1 : 주민번호
-- 고객_x2 : 고객명

select /*+use_concat*/
*
from 고객
where 주민번호 like :reg_no || '%'
and 고객명 = nvl(:cust_nm , 고객명)

-- execution plan 1
-- select statement
--  concatenation
--  filter
--    table access by index rowid 고객
--      index range scan 고객_x1
--  filter
--    table access by index rowid 고객
--      index range scan 고객_x2

select /*+no_expand*/
*
from 고객
where 주민번호 like :reg_no || '%'
and 고객명 = nvl(:cust_nm , 고객명)

-- execution plan 2
-- select statement
--   table access by index rowid 고객
--    index range scan of 고객_x1
```

nvl 또는 decode 함수에 대해서도 or expansion 기능이 작동한다. 관련 히든 파라미터는 'or_expand_nvl_predicate' 이며, 기본 설정은 true이다.

이 기능을 활용하면 변별력이 좋은 컬럼에 대한 옵션 조건을 효과적으로 처리할 수 있다.

단, null 허용 컬럼일 경우 결과집합에 오류가 생길 수 있으므로 반드시 Not null 컬럼에만 사용해야 한다.

참고로 nvl 함수 대신 coalesce 함수를 , decode 함수 대신 case 문을 사용해도 되지만 or expansion 이 작동하지 않는다.

45.

```sql
-- 인덱스 구성
-- dept_pk :deptno
-- dept_x1 : loc
-- emp_pk : empno
-- emp_X1 : job + deptno
-- emp_x2 : mgr + job

select
*
from emp e, dept d
where
e.job = 'cleark'
and e.deptno = d.dpetno
and
(d.loc = 'dallas' or d.mgr = 7782)

-- execution plan

-- select statement
--  nested loops
--    nested loops
--      table access by index rowid emp
--        index range scan emp_x1
--      index unique scan dept_pk
--    table access by index rowid dept
```

공통 표현식 제거는 같은 조건식이 여러 곳에서 반복 사용될 경우, 해당 조건식이 각 로우당 한 번씩만 평가되도록 변환하는 것을
말한다.

공통 표현식 제거 쿼리 변환이 작동하지 않았다면 문제의 sql은 or-expansion 을 통해 아래와 같은 실행계획이 나타났을 것이다.

```sql
-- select statement
--  concatenation
--    nested loops
--      nested loops
--        table access by index rowid emp
--          index range scan emp_x2
--        index unique scan dept_pk
--      table access by index rowid dept
--    nested loops
--      nested loops
--        table access by index rowid dept
--          index range scan dept_X1
--        index unique scan emp_x1
--      table access by index rowid emp
```

옵티마이저가 두 조건절에 공통으로 사용된 조건절을 바깥을 ㅗ빼내서 아래 정답과 같이 쿼리를 재작성할 수 있고, 그러면 문제에 제시한 실행계획이 나타난다.

둘 중 어느 쪽의 성능에 유리할지는 데이터 분포에 따라 다르다. 개발자가 상황에 따라 최적의 형태로 Sql을 작성할 줄 알아야 한다.


