# 소트튜닝

1. 소트 수행 과정

정렬할 대상 집합을 SGA 버퍼캐시를 통해 읽어들이고, 일차적으로 SORT AREA에서 정렬을 시도한다.

PGA 메모리 공간에 할당한 SORT AREA에서 정렬 작업을 완료하는 것이 최적이지만,
데이터의 양이 많을때는 정렬된 중간집합을 Temp 테이블스페이스에 임시 세그먼트를 만들어저장한다.

- SORTAREA가 찰 때마다 TEMP 영역에 저장해 둔 중간 단계의 집합을 sort runs라고 부른다.

정렬된 결과를 temp 영역에 임시 저장했다가 다시 읽어들이는 디스크 소트가 발생하는 순간 SQL 성능이 크게 나빠진다.

\- 정렬 대상 집합이 크지 않아 SORT AREA 내에서 작업을 마무리하는 것을 optimal 소트라고 한다.

\- 실행계획에 나타난 하나의 소트 오퍼레이션에 대해 정렬 대상 집합을 한 번만 기록하고 작업을 마치는 것을 onepass 소트, 디스크에 여러 번 기록하는 것을 multipass 소트 라고 한다.

2. 소트 오퍼레이션

```sql
SET AUTOTRACE TRACEONLY;

SELECT *
FROM (
  SELECT 고객번호, 거래일자, 거래금액,
  SUM(거래금액) OVER (PARTITION BY 고객번호) 총거래금액
  FROM 거래
)
WHERE 총거래금액 >= 100000
ORDER BY 총거래금액 DESC, 고객번호, 거래일자;

--- OPERATION
-- SELECT STATEMENT
--    SORT ORDER BY
--      VIEW
--        WINDOW SORT
--          TABLE ACCESS FULL 거래

-- Statistics
-- 1 sort (memory)
-- 2 sort (disk)
```

실행계획에 나타난 소트 오퍼레이션의 수는 실행통계(STATISTICS)의 sorts(memory) 항목과
sorts(memory) 항목의 수치를 더한 값과 일치한다.

위 실행계획에서는 소트 오퍼레이션이 두 번(sort order by, window sort) 나타났는데 그 중 한 번은 메모리 내에서 처리를 완료해(sort memory)로 표시됐고, 다른 한 번은 디스크 소트가 발생했다

소트해야 할 데이터양을 감안할 때, 전자는 SORT ORDER BY( 총거래금액이 10만 이상인 데이터만 정렬) 가 해당하고 후자는 WINDOW SORT(전체 거래 데이터에 대한 윈도우함순) 에 해당한다.

GROUP BY 또는 중복 제거 연산에 HASH 알고리즘을 사용하면 sorts memory 항목과 sort dist 항목이 모두 0으로 표시된다.

3. 대기이벤트

데이터를 정렬할 때 일차적으로 PGA 메모리에 할당되는 SORT AREA를 이용한다.
SORT AREA 가 부족해지면 TEMP 테이블스페이스를 이용하는데, SORT AREA에 정렬된 데이터를 TEMP 테이블스페이스에 쓰고 이를 다시 읽어 들일 때 DIRECT PATH I/O 방식을 사용한다. 이 과정에서 i/o call이 완료될 때 까지 대기가 발생하는데 direct path write temp / Direct path read temp 이벤트로 측정된다.

4. sort operation

```sql
select distinct 고객번호
From 주문
where 주문일시 >= trunc(sysdate - 1)
order by 고객번호

-- execution plan
select statement
  sort (unique)
    partition range single
      table access full of 주문
```

\- sort group by는 group by 를 처리할 때 나타나는 오퍼레이션이다
\- partition range single 오퍼레이션을 통해 주문 테이블이 파티셔닝돼 있음을 알 수 있다
\- sort(unique) 는 distinct 또는 unique 연산을 처리할 때 나타난다
\- order by 가 없다면 sort(unique) 대신 hash(unique) 오퍼레이션이 나타날 수 있다
\- distinct 와 order by 를 같이 사용한다고해서 hash(unique) 와 sort(order by) 오퍼레이션이 둘 다 나타나지는 않는다 hash(unique) 오퍼레이션이 sort(unique) 오퍼레이션으로 변경된다

5. sort operation

\- sort(aggregate) 는 전체 데이터에 대한 count, avg, sum 등 집계함수를 구할 때 나타난다. sort area를 가장 적게 사용한다.

\- sort (order by )는 전체 데이터를 정렬할 때 나타난다. 따라서 sort area를 가장 많이 사용한다.

\- sort(group by)는 group by 할때 나타나는 오퍼레이션이다. 전체 데이터를 정렬하지는 않고 읽는 레코드마다 sort 알고리즘을 이용해 값을 찾아가서 count, sum, min, max 연산을 수해안다.
따라서 결과집합 건수만큼만의 sort area 를 사용한다.

\- hash(group by) 는 sort 알고리즘대신 Hash 알고리즘을 사용한다는 점만 다를 뿐이다.
group by의 결과집함 만큼의 공간만 사용한다.

6.

```sql

select max(sal) from emp where deptno = 10

-- operation
--    select statement
--      sort aggregte
--        table access full of emp

select * from emp where deptno = 10 order by sal desc

-- operation
--    select statement
--      sort order by
--         table access full of emp

select job, max(sal) from emp where deptno = 10 group by job

-- operation
--    select statement
--      sort group by
--         table access full of emp

select job from emp where deptno = 10
union
select job from emp where deptno = 20

-- operation
--    select statement
--      sort unique
--        union-all
--          table access full of emp
--          table access full of emp
```

sort aggregate 는 조건을 만족하는 전체 데이터에 대한 count, sum, min, max 값을 구할 때 나타난다. Count, sum을 구할 때는 어쩔 수 없지만 Min, max를 구할 때는 인덱스 구성으 통해 소트 연산을 대체할 수 있다.

아래는 조건절을 만족하는 min, max 값을 인덱스에서 한 건만 읽어서 반환할 때 나타나는 실행계획이다.

```sql
-- operation
--    select statement
--      sort aggregte
--        first row
--          index rane scan (min/max) emp_x1
```

sort order by는 인덱스를 잘 구성하면 소트 연산을 생략할 수 있다.

sort group by 도 인덱스를 잘 구성해 주면 소트 연산을 생략할 수 있다.

```sql
-- operation
--  select statement
--      sort group by nosort
--        index range scan emp_x1
```

sort unique/union-all 은 Union 집합 연산다를 사용할 때 나타난다.
union 위쪽과 아래쪽 집합 간 중복을 제거하려면 데이를 모두 읽어야하므로 인덱스로 소트 연산을 대체할 수 없다.

7. union / union all

```sql
-- 주문  1       결제 N
-- # 주문번호    # 결제번호
-- * 고객번호    * 결제수단코드
-- * 주문일시    * 주문번호
-- * 주문금액    * 결제금액
--             * 결제일자
--             * 주문일자

-- 결제수단 코드가 상호 배타적이고 조회 컬럼에도 속해 있다.
-- 결제번호는 집합안에서 중보이 발생하지않는다.
-- union all로 대체해도 결과집합이 변하지 않는다.
select 결제번호, 결제수단코드, 주문번호, 결제금액
from 결제
where 결제수단코드 = 'M' and 결제일자 = '20210316'
union
select 결제번호, 결제수단코드, 주문번호, 결제금액
from 결제
where 결제수단코드 = 'C' and 결제일자 = '20210316'

-- 결제수단 코드가 상호 배타적이지만 조회 컬럼에 속해있지 않다.
-- 주문번호는 결제테이블에 의해 중복될 수 있다.
-- union all로 대체하면 중복컬럼이 나타나므로 결과집합이 변한다.
select 주문번호, 결제금액, 결제일자, 주문일자
from 결제
where 결제수단코드 = 'M' and 결제일자 = '20210316'
union
select 주문번호, 결제금액, 결제일자, 주문일자
from 결제
where 결제수단코드 = 'C' and 결제일자 = '20210316'

-- 주문번호는 결제테이블에 의해 중복될 수 있다.
-- union all로 대체하면 중복컬럼이 나타나므로 결과집합이 변한다.
select 주문번호, 주문일자, 결제수단코드, 결제금액
from 결제
where 주문일자 = '20210315'
union
select 주문번호, 주문일자, 결제수단코드, 결제금액
from 결제
where 주문일자 = '20210316'

-- union all로 대체하면 중복컬럼이 나타나므로 결과집합이 변한다.
select
from 결제
where 결제수단코드
union
select
from 결제
where 결제수단코드
```

8. 부분범위처리

```sql
-- 인덱스 구성
-- 결제_pk : 결제번호
-- 결제_x1 : 주문번호 + 결제수단코드
-- 결제_x2 : 결제일자
-- 결제_X3 : 주문일자

select 결제번호, 결제수단코드, 주문번호, 결제금액, 결제일자, 주문일자 ...
from 결제
where 결제일자 = '20210316'
union
select 결제번호, 결제수단코드, 주문번호, 결제금액, 결제일자, 주문일자 ...
from 결제
where 주문일자 = '20210316'

-- execution plan
-- select statement
--    sort
--      union-all
--        filter
--          table access by index rowid of 결제
--            index range scan of 결제_x2
--        filter
--          table access by index rowid of 결제
--            index range scan of 결제_x3
```

union 을 union all로 변경하면 3월 16일에 주문과 결제를 모두 처리한 데이터는 중복출력된다.

결제일자와 주문일자 조건은 상호배타적 조건이 아니기 때문이다.

소트 연산이 일어나지 않도록 union all 을 사용하면서도 데이터의 중복을 피하려면
union all 아래쪽에 결제일자가 20210316인 데이터가 출력되지 않도록 조건절을 추가한다.

결제일자가 null 허용 컬럼일 경우 null일때는 포함되도록 한다.

```sql
select 결제번호, 결제수단코드, 주문번호, 결제금액, 결제일자, 주문일자 ...
from 결제
where 결제일자 = '20210316'
union all
select 결제번호, 결제수단코드, 주문번호, 결제금액, 결제일자, 주문일자 ...
from 결제
where 주문일자 = '20210316'
and (결제일자 <> '20210316' or 결제일자 is null)

```

9. i/o 최소화

```sql
-- 데이터
-- 종목거래 : 100억 건
-- 하루 거래건수 : 1000만 건
-- 종목 : 500개
-- 거래지점 : 5개

select *
from (
  select 거래일시, 체결건수, 체결수량, 거래대금
  from 종목거래
  where 종목코드 = 'kr12456' -- 종목 500개, 종목당 거래 평균 2천만건
  and 거래지점코드 in ('a03', 'f12') -- 거래지점 5개, 거래지점당 20억건
  and 거래일시 >= trunc(sysdate) -- 하루 거래수 1000만건
  order by 거래일시 desc, 거래순번 desc
)
where rownum <= 50
```

인덱스에 다수의 소트조건 컬럼이 연속되지않으면 소트 생략 불가능한 인덱스 구성이다.
조건절을 만족하는 전체 데이터만큼 인덱스를 스캔하면서 테이블 액세스를 하고 정렬까지 만친 후 50건은 출력한다. 전체범위를 처리하는 과정에 많은 i/o가 발생한다.

조건절에 있는 컬럼이 인덱스에 포함되지 않으면 조건을 만족하지 않는 데에터에 대해서도 테이블 액세스가 발생한다.

10. i/o 최소화

```sql
-- data
-- 하루 상담건수 = 20000
-- 아웃바운드(접촉구분코드 = 'otbnd') 50%
-- 판매성공 건 (상담결과코드 = 'RS01')  1%
-- 방문요청 건 (상담결과코드 = 'RY13')  2%

select *
from (
  select 상담원id, 상담일자, 상담순번, 상담유형코드, 상담결과코드, 상품코드
  from 상담
  where 접촉구분코드 = 'otbnd'
  and 상담결과코드 in ('rs01', 'ry13')
  and 상담일자 >= to_char(sysdate -1 , 'yyyymmdd')
  and 상담일자 < to_char(sysdate , 'yyyymmdd')
  order by 상담일자 Desc, 상담순번 desc
)
where rownum <= 100
```

인덱스를 접촉구분코드 + 상담일자 + 상담순번 으로 구성할 경우
접촉구분코드 조건에 해당하는 데이터가 많기때문에 소트 연산을 생략할 수 있더라도 많은 테이블 랜덤 엑세스가 발생한다.

상담결과코드의 선택도가 3%이므로 평균적으로 테이블을 100번 액세스해야 3개 레코드를 얻는다. 100개의 레코드를 출력하려면 테이블을 펴균 3,334번 액세스 해야한다.

상담결과코드를 선두로 인덱스를 설계하면 소트를 생략할 수 없지만 조걵러을 만족하는 데이터의 수가 적다. 테이블 랜덤 액세스도 최데 300 번 정도 발생한다.

11. 소트연산생략

```sql
-- 소트연산을 생략하면서 i/o 최소화할 수 있는 인덱스 구성
select 상담원id, count(*) 상담건수
from 상담
where 상담결과코드 = 'RS01'
and 상담일자 < trunc(sysdate, 'MM')
group by 상담원id
-- 인덱스 전체가 group by 기준컬럼에 대해 정렬되어있어야 생략가능
-- 1. 상담원id + 상담결과코드 + 상담일자
-- 2. 상담결과코드 + 상담일자 + 상담원Id
-- 3. 상담결과코드 + 상담원Id + 상담일자
```

소트 생략은 부분범위 처리와 같은 개념이다.
소트 연산을 생략하려는 목적이 전체 결과 집합 중 앞쪽 일부를 빨리 출력하기 위함이기 때문이다.

order by 뿐 아니라 Group by도 인덱스를 장 구성하면 소트 연산을 생략할 수 있다.

```sql
select statement
  sort group by nosort
    table access by index rowid 상담
      index range scan 상담_x01
```

1번 인덱스는 소트 생략이 가능하지만, 상담결과코드를 필터링하는 과정에서 i/o가 많이 발생한다.

3번은 소트 생략 가능하며 상담일자를 인덱스에서 필터링 하므로 불필요한 테이블 액세스는 발생하지 않는다.
상담일자 조건이 전월 이전에 상당한 데이터를 가리키므로 대부분의 상담 데이터가 조건을 만족한다 따라서 인덱스 스캔 비효율도 없다.

12. distinct 쿼리변환

```sql

-- data
-- 상품 : 1000건
-- 계약 : 5000 건
-- 1년간 계약건수는 500만 건
-- 상품유형코드를 = 조건으로 검색할때의 평균 카디널리티는 100

-- index
-- 상품_pk : 상품번호
-- 상품_x1 : 상품유형코드
-- 계약_PK : 계약번호
-- 계약_x1 : 계약일자
-- 계약_x2 : 상품번호

select
distinct p.상품번호, p.상품명, p.상품가격, p.상품분류코드
from 상품 P, 계약 c
where p.상품유형코드 = :pclscd
and c.상품번호 = p.상품번호
and c.계약일자 >= trunc(add_months(sysdate, -12))

-- select statement
--    hash (unique)
--      filter
--        nested loops
--          nested loops
--            table access by index rowid of 상품
--              index range scan of 상품_x1
--             index range scan of 계약_x2
--           table access by index rowid of 계약

select
p.상품번호, p.상품명, p.상품가격, p.상품분류코드
from 상품 P
where p.상품유형코드 = :pclscd
and exists (
  select /*+ no_unnest index(계약 계약_x3)*/
  'X'
  from 계약
  where c.계약일자 >= trunc(add_months(sysdate, -12))
  and 상품번호 = p.상품번호
  )

select /*+leaing(p)*/
p.상품번호, p.상품명, p.상품가격, p.상품분류코드
from 상품 P
where p.상품유형코드 = :pclscd
and exists (
  select /*+ unnsest nl_sj*/
  'X'
  from 계약
  where c.계약일자 >= trunc(add_months(sysdate, -12))
  and 상품번호 = p.상품번호
  )
```

상품유형코드의 선택도가 10%이므로 최근 1년간 계약건수 500만 건 중 50만건을 읽을 것으로 예상딘다.
DISTINCT 연산을 통해 중복을 제거한 최종 결과집합은 100개의 상품 집합인데, 문제에서 제시한 실행계획대로 읽으면 50만 건의 계약 데이터를 랜덤 엑세스 방식으로 읽어야 한다.

exists를 서브 쿼리로 변환하면 100개 상품에 대해 계약과 조인에 성공하는 데이터가 존재하는지만 확인하면 되므로 훨씬효율저이다.

계약일자 조건을 확인 하기 위한 테이블 액세스를 피하려면, 계약\_x2 인덱스를 상품번호 + 계약일자로 구성해 주는 것이 좋다.

튜닝 후 실행계획은 아래와 같다.

```sql
SELECT STATEMENT
  FILTER
    NESTED LOOPS(SEMI)
      table access by index rowid of 상품
        index range scan of 상품_x1
      index range scan of 계약_x3
```

EXISTS 서브쿼리로 변환했는데 옵티마이저가 서브쿼리를 Unnesting 한 후에 해시 세미죈하거나 계약 테이블을 머저 읽어서 상품가 조인하는 방식으로 수행하면 원하는 성능 효과를 얻을 수 없다.

항상 위 실행계획처럼 상품을 먼저 읽어서 계약과 nl 세미 조인하도록 강제하려면 leading 과
nl_sj 힌트를 추가하면 된다.

서브쿼리를 unnesting 하지 못하도록 no_unnesting 만 ㅊ가해도 된다.
항상 필터방식으로 실행된다. 필터방식은 nl 세미 조인과 사실상 차이가 없고 항상 메인 쿼리를 먼저 읽으므로 Leading 또는 ordered 힌트도 불피료하다.

```sql
SELECT STATEMENT
  FILTER
      table access by index rowid of 상품
        index range scan of 상품_x1
      FILTER
        index range scan of 계약_x3
```

13. distinct 최적화

```sql
-- data
-- 상품 : 100개
-- 주문 : 1억건
-- 주문상품 : 2억 건

-- 한달주문건수 : 100만 건
-- 거의 모든 상품에 골고루 주무 발생

-- index
-- 주문_pk : 주문번호
-- 주문_x1 : 주문일자
-- 주문상품_pk : 주문번호 + 상품코드

-- sql

select distinct
o.주문번호, o.주문금액, o.결제구분코드, o.주문매체코드
from 주문 o, 주문상품 p
where o.주문일자 >= trunc(add_months(sysdate, -12))
and p.주문번호 = o.주문번호
and p.상품코드 = :prd_cd

SELECT STATEMENT
  HASH(UNIQUE)
    FILTER
      NESTED LOOPS
        NESTED LOOPS
          TABLE ACCESS BY INDEX ROWID OF 주문
            INDEX RANGE SCAN OF 주문_x1
          INDEX RANGE SCAN OF 주문상품_x2
```

1년 기간동안 주문건수는 대략 1200만 건
거의 모든 상품에 골고루 주문이 발생하므로 특정 상품코드에 대한 주문상품 건수는 200만 건

```sql
select
o.주문번호, o.주문금액, o.결제구분코드, o.주문매체코드
from 주문 o
where o.주문일자 >= trunc(add_months(sysdate, -12))
and exists (
  select /*+unnest hash_sj*/'x'
  from 주문상품
  where p.주문번호 = o.주문번호
  and p.상품코드 = :prd_cd
)
```

주문테이블은 1억 건중 1200만 건을 읽어야 하므로 table full scan이 효과적이다.

주문상품과 조인한 후 distinct 연산을 통해 중복을 제거한 최종 결과집합은 주문 단위 집합이다.

exists 서브쿼리로의 변환을 생각해볼 수 있지만 주문당 평균 주문 상품은 2건에 불과하므로
데이터 존재 여부만 확인한다고 해서 얻는 이점은 별로 없다.

1년치 주문이 1200만 건이므로 랜덤 엑세스 방식으로 주문상품을 필터링하기는 부담스럽다.
쿼리를 그댈 둔 상태에서 Nl 조인으로 처리하면 랜덤 엑세스 및 소트 부하가 더 크다.

결과적으로 해시 조인이 가장 효과적이다.

100개의 상품에 골고루 주문이 발생한다고 했으므로 상품코드 조건을 만족하는 주문 상품 데이터는 평균 200만 건이다.
주문번호에 대한 중복이 존재하지 않는다. 주문상품*pk가 주문번호 * 상품코드 이기때문이다.

주문에서 읽은 1000만건의 데이터 보다 건수도 적고 조인키에 중복 값도 없으므로 해시 맵 build input으로 최적의 조건이다.

주문상품을 읽을때 200만 건을 테이블 엑세스 없이 index range scan으로 읽으려면 상품코드 + 주문번호로 구성된 인덱스를 추가해야 한다.

200만 건도 많은 양이고 버퍼캐시 히트율이 낮을 때 single block i/o 방식으로 많은 디스크 블록을 읽는다면 성능이 매우 느릴수 있다. 게다가 쿼리 수행빈도가 높지 않다면 인덱스를 추가하는 것도 부담스러바.

그럴 때 인덱스 추가 없이 기존 주문상품\_pk 인덱스를 fast full scan 하도록 유도하면 multiplock i/o의 이점을 누릴 수 있다.

```sql
-- 주문상품_x1 : 상품코드 + 주문번호
select /*+leading(p) use_hash(o) full(o) index(p 주문상품_x1)*/
distinct
o.주문번호, o.주문금액, o.결제구분코드, o.주문매체코드
from 주문 o, 주문상품 p
where o.주문일자 >= trunc(add_months(sysdate, -12))
and p.주문번호 = o.주문번호
and p.상품코드 = :prd_cd

select /*+leading(p) use_hash(o) full(o) index_ffs(p 주문상품_p)*/
distinct
o.주문번호, o.주문금액, o.결제구분코드, o.주문매체코드
from 주문 o, 주문상품 p
where o.주문일자 >= trunc(add_months(sysdate, -12))
and p.주문번호 = o.주문번호
and p.상품코드 = :prd_cd
```

14. 소트생략

```sql
-- index
-- 상품_pk : 상품코드
-- 계약_pk : 계약번호
-- 계약_X1 : 지점ID

-- 계약_x2 : 지점ID + 계약일시
select *
from (
  select /*+ leading(c) use_nl(p) index_desc(c 계약_x2)*/
  c.계약번호, c.
  from 계약 c, 상품 P
  where c.지점id = :brch_id
  and p.상품코드 = C.상품코드
  order by c.계약일시 desc
) x
where rownum <= 50

-- exection plan
select statement
  count(stopkey)
    view
      sort
        hash join
          table access full of 상품
          table access by index rowid of 계약
            index range scan of 계약_x1
```

조건절을 만족하는 전체 데이터 중 정렬 기준에 맞는 상위 50개 레코드를 빠르게 추출하려면 부분범위 처리가 가능해야 한다.
즉, 소트 연산을 생략할 수 있어야 한다.

해시 조인으로는 소트연산을 생략할 수 없으므로 nl\_조인으로 유도해야 한다.
정렬 기준이 소트를 생략하려면 인데스를 지점id\_계약일시 로 구성해야 한다.

15. 페이징처리

```sql
SELECT 계약번호, 상품코드, 계약이시, 계약금액
FROM (
  SELECT ROWNUM AS RNUM, C.*
  from (
    select
    계약번호, 상품코드, 계약이시, 계약금액
    from 계약
    where 지점id = :brcd_id
    and 계약일시 >= trunc(sysdate - 7)
    order by 계약일시 DESC
  )C
  WHERE ROWNUM <= (:PAGE * 10)
)
WHERE RNUM >= (:PAGE -1) * 10 + 1

```

성능 측면에서 가장 효과적으로 페이징 처리를 구현하려면, 부분범위 처리 가능한 패턴을 선택해야 한다.

TOP N STOPKEY 알고리즘이 작동할 수 있어야하는데 이를 윟 인라인 뷰에 안쪽 order by를 명시하고 바로 바깥 쪽에 ROWNUM <= 조건을 명시해야 한다.

이 방식으로 쿼리를 자성하면 인덱스 구성이 불충분해서 전체 데이터를 읽더라도 top N sort 알고리즘이 작동하면서 소트 부하를 경감한다.

16. 집계함수

```sql
-- 상품변경이력에서 최근 1년 내에 ze367 상품의 변경구분코드가 C2인 최종 변경일시를 찾는 가장 효과적인 sql 작성

-- 상품변경이력
-- # 상품번호
-- # 변경일시
-- # 변경구분코드

select max(변경일시)
from 상품변경이력
where 상품번호 = 'ze367'
and 변경구분코드 = 'C2'
and 변경일시 >= Trunc(add_months(sysdate, -12))
```

상품번호 + 변경구분코드 + 변경일시 로 구성된 인덱스가 있으면 가장 좋지만,
현재는 상품번호 + 변경일시 + 변경구분코드 순으로 구성된 pk dlseprtm Qnsdlek.

다행히 소트 생략 가능한 구성이므로 first row min/max 기능은 작동한다.

변경구분코드가 필터조건이므로 인덱스 스캔 과저에서 다소 비효율이 나타날 수 있다.
하지만 상품번호조건에 해당하는 변경이력은 매우 많은데 그 중 변경구분코드에 해당하는 데이터가 매우 적은 경우가 아니면 큰 문제는 없다.

1번은 틀린 결과를 추력하고 2번은 같은 데이터를 2번 읽는 비효율이 있다.

4번은 인덱스 구성이 변경되면 틀린 결과를 반환할 가능성이 있으므로 사용하지 않는 것이 좋다.
기존 인덱스가 변경되지 않더라도 index 힌트에 인덱스명을 지정하지 않았으므로 신규 인덱스로 인해 틀린 결과를 반한할 수도 있다.

17. top 1

```sql
-- 상품변경이력에서 상품번호 = 'ze367' 상품의 변경구분코드가 C2인 최종 변경일시를 찾는 가장 효과적인 sql 작성

-- ERD 컬럼 나열 순서와 동일하게 PK 인덱스를 생성했다.

-- 상품변경이력
-- # 상품번호
-- # 변경일시
-- * 변경구분코드
-- 상품변경이력_pk : 상품번호 + 변경일시

select max(변경일시)
from 상품변경이력
where 상품번호 = 'ze367'
and 변경구분코드 = 'C2'

```

위 쿼리는 성능 측면에서 비효율이 생길 수 이다.

인데스에서 최소 또는 최대값을 빠르게 찾으려면, 조건절 컬럼과 min, max 함수 인자 컬림이 모두 인덱스에 포함되어있어야 한다. 즉, 테이블 액세스가 전혀 발생하지 않아야 한다.
하지만 변경구분 코드를 필터링하려면 테이블 엑세스해야한다.
결국, first orw (min/max) 기능이 작동하지 않아 조걸절 데에티를 모두 읽어야 하고 상품조건에 대한 변경이력이 매우 많다면 성능에 문제가 될 수 있다.

인덱스를 변경하거나 추가할 수 없다면 top1 쿼리로 작서애주는 것이 좋다

```sql
select 변경일시
from (
  select 변경일시
  from 상품변경이력
  where 상품번호 = 'ze367'
  and 변경구분코드 = 'C2'
  order by 변경일시 desc
)
where rownum <= 1

```

18. 집계함수

```sql
-- 2021년 3월에 변경된 상품 중에 3월의 최종 상품변경이력의 변경구분코드가 c2인 상품의 상품번호와 변경일시를 출력하는 최적 sql

-- 상품변경이력
-- # 상품번호
-- # 변경일시
-- * 변경구분코드



select 상품번호, 변경일시
From (
  select 상품번호, 변경일시, 변경구분코드
  , row_number() over(partition by 상품번호 order by 변경일시 desc) no
  from 상품변경이력
  where (
    변경일시 >= to_date('20210301', 'YYYYMMDD')
    and
    변경일시 <= to_date('20210401', 'YYYYMMDD')
  )
)
where no = 1
and b.변경구분코드 = 'c2'

```

2021 3월에 변경된 상품변경이력 중에서 상품별 최종 데이터를 찾는 방법은 위와 같다.
이제 변경구분코드가 C2 인 데이터를 찾아야 하므로 하단에 변경구분코드 = c2 조건을 추가해주면 된다.

keep 절을 이용하는 방법도 있다.

```sql
select 상품번호 , max(변경일시) 변경일시
from 상품변경이력
where (
    변경일시 >= to_date('20210301', 'YYYYMMDD')
    and
    변경일시 <= to_date('20210401', 'YYYYMMDD')
  )
group by 상품번호
having max(변경구분코드) keep (dense_rank last order by 변경일시) = 'C2'


```

19. 집계함수

```sql
-- 아래 상품할인율 테이블에서 상품번호가 R0014인 상품의 2021년 3월 한 달간 일별 최종 한인율(기준일자별 마지막 변경순서 할인율)을 찾는 sql을 작성하시오

-- 상품할인율
-- # 상품번호
-- # 기준일자
-- # 변경순번
-- * 할인율

select 기준일자, 할인율
From (
  select
   기준일자, 할인율,
  row_number() over (partition by 기준일자 order by 변경순변 desc) no
  from 상품할인율
  where 상품번호 = 'R0014'
  and 기준일자 between '20210301' and '20210331'
)
where no <= 1
order by 기준일자


select 기준일자,
, max(할인율) keep (dense_rank last order by 변경순번) 할인유
from 상품할인율
where 상품번호 = 'R0014'
and 기준일자 between '20210301' and '20210331'
group by 기준일자
order by 기준일자
```

sql을 아래와 같이 작성해도 결과는 같지만, 상품할인율을 두 번 조회하므로 최적은 아니다.

```sql
select B.기준일자, B.할인율
FROM (
  SELECT
  기준일자, MAX(변경순번) 변경순번
  FROM 상품할인율
  WHERE 상품번호 = 'R0014'
  and 기준일자 between '20210301' and '20210331'
  GROUP BY 기준일자
), 상품할인율 B
WHERE B.상품번호 = 'R0014'
AND B.기준이자 = a.기준이자
AND b.변경순번 = a.변경순번
ORDER BY B.기준일자
```

20.집계함수

```sql
-- 아래 상품할인율 테이블에서 상품번호가 R0014인 상품의 최종(마지막 기준일자의 마지막 변경순서) 할인율을 출력하는 최적 sql

-- 상품할인율
-- # 상품번호
-- # 기준일자
-- # 변경순번
-- * 할인율

select 기준일자, 할인율
From (
  select
   할인율,
  from 상품할인율
  where 상품번호 = 'R0014'
  order by 기준일자 desc, 변경순변 Desc
)
where no <= 1


```

21. IN LIST-ITERATOR

```sql
select *
from (
  select *
  from 상품변경이력
  where 상품번호 = :prd_no
  and  변경구분코드 in( 'A1', 'C2')
  order by 변경일자 desc, 변경일련번호 desc
)
where rownum >= 1
```

조건을 만족하는 단 한 건의 데이터를 빠르게 찾으려면 소트 연산을 생략할 수 있어야 한다.
그러기 위해선 인덱스 아래 공식에 따라 구성해야 한다.

1. = 연산자를 사용한 조건절 컬럼 선정
2. order by 절에 기술한 컬럼 추가
3. = 연산자가 아닌 조건절 컬러믄 데이터 분포를 고려해 추가 여부 결정ㄴ

In 조건절에 쓰인 컬럼인 변경구분코드를 앞쪽에 두어도 소트연산을 생략할 수 있다고 생각했을 수 있다.
IN 조건은 = 이 아니다. iN-LIST ITERATOR 방식으로 풀려야 = 와 같다.

IN-LIST ITERATOR 방식으로 풀린다 하더라도 union all 로 결합한 두 집합의 정렬 순서를 인덱슬 제어할 방법은 없다.

결론적으로 소트연산을 생략하려면 in-list-iterator 방식으로 풀려선 안된다.

즉, iN 조건절을 인덱스 엑세스 조건으로 상요하면 안되고 필터조건으로 사용되야 한다.
따라서 변견구분토드는 인덱스에서 아에 졔외 되거나 맨 뒤쪽에 둔 상태에서 소트 생략 가능한 구성을 고민해야 한다.

22. top N

장비구분코드가 A001인 장비의 최종 상태코드, 변경일자, 변경순번을 출력하는 최적 SQL을 작성하시오.

```sql
select e.장비명, h.상태코드, h.변경일자, h.변경순번
from 장비 e,
(
  select 장비번호, 상태코드, 변경일자, 변경순번
  from (
    select 장비번호, 상태코드, 변경일자, 변경순번
    ,row_number() over (partition by 장비번호 order by 변경일자 desc 변경순번 desc) no
    from 상태변경이력
  )
  where no = 1
) h
where e.장비구분코드 = 'A001'
and h.장비번호 = e.장비번호

```

오라클 11g 까지는 메인 쿼리 컬럼을 서브쿼리 내 인라인 뷰에서 참조할 수 없었는데
12 버전부터 이 제약이 풀렸다.

따라서 TOP N 패턴의 성능 이점을 자유로베 활용할 수 있다.

```sql
select e.장비명, h.상태코드, h.변경일자, h.변경순번
from 장비 e, 상태변경이력 h
where e.장비구분코드 = 'A001'
and h.장비번호 = e.장비번호
and (h.변경일자 , h.변경순번) =
(
  select 변경일자, 변경순번
    from (
      select 변경일자, 변경순번
      from 상태변경이력
      where 장비번호 = p.장비번호
      order by 변경일자 desc, 변경순변 desc
    )
    where rownum <= 1
)
```

# DML 튜닝

23. DML 성능

DML 성능에 영향을 미치는 요소로는 인덱스, 무결성 제약, 조건절, 서브쿼리, REDO로깅, UNDO로깅, LOCK, 커밋 등이 있다.

DML 인 경우 옵티마이저 모드는 항상 ALL_ROWS(전체 처리속도 최적화)로 작동한다.
삽입, 갱신, 삭제 대상 중 일부만 처리하고 멈출 수 없기 때문이다.

24. commit 프로세스

```sql
ResultSet rs = stat.executeQuery();
while(rs.next()){
  int empno = rs.getInt(1);
  String ename = rs.getString(2);

  ...

  String SQLStmt = "insert into emp(empno, enam, ...) values(?,?, ...)";
  PreparedStatement st = con.prepareStatement(SQLStmt);
  st.setString(1, empno);
  st.setString(2, ename);
  ...
  st.execute();
  con.commit();
}
```

JAVA 애플리케이션이 커밋을 발행할 때마다 네트워크를 경유한 dB CALL이 발생한다.

커밋 명령을 전달받은 서버 프로세스는 REDO 로그버퍼에 커밋 레코드를 기록하고 LGWR에게 신호를 보낸 후 대기 상태로 전환한다.

신호를 받은 LGWR은 로그버퍼를 디스크 상의 로그 파일에 기록한 후 서버 프로세스에게 작업 완료 신호를 보낸다.

작업 완료 신호를 받은 서버 프로세스는 다음 작업을 계속 진행한다.

이런 복잡한 메커니즘을 수분하므로 커밋을 자주 수행하면 성능이 느려진다.

서버 프로세스가 변겨안 버퍼블록들이 커밋 시점에 바로 데이터 파일에 기록되지 않는다.

추후에 dbwr에 의해 기록된다. 버퍼블록 내용이 유실되더라도 트랜잭션의 영속성은 ㅗㅂ장된다.
커밋시점에 redo 로그를 디스크에 기록했기 때문이다.

25. UPDATE BATCH 성능 개선

\- UPDATE 되는 컬럼을 포함한 인덱스를 unusable 상태로 변경하고, 작업 완료 후에 재생성한다.

\- pk, fx 등 제약을 설정하고, 작업 완료 후에 재설정한다.

\- 병렬 처리를 활용한다.

\- nologging은 insert 시만 가능하다.

26. INSERT BATCH 성능개선

온라인 트랜잭션이 존재하는 주간에 대량 데이터를 일괄 INSERT 하는 배치 프로그램의 경우

DIRECT PATH INSERT 는 EXCLUSIVE MODE tM LOCK을 설정하므로 다른 트랜잭션이 해당 테이블에 DML을 수행하지 못하게 된다.

트랜잭션이 빈번한 주간에 이 옵션을 사용하는 것은 금물이다.

INSERT에 nologging 옵션을 활용할 수 있지만, 이는 DIRECT PATH INSERT 할 때만 작동한다.

온라인 트랜잭션이 수행되는 도중에 인덱스 및 제약을 해제할 수는 없다.

ARRAY PROCESSING 기능을 활용할 수 있다.

27. DIRECT PATH INSERT

DIRECT PATH INSERT 시,

DIRECT PATH INSERT EXCLUSIVE MODE TM LOCK을 설정하므로 다른 트랜재션이 해당 테이블에 DML 하지 못하게 된다.

uNDO 데이터를 남기지 않는다.

FREELIST를 참조하지 않고 HWM 바깥 영역에 데이터를 순차적으로 입력한다.

INSERT 할 블록을 버퍼캐시에서 탐색하지 않고 데이터파일에 직접 기록한다.

28. DIRECT PATH INSERT 작동 케이스

\- INSERT ... SELECT 문에 append 힌트 사용
\- 병렬 dml 을 활성화한 상태에서 insert 문에 parallel 힌트 사용
\- create table ... as select 문으로 테이블 생성

INSET ... SELECT 문을 수행하기 전에 nologging 모드로 전환

---

nologging 모드는 redo 로그 생성하지 않게 하는 옵션이므로 direct path insert와 직접적인 관련은 없다.

다만, redo 로그를 생성하지 않는 기능이 테이블을 nologging 모드로 전환한 상테에서 direct path insert 할 때만 작동할 뿐이다.

29. INSERT 성능 ㅐ선

```sql
ALTER TABLE TAGET_T NOLOGGING;
INSERT /*+APPEND*/
INTO TARGET_T
SELECT * FROM SOURCE_T;
```

테이블을 NOLOGGING 모드로 전환했고 DIRECT PATH INSERT (APPEND) 기능까지 작동하므로 성능 개선에 큰 도움이 된다.

```SQL
ALTER SESSION ENABLE PARALLEL DML
ALTER TABLE TARGET_T NOLOGGING;

INSERT /*+PARALLEL(T, 4)*/ INTO TARGET_T T
SELECT * FROM SOURCE_T;
```

병렬로 INSERT 할 때는 APPEND 힌트를 지정하지 않아도 자동으로 DIECT PATH INSERT 기능이 작동한다. 단. 사전에 'ALTER SESSION ENABLE PARALLEL DML' 명령을 통해 별령 DML 을 활성화해야 한다.

30. BATCH INSERT

온라인 트랜재션이 없는 야간에 대량 데이터를 일괄 INSERT 하는 배치 프로그램 성능 개선

```SQL
INSERT INTO TARGET_T
SELECT * FROM SOURCE_T;

COMMIT;
```

\- 테이블을 nologging 모드로 전환한 상태에서 Insert 문에 append 힌트 사용
\- 병령 DML을 활성화한 상태에서 insert 문에 parallel 힌트를 사용
\- 인덱스 및 제약을 해제한 상태에서 insert 문 수행

ARRAY PROCESSING은 성능 개선에 큰 효과가 있지만 INSERT INTO SELECT 보다 느리다.

31. DML 성능

```sql
-- 온라인 트랜잭션이 없는 야간에 대량 테이블 일괄 INSERT 하는 배치 프로그램

-- DELETE FROM TARGET_T;
TRUNCATE TABLE TARGET_T;

ALTER TABLE TARGET_T MODIFY CONSTRAINT TARGET_T_PK DISABLE DROP INDEX;

ALTER SESSION ENABLE PARALLEL DML;

ALTER TABLE TARGET_T NOLOGGING;


INSERT /*+PARALLEL(T1 4)*/ INTO TARGET_T T1
SELECT /*+FULL(T2) PARALLEL(T2 4)*/ *
FROM SOURCE_T T2;

COMMIT;

ALTER TABLE TARGET_T MODIFY CONSTRAINT TARGET_T_PK ENABLE NOVALIDATE;

ALTER TABLE TARGET_T LOGGING;
ALTER SESSION DISABLE PARALLEL DML;

```

delete 문을 사용하면 remo로그와 undo 를 생성하면서 레코드 단위로 삭제하믈 데이터가 많을 때 상당히 오랜 시간이 소요된다. 반면 TRUNCATE 문은 딕셔너리 상에서 익스텐트만 반환하는 방식을 사용하므로 대량 데이터도 빠르게 삭제할 수 있다.

DML 중에 제약 조건을 체크하고 인덱스를 관리하는 부하가 매우 크므로 작업 전에 제약을 해제하고 인덱스를 unusable 상태로 변경하면 성능을 크게 높인다.

SOURCE_T는 병렬로 읽지만 TARGET_T 테이브레 iNSERT 하 때는 qc 혼자서 처ㅣ한다.
병렬 dml을 활성화했지만, insert 무네 parallel 힌트를 사용하지 않았기 때문ㅇ다.

제대로 병렬 철를 하려면 insert 문에도 parallel 힌트를 추가해야 한다.

추가로, target_t 테이블을 nologging 모드로 전환하면 redo 로깅을 생략할 수 있어 더 빠르게 insert 할 수 있다.

32. 원격DB 배치

```sql
-- 새벽 시간에는 mytab 테이블에 온라인 트랜잭션이 거의 발생하지 않는다.
-- 새벽에 원격 rds 시스템으로부터 1,000만 건 정도의 데이터를 읽어 INSERT 하는
-- 배치(batch) 프로그램 성능을 개성하시오.

-- UPDATE문에서 C1조건절을 만족하는 데이터는 90% 이상이다.
-- MYTAB 테이블의 PK는 dt + id 이다.
-- 병렬 처리는 활용할 수 없다.

CREATE TABLE MYTAB_TEMP
AS
SELECT C0 AS ID,
C1,C2,C3,C4
FROM YOURTAB@RDS
WHERE 1 = 2;

ALTER TABLE MYTAB_TEMP ADD CONSTRAINT MYTAB_TEMP_PK PRIMARY KEY (ID);

DECLARE
  V_CT NUMBER;
BEGIN
  -- 1,000만건
  INSERT INTO MYTAB_TEMP
  SELECT C0, C1, C2, C3, C4
  FROM YOURTAB@RDS
  WHERE C0 IS NOT NULL
  AND C5 > 0;

  -- 90%이상의 데이터가 update
  UPDATE MYTAB_TEMP SET C4 = C4 + 1 WHERE C1 < TRUNC(SYSDATE);

  -- 배치 프로그램을 재실행할 경우를 대비해서 위한 delete

  DELETE FROM MYTAB WHERE DT = TO_CHAR(SYSDATE, 'YYYYMMDD');

  INSERT INTO MYTAB (DT, ID, C1,C2, C3, C4)
  SELECT TO_CHAR(SYSDATE, 'YYYYMMDD'), A.* FROM MYTAB_TEMP A;

  V_CNT := SQL%ROWCOUNT;
  INSERT_LOG (SYSDATE, 'INSET MYTAB_TEMP', 'SUCCESS', V_CNT || 'ROWS');

  COMMIT;

  EXCEPTION
    WHEN DUP.VAL_ON_INDEX THEN
      INSERT_LOG(SYSDATE, 'INSET MYTAB_TEMP', 'FAIL', '중복 데이터');
  END;
  /

  DROP TABLE MYTAB_TEMP;
```

대량 테이블에서 90%이상 데이터를 Redo와 Undo를 생성하면서 건건이 update 하려면 상당히 오랜 시간이 소요된다.

update를 따로할 필요없이 mytab_temp 테이블을 생성할 때 아예 변경된 값을 입력하면 된다.
CTAS 문으로 데이터를 입력하므로 direct path insert 기능이 작동하며, Nologging 옵션을 지정하였으므로 REdo 로그를 생성하지 않는다.

update를 따로 하지 않으므로 Undo 생성량도 줄일 수 있다.

최종적으로 MYTAB 테이블에 데이터를 입력할 때는 온라인 트랜잭션이 발생할 수도 있으므로 DIRECT PATH INSERT 기능을 활용할 수 없다.

MYTAB_TEMP 테이블에 pk 제약을 생성한 상태에서 대량 데이터를 Insert 하면 성능이 느리다.

Id에 중복값이 존재하는 지확인한 후에 mytab 테이블에 입력하도록 프로그램을 수정하면
pk 제약을 생성하지 않아도 된다.

중복값으로 mytab 데이터 적제에 실패한 경우, mytab_temp 데이터를 정제한 후 수작업으로 재적재하는 업무 규칙을 상정했다.

yourtab@rds 데이터를 정제한 후 재적재 하는 것이 업무규칙이라면,데이터를 가져오기 전에 중복값 존재 여부를 확인할 수 있다.

```sql
-- 새벽 시간에는 mytab 테이블에 온라인 트랜잭션이 거의 발생하지 않는다.
-- 새벽에 원격 rds 시스템으로부터 1,000만 건 정도의 데이터를 읽어 INSERT 하는
-- 배치(batch) 프로그램 성능을 개성하시오.

-- UPDATE문에서 C1조건절을 만족하는 데이터는 90% 이상이다.
-- MYTAB 테이블의 PK는 dt + id 이다.
-- 병렬 처리는 활용할 수 없다.

CREATE TABLE MYTAB_TEMP
AS
SELECT C0 AS ID,
C1,C2,C3,
(CASE WHEN C1 < TRUNC(SYSDATE) THEN C4 + 1 ELSE C4 END) AS C4
FROM YOURTAB@RDS
WHERE C0 IS NOT NULL
AND C5 > 0;

-- ALTER TABLE MYTAB_TEMP ADD CONSTRAINT MYTAB_TEMP_PK PRIMARY KEY (ID);

DECLARE
  V_CT NUMBER;
BEGIN

-- ID에 중복 값이 있는지 확인
SELECT CONUT(*) INTO V_CNT
FROM (
  SELECT ID
  FROM MYTAB_TEMP
  GROUP BY ID
  HAVING COUNT(*) > 1
);

IF V_CNT > 0 THEN
  INSERT_LOG(SYSDATE, 'INSET MYTAB_TEMP', 'FAIL', '중복 데이터');
ELSE
  -- 배치 프로그램을 재실행할 경우를 대비해서 위한 delete
  DELETE FROM MYTAB WHERE DT = TO_CHAR(SYSDATE, 'YYYYMMDD');

  INSERT INTO MYTAB (DT, ID, C1,C2, C3, C4)
  SELECT TO_CHAR(SYSDATE, 'YYYYMMDD'), A.* FROM MYTAB_TEMP A;

  V_CNT := SQL%ROWCOUNT;
  INSERT_LOG (SYSDATE, 'INSET MYTAB_TEMP', 'SUCCESS', V_CNT || 'ROWS');
END IF;

  COMMIT;
END;
  /

DROP TABLE MYTAB_TEMP;
```

33. DML 튜닝

```sql
-- 야간 배치 프로그램에서 수행하는 아래 update 문을 튜니하고, 정확히 원하는 실행계획이 나오도록 조인 순서와 방식, 인덱스 힌트를 기술하시오

-- 데이터
-- 고객 100만명
-- 미성년자(성인여부 = 'N') 2%
-- 법정대리인을 등록한 미성년자 50%

-- 인덱스 구성

-- 고객_pk : 고객번호
-- 고객_X1 : 고객명
-- 고객_x2 : 연락처
-- 고객_X3: 법정대리인_고객번호

UPDATE 고객 c
set 법정대리인_연락처 =
nvl(
  (
    select
    연락처
    From 고객
    where 고객번호 = c.법정대리인_고객번혼
  ), c.법정대리인_연락처
)
where 성인여부 = 'N'
```

법정대리인을 등록하지 않은 50% 의 미성년 고객까지 모두 update 하는 문제점이 있다.
필요 이상의 데이터를 update 하는 데 따른 i/o, redo, undo 증가도 문제지만 불필요한 Lock 경합을 유발할 수 있다.

EXISTS 서브쿼리를 추가하면 법정대리인을 등록한 미성년 고객만 update할 수 있어 가장 큰 문제점을 해결할 수 있다.

하지만 같은 데이터를 두 번 조회하는 비효율이 있고, 변경되지 않을 법정대리인 연락처를 일괄 update 해 lock 경합을 유발하는 문제가 남는다.

```sql
UPDATE 고객 c
set 법정대리인_연락처 = (
  select 연락처 from 고객 where 고객번호 = c.법정대리인_고객번혼
)
where 성인여부 = 'N'
and exists(
  select /*+unnnest nl_sj*/
  'X'
  from 고객
  where 고객번호 = c.법정대리인_고객번혼
  )
```

이때 수정가능 조인 뷰 또는 merge 문을 활용하면 효과적이다.

법정대리인을 등록한 미성년 고객만 update 할 수 있고, p.연락처 <> C.법정대리인\_연락처

조건을 추가해 법정대리인 연락처가 변경된 데이터만 정확하게 update 할 수 있다.

법정대리인\_고객번호 Is not null 조건을 추가해주면, 불필요한 조인 액세서를 줄일 수 있고 고객\_x3 인덱스도 사용할 수 있다.

고객\_x3 인덱스를 사용하면 full scan 처리 되겠지만, 오라클의 경우 고객\_X3 인덱스에 법정대리인 고객번호를 입력한 데이터만 저장하므로, 불필요한 테이블 엑세스는 없다.

오라클 옵티마이저는 법정대리인\_고객번호 is nut null 조건을 자동으로 추가해 준다.

미성년이면서 법정대리인을 등록하지 않은 고객은 1%에 불과한 데다 법정대리인 연락처가 변경된 고객은 극소수일 테니 NL조인이 유리하다.

```sql
UPDATE
(
  SELECT /*+LEADING(C) USE_NL(P) INDEX(C 고객_x3) INDEX(P 고객_PK)*/
  C.법정대리인_연락처, P.연락처
  FROM 고객 C, 고객 P
  where 성인여부 = 'N'
  and c.법정대리인_고객번호 is not null
  and p.고객번호 = c.법정대리인_고객번호
  and p.연락처 <> C.법정대리인_연락처
)
SET 법정대리인_연락처 = 연락처

MERGE /*+LEADING(C) USE_NL(P) INDEX(C 고객_x3) INDEX(P 고객_PK)*/
INTO 고객 C
USING 고객 P
  ON (
    C.성인여부 = 'N'
    and c.법정대리인_고객번호 is not null
    AND p.고객번호 = c.법정대리인_고객번호
  )
  WHEN MATCHED THEN UPDATE
  SET C.법정대리인 연락처 = P.연락처
  WHERE C.법정대리인_연락처 <> P.연락처
```

34. 배치 Dml 튜닝

```sql
-- 데이터
-- 상품재고 101,382 rows
-- 상품재고이력 88,370,445 rows

-- 인덱스 구성
-- 상품재고_PK : 상품번호
-- 상품재고이력_PK : 상품번호 + 변경일자 + 변경순번

-- 업체코드가 Z이고 가용제고량이 0이고 가상제고수량이 0인 레코드의 품질 유지일의 품질유지일을 오늘날짜에서 상품제고이력의 최근 변경일자를 뺀 값으로 업데이트
UPDATE 상품재고 T
  SET T.품질유지일 =
    NVL(
    (
      SELECT
      TRUNC(SYSDATE) - TO_DATE(MAX(A.변경일자), 'YYYYMMDD')
      FROM 상품재고이력 A, 상품재고 B
      WHERE A.상품번호 = B.상품번호
        AND B.업체코드 = 'Z'
        AND B.가용재고량 = 0
        AND NVL(B.가상재고수량, 0) <= 0
        AND A.상품번호 = T.상품번호
        GROUP BY A.상품번호
      )
      , T.품질유지일)
    WHERE T.업체코드 = 'Z'
    AND T.가용제고량 = 0
    AND NVL(T.가상재고수량, 0) <= 0

-- UPDATE STATEMENT
--  UPDATE              상품재고
--    TABLE ACCESS FULL 상품재고                  85198
--    SORT GROUP BY NOSORT                         1
--      NESTED LOOPS                               1
--        TABLE ACCESS BY INDEX ROWID OF 상품재고    1
--          INDEX UNIQUE SCAN 상품재고_PK            1
--        INDEX RANGE SCAN 상품재고이력_PK            1

UPDATE /*+Leading(t)*/ 상품재고 T
  SET T.품질유지일 =
    (
      SELECT
      TRUNC(SYSDATE) - TO_DATE(MAX(A.변경일자), 'YYYYMMDD')
      FROM 상품재고이력
      WHERE 상품번호 = T.상품번호
    )
    WHERE T.업체코드 = 'Z'
    AND T.가용제고량 = 0
    AND NVL(T.가상재고수량, 0) <= 0
    AND EXISTS (
      SELECT /*+unnest nl_sj*/ 'X'
      FROM 상품제고이력
      WHERE 상품번호 = T.상품ㅂㄴ호
    )

MERGE INTO 상품재고 x
USING (
  SELECT A.상품번호, B.신규_품질유지일
  FROM 상품재고 A
  , (
    SELECT 상품번호
    , TRUNC(SYSDATE) - TO_DATE(MAX(A.변경일자), 'YYYYMMDD')
    FROM 상품재고이력
    GROUP BY 상품번호
  ) B
  WHERE A.업체코드 = 'Z'
    AND A.가용제고량 = 0
    AND NVL(T.가상재고수량, 0) <= 0
    AND a.상품번호 = b.상품번호
    AND a.품질유지일 <> B.신규_품질유지일
) Y
ON (x.상품번호 = y.상품번호)
WHEN MATCHED THEN UPDATE SET X.품질유지일 = Y.신규_품질유지일;
```

상품제고 테이블을 스칼라 서브쿼리에서 다시 조인할 이유가 없다.
불필요햔 조인을 제거하고 나면 FIRST ROW 또는 TOP N STOPKEY 알고리즘이 작동할 수 있어 효과적이다.

10만여건중 80%에 해당하는 데이터를 메번 Update 함으로써 row lock 경합이 자주 발생한다.

80% 데이터가 실제 변경된다면 어쩔 수 없지만 1시간 주기 batch 를 고려하면 거의 변경되지 않는다고 봐야한다.

merge 문을 이용하면 품절유지일이 변경된 데이터만 Update 하게 함으로써 lock 경합을 최소화 할 수 있다.

sql 문장만 보면 상품재고 데이터를 두 번 읽는 것이 비효율적이라고 생각할 수 있지만,
품질유지일이 변경된 소수 데이터만 액세스하므로 실제 비효율은 크지않다.

---

# 데이터베이스 call 최소화

35. 데이터베이스 call

애플리케이션 커서를 캐싱하지 않는 한, parse call은 바인드 변수를 사용해도 매번 일어난다.

parse call 단계에서 하드 파싱을 하게 되면 딕셔너리를 조회하는 과정에 recursive call이 발생한다.

DML은 parse call 단계를 제외하면 모든 i/o가 execute call 단계에서 일어난다.

select 문은 대부분 i/o가 Fetch call 단계에서 일어난다.

36. 데이터베이스 Call

parse call 단게에서 하드 파싱을 하게 되면 딕셔너리를 조회하는 과정에서 Recursive call이 발생한다.

DB 저장형 프로시저는 EXecute call 단계에서 수행되며, 그 안에 내장된 Sql을 실행할 때 recursive call이 발생한다. dml 문에 사용한 db 저장형 함수도 execute call 단계에서 수행된다.

SELECT 문에 사용한 DB 저장형 함수는 execute 단계에서 수행되는 일부 예외 케이스를 제외하면 대부분 FETCh 단계에서 수행된다. db 저장형 함수에 내장된 sql을 실행할 때 recursive call 이 발생한다.

user call 은 네트워크를 경유하므로 recursive call 보다 성능 부하가 훨씬 크다.

37. database call

```sql
-- call count cpu elapsed disk query current rows
-- parse    1
-- execute  5000
-- fetch    10000              40000         100000
-- misses in library cache during parse : 1
```

fetch call 이 10000 번 발생했고 블록 i/o와 처리 건수가 모두 fetch 단계에 나타났으므로 select 문에 대한 트레이스 결과다.

5000번 실행하는동안 parse call 이 1회 발생한 사실을 통해 애플리케이션 커스를 캐싱한 상태에서 sql을 실행했음을 알 수 있다.

100000 로우를 읽는 동안 10000번 fetch 했으므로 array size 는 10이다.

5000번 실행하는 동안 블록을 40000 개 읽었으므로 한 번 실행할 때 ㅍ평균 8개 블록을 읽었다.

38. database call

바인드 변수를 사용한다고 데이터베이스 Call이 줄어들지 않는다. 바인드 변수를 사용해도 애플리케이션 커서를 캐싱하지 않는 한 parse call은 매번 일어나기 때문이다.
ARRAY SIZE를 늘리거나 페이징 처리 기법을 사용하면 FETCH CALL을 줄일 수 있고, ARRAY PROCESSING을 활용하면 execute call을 줄일 수 있다.

39. one sql

```sql
-- 인덱스 구성
-- 고객_pk: 고객번호
-- 고객_x1: 회원사코드
-- 계좌_pk : 계좌번호
-- 계좌_x1 : 고객번호
-- 일별예수금잔고_pk : 계좌번호 + 기준일자

DECLARE
  V_CNT NUMBER DEFAULT 0;
  V_BASE_DT VARCAHR2(8);
BEGIN
  FOR C IN (
    SELECT B.계좌번호
      FROM 고객 a, 계좌 b
      where a.회원사코드 like '8%'
      and b.고객번호 = a.고객번호
  )

  lOOP
    V_BASE_DT := GET_BASE_DT(C.계좌번호);

    DELETE FROM 일별예수금잔고
    WHERE 기준일자 = V_base_dt
    and 계좌번호 = c.계좌번호;

    v_cnt := v_cnt + sql%rowcount;

    commit;
  end loop;
end


DECLARE
  V_CNT NUMBER DEFAULT 0;
BEGIN
  DELETE
    FROM 일별예수금잔고 A
    , (
      SELECT B.계좌번호
      FROM 고객 a, 계좌 b
      where a.회원사코드 like '8%'
      and b.고객번호 = a.고객번호
    ) C
    WHERE A.기준일자 = GET_BASE_DT(C.계좌번호);
    AND A.계좌번호 = C.계좌번호

    v_cnt := v_cnt + sql%rowcount;
    commit;
end

DECLARE
  V_CNT NUMBER DEFAULT 0;S
BEGIN
  DELETE
  FROM 일별예수금잔고
  WHERE (계좌번호, 기분일자) IN
  (
    SELECT B.계좌번호
    FROM 고객 a, 계좌 b
    where a.회원사코드 like '8%'
    and b.고객번호 = a.고객번호
  );
  v_cnt := v_cnt + sql%rowcount;
  commit;
```

절차적인 루프 처리에 의해 많은 데이터 베이스 Call을 발생시키는 대표적인 사례이다.
ONE SQL로 구현하면 단 한 번의 데이터 베이스 call로 처리하므로 성능 개선에 큰 도움이 된다.

40.

```sql
-- 수납
-- # 수납일자 : Varchar2(8)
-- # 고객ID : NUMBER
-- * 수납금액 : NUMBER

-- 은행입금내역
-- # 입금일시 : DATE
-- # 고객ID : NUMBER
-- # 은행코드 : VARCHAR2(2)
-- * 입금액 : NUMBER

-- 수납 데이터 보관기간은 10년
-- 은행입금내역의 보관기간은 일주일
-- 은행입금내역 테이블에서 입금일시 조건을 만족하는 데이터는 20만 건
-- 은행입금내역을 고객ID로 GROUP BY 한 결과는 10만건 -- 고객 10만명

-- 인덱스 구성
-- 수납_pk : 수납일자 + 고객id
-- 은행입금내역_pk : 입금일시 _+ 고객id + 은행코드

declare
  1_수납금액 number;
begin
  -- 100000 row
  for c in (
    select 고객id, Sum(입금액) 입금액
    from 은행입금내역
    where to_char(입금일시, 'yyyymmdd') = '20210329'
    group by 고객id
  )
loop
  begin
    -- l_수납금액 : 고객별로 수납일자에 수납한 금액
    select 수납금액 into l_수납금액
    from 수납
    where 고객id = c.고객id
    and 수납일자 = 20210329
    execute immediate
    'update 수납 set 수납금액 = ' || c.입금액 ||
    'where 고객id = ' || c.고객id ||
    'and 수납일자 = 20210329';
exception
  when no_data_found then
    execute immediate
      'insert into 수납(고객id, 수납일자, 수납금액) values (' ||
      c.고객id || ', 20210329, '|| c.입금액 || ')';
  end
  commit;
  end loop;
end
```

```sql
update 수납
set 수납금액 =
(
   select sum(입금액) 입금액
    from 은행입금내역
    where to_char(입금일시, 'yyyymmdd') = '20210329'
    group by 고객id
)
where 고객id = c.고객id
and 수납일자 = 20210329;

-- 존재하지 않는 고객일때
insert into 수납(고객id, 수납일자, 수납금액)
Values (c.고객id, 20210329, c.입금액);
```

41. ARRAY PROCESSING

ARRAY PROCESSING 이 성능 효과를 발휘하는 핵심 원리는 데이터베이스 call을 줄이는 데 있다.

네트워크를 경유하는 프로그럼은 PL/SQL 프로그램보다 데이터베이스 call 부하가 더 크다.
따라서 array processing을 적용했을 때 성능 개선 효과가 더 크다.

ARRAY 단위를 늘리면 성능이 좋아지지만 개선율은 점차 감소한다. 일정 수준을 넘어서면 개선 효과는 없고 지원만 많이 사용하므로 적정 크기로 설정해야 한다.

ARRAY PROCESSING 효과를 극대화하려면 연속된 일련의 과정을 모두 ARRAY 단위로 처리해야 한다.

세 개의 단위 작업 중 첫 번째와 세 번째에만 ARRAY PROCESSING을 적용하면,
두 번째 작업이 병목구간으로 작용한다.

42. FETCH CALL 최소화 방안

- 부분범위 처리를 활용한다.
- 화면 페이징 처리 기법을 활용한다.
- array size를 늘린다.

sdu, tdu 등 세션이나 네트워크 프로토콜 레이어에서 사용하는 패킷 크기를 늘리면
서버 / 클라이언트 간 통신 횟수를 줄일 수는 있다.
하지만 이는 오라클이 '한 번의 FETCH CALL' 내에서 전송할 데이터 량이 많을 때 일정량씩 나눠 전송하는 단위이므로 FETCH CALL 횟수에는 영향을 주지 않는다.

43. 부분범위처리

서버 프로세스가 쿼리 집합을 한 번에 모두 전송하지 않고 클라이언트로 부터 fetch call이 올 때마다 일정량 나눠서 전송하는 것을 '부분부붐 처리' 라고 한다.

부분범위 처리를 활용한 튜닝은 오라클뿐만 아니라 데이터를 일정량씩 나눠서 전송하는 모든 dbms에 활용할 수 있다.

한 번의 FETCH CALL을 처리하고 나면 서버 프로세스는 CPU를 os에 반환한 상태에서 다음 fetch call을 기다린다.

array size를 작게 설정하거나 읽어야 할 데이터 범위에서 조건절을 만족하는 데이터가 많을 수록 운반 단위를 빨리 채워 응답속도가 빠르다.

44. DB I/O 및 네트워크 성능

MULTIBLOCK I/O 단위를 줄일 수록 FULL TABLE SCAN 시 I/O CALL 횟수가 늘어나낟.

테이블 익스텐트를 작게 설정하면 FULL TABLE SCAN 할 때 I/O CALL 횟수가 늘어날 수 있다.

ARRAY SIZE를 크게 설정할 수록 메모리에서 블록 읽는 횟수가 줄어든다.

SOU, TOU 등 네트워크 패킷을 작게 설정할수록 서버와 클라이언트 간 통신 횟수가 늘어난다.

FULL TABLE SCAN 할 때의 i/O CALL 횟수는 MULTIBLOCK I/O를 작게 설정할 수록 늘고, 크게 설정할수록 줄어든다

MULTI BLOCK I/O는 한 익스텐트 안에서 이루어진다. 즉, 한 익스텐트에 속한 마지막 블록을 읽었는데 아직 MULTIBLOCK I/O 단위를 채우지 못했어도 다음 익스텐트를 추가로 읽지 않는다. 따라서 작은 EXTENT로 구성된 테이블을 FULL TABLE SCAN 하면 I/O call이 더 많이 발생한다.

한 번의 fetch call에서 마지막 블록을 읽다가 운반 단위가 모두 차면 바로 데이터를 전송하며, 남은 데이터는 다음 fetch call에서 읽어서 전송하게 된다. 따라서 array size 를 작게 설정할 수록 한 블록에 여러 번에 걸쳐서 읽는 현상이 발생한다.

반대로 크게 설정하면 한 블록을 여러 번에 걸쳐 읽는 현상이 줄어든다.

45. 쿼리성능개선방안

코드명, 상품명, 고객명 처럼 값이 변하지 않는 속성을 출력할때, id 속성은 db에서 읽고 이름 속성은 어플리케이션 서버 레이어에 미리 캐싱해 둔 데이터를 조회함으로써 조인 부하를 줄인다.

인덱스 및 sql 튜닝만으로 만족스러운 성능을 내기 어려울 때, 상품명, 고객명처럼 값이 변하지 않는 속성은 반정규화로 거래 테이블에 미리 저장해둔다.

조회 결과집합을 한 번에 모두 출력하지 않고 페이징 처리를 활용한다면, 코드명, 상품명, 고객명 등은 화면에 출력하는 최종 데이터에 대해서만 조인하도록 구현한다.

코드명, 상품명, 고객명 등을 조회할 때 조인 대신 dB 저장형 함수를 사용하면 db Call 부하로 인한 성능은 오히려 더 느려진다.

46. DB 저장형 사용자정의함수/프로시저

가상머신 상에서 실행되는 INTERPRETING 언어이다.

호출 시마다 SQL 실행엔진과 PL/SQL 가상머신 사이에 context switching이 발생한다.

함수/프로시저에 내장된 Sql이 참조하는 테이블에 구조 변경, 인덱스 변경, 통계정보 재수집 등이 일어나면, 이후 최초 실행 시점에 재컴파일이 일어난다.

함수에 SQL이 내장돼 있으면, 함수 실행 횟수 만큼 RECURSIVE CALL 이 발생한다.

함수가 SELECT-LIST에 있다면, 결과집합 검수만큼 함수가 실행된다.

함수가 조건절에 있으면, 필터가 처리되는 건수만큼 함수가 실행된다.

47. DB CALL

```sql
create or replace function GET_상품명(p_상품번호 number) return varchar2
is
  l_상품명 상품.상품명%TYPE;
begin
  select 상품명 into l_상품명 from 상품 Where 상품번호 = p_상품번호;

  return l_상품명;
exception
  when others then
    return null;
end;
/

select 거래번호, 상품번호, GET_상품명(상품번호) as 상품명
From 거래
where 업체코드 = 'Z123'
and 거래일자 >= To_char(sysdate , 'YYYYMMDD')
```

메인 쿼리 결과 집합이 100건 이므로 EXECUTE CALL 과 FETCH CALL은 각각 100회 씩 발생한다.

sql 프로그램에 내장된 sql에 대해서는 오라클이 자동으로 커서를 캐싱하므로 parse call 은 최초 1회만 발생한다. 따라서 총 call 횟수는 201이다.

CALL 횟수는 SQL 트레이스의 call statistics 를 통해 확인할 수 있고, V$SQL 에서 SQL_ID를 확인한 후 아래 쿼리를 통해서 확인할 수 있다.

```SQL
SELECT SQL_TEXT, PARSE_CALL, EXECUTIONS, FETCHES
FROM V$SQL
WHERE SQL_ID = :SQL_ID

-- 100행이 선택되었습니다.
```

48. DB 저장형 함수 성능 저하

DB 저장형 함수를 C, java, vb 등 에플리케이션 함수로 전환하면, Recursive call 대신 user call이 발생하므로 성능이 더 느려진다.

CASE 문이나 조인문을 활용함으로써 db 저장형 함수를 제거하면, 함수 호출 및 REcursive call이 발생하지 않아 성능 개선에 도움이 된다.

deterministic 함수로 전환하면 캐싱효과가 나타난다.

함수에 참조하는 테이블 데이터가 자주 변하지 않는다면, result 캐시 기능도 도움이 된다.

49. 부분범위처리

```sql
-- 인덱스 구성
-- 게시판_pk : 글번호
-- 게시판_X1 : 게시판코드 + 등록일시

SELECT 글번호, 등록일시, 작성자id, Get_wirter(작성자id) 작성자명
, code_nm('418', 게시글분류코드) 게시글분류명
FROM 게시판 B
WHERE 게시판코드 = :BBS_CD
AND 등록일시 between trunc(sysdate-2) and sysdate
ORDER BY 등록일시 desc

```

부분범위 처리를 활용하면 함수 호출 부하를 최소화 할 수 있따.
부분범위 처리를 활용하려면 소트 연산을 생략할 수 있어야 하는데 orer by를 제거할 필요는 없다. 게시판\_x1인덱스를 사용하면 소트연산이 자동으로 생략되기 때문이다.

페이징 처리 활용도 함수 호출 부하를 최소화하는데 큰 도움이 된다.

함수에 스칼라 서브쿼리를 씌워서 실행하면 함수 호출 부하를 줄이는데 큰 도움이 된다.
스칼라 서브쿼리에 캐싱 기능이 작동하기 때문이다. 단, 함수에 입력하는 값 종류가 많지 않아야 한다.

함수를 풀어서 조인문으로 변경하는 것이 함수 호출 부하를 줄이는 근본적인 해법이다.
조인으로 변경할 경우, nL 조인이 가장 효과적이다.
부분범위처리가 가장 잘 작동하기 때문이다. 해시 조인은 소트 연산을 생략할 수 없다.

50. RECURSIVE CALL

- 스칼라 서브쿼리를 이용한 함수 결과 캐싱

스칼라 서브쿼리에 대한 캐싱인 SQL 단위로 이루어지므로 캐싱 효과가 가장 좋다.

- DETERMINISTIC 함수 캐싱

DETERMINISTIC 함수에 대한 캐싱은 FETCH CALL 단위로 이루어진다.
따라서 FETCH CALL 이 많으면 같은 입력 값에 대한 recursive call 횟수도 많아진다.

- RESULT 캐시
  스칼라 서브쿼리 및 dETERMINISTIC 함수 결과는 PGA에 캐싱되지만, RESULT 캐시는 SGA 영억에 캐싱된다. 따라서 데이터를 읽고 쓸 때마다 래치 획득해야 하는 부담이 있다.

- NATIVE 컴파일
  NATIVE 컴파일 기능을 활용하면 인터프리팅 하는 부하를 줄여주지만, CONTEXT SWTICHING과 RECURSIVE CALL 에 대한 부하는 줄여주지 못한다

51. READ CONSISTENCY

deterministic 함수는 FETCH CALL 단위로 캐싱하므로 함수 결과의 일관성을 보장하지 않는다.

함수를 스칼라 서브쿼리에 실행할 때의 캐싱 효과는 SQL 수행을 마칠 때 까지 유효하므로 일관성을 보장할 것 같지만 그렇지 않다.

각 입력값에 대한 첫 번째 함수 호출이 일어날 때까지의 시간차 때문에 보장이 어렵고 모든 값을 다 캐싱할 수 없다는 점때문에도 보장하기 어렵다.

스칼라 서브쿼리 조인은 일관성을 보장한다. 즉, 중간에 값이 변하더라도 쿼리 시작 지점 기준으로 일관된 데이터를 출력한다.

52.

```sql
-- 회원_x1 : 생년월일
-- 회원_x2 : 생년월일 + 전화번호
-- 회원_x3 : 생년월일 + 회원명 + 전화번호
-- 회원_x4 : 전화번호

select *
from 회원
where 생년월일 like '1979%'
and 전화번호 = encryption(:phone)
```

DB 저장형 함수에 대한 조건절이 필터 조건이면 필터링 횟수만큼 수행되고, 인덱스 액세스 조건이면 단 1회만 수행된다.

53. distinct

```sql
-- 휴가기록 : 600개 블록에 5만여 건을 저장한 소형 테이블
-- GET_USERNAME : 입력받은 사원 ID로 사원 테이블을 조회해서 사원명을 반환하는 함수

select distinct get_username(사원ID)
FROM 휴가기록
where 휴가일자 >= add_monts(sysdate, -3);

-- select statement
--    hash unique
--      table access full 사원
```

튜닝 전 SQL은 함수를 수행해서 반환된 값 기준으로 중복 제거한다.

따라서 휴가일자 조건을 만족하는 결과 건수만큼 함수를 반복해서 수행한다.

SQL을 아래와 같이 수정하면, 사원 ID로 group by 한 결과 집합 함수를 적용하므로 함수 수행 횟수를 최소화할 수 있다. 동명이인이 있을 수 있으므로 group by 후에 distinc 연산을 수행해 줘야 한다.

```sql

select distinct get_username(사원ID)
FROM 휴가기록
where 휴가일자 >= add_monts(sysdate, -3);
group by 사원id;

-- select statement
--    hash unique
--      hash group by
--        table access full 사원
```

# 파티셔닝

1. 파티셔닝

테이블을 파티셔닝하면 성능 향상 및 경합 분산에 도움이 되고, 백업 및 복구, 대량 데이터 변경 및 삭제 등을 파티션 단위로 빠르게 처리할 수 있어 가용성이 향상된다.
테이블을 파티셔닝 하면 저장 공간 측면에서는 오히려 효율성이 떨어진다.
여유 공간을 세그먼트 단위로 관리하기 때문이다.

2. RANGE 파티션

파티션 기준으로 여러 컬럼을 선택할 수 있으며, 문자형 컬럼도 선택할 수 있다.
입력 공간을 찾지 못해 에러가 발생하는 현상을 방지하려면 MAXVALUE 파티션을 추가해야 한다.

3. PARTITION 명령어

```sql

-- 주문 테이블을 반기별로 파티셔닝 한다.
-- 주문 테이블에 입력하려고 백업해 둔 임시테이블에는 2020년 1월 부터 2021년 10월까지의 주문 데이터가 입력돼 있음
-- 예상치 못한 주문일시가 입력되더라도 에러가 발생하지 않아야 함
-- 파티션 명명 규칙은 자유롭게 지정

CREATE TABLE 주문 (
  주문번호 NUMBER
  , 주문일시 DATE
  , 고객ID VARCHAR2(5)
  , 주문금액 NUMBER
)

PARTITION BY RANGE(주문일시)
(
  PARTITION P2020_H1 VALUES LESS THEN(TO_DATE('20200701', 'YYYYMMDD'))
  ,PARTITION P2020_H2 VALUES LESS THEN(TO_DATE('20210101', 'YYYYMMDD'))
  ,PARTITION P2021_H1 VALUES LESS THEN(TO_DATE('20210701', 'YYYYMMDD'))
  ,PARTITION P2021_H2 VALUES LESS THEN(TO_DATE('20220101', 'YYYYMMDD'))
  ,PARTITION P9999_MX VALUES LESS THEN MAXVALUE
)
```

4. LIST PARTITION

\- 사용자가 지정한 불연속적인 값의 목록으로 데이터를 분할하고자 할 때 사용한다.
\- 데이터를 시도별로 파티셔닝했다면, 부산 지역에 대량 변경이나 백업 또는 복구가 진행되는 동안 서울 지역에는 조회, 변경, 삭제를 정상적으로 진행할 수 있다.
\- 입력 공간을 찾지 못해 에러가 발생하는 현상을 방지하려면 Default 파티션을 추가해야 한다.
\- list 파티션은 단일 컬럼으로만 파티션 할 수 있다.

5. HASH PARTITON

\- DML 경합을 분산하는데 큰 도움이 된다.
\- 파티션 기준으로 여러 컬럼을 선택할 수 있다.
\- 입력 공간을 찾지 못해 에러가 발생하는 현상은 발생하지 않는다.

RANGE, LIST 파티션은 파티션 기준을 사용자가 직접 지정하므로 특정 파티션에 데이터가 몰리지 않도록 구성할 수 있다.

하지만 HASH 파티션은 DBMS가 정한 해시 알고리즘에 따라 임의로 데이터를 분할하므로 값의 분포가 고르지 않을 때 특정 파티션에 데이터가 몰리는 현상이 생길 수 있다.

6. 파티션 특징

RANGE 파티션은 주기적으로 신규 파티션을 추가해야하는 관리적 부담이 있다.

list파티션에 대한 파티션 prunning 은 between 조건일 때도 작동한다.

HASH 파티션에 대한 파티션 PRUNING은 = 조건 또는 IN-조건일 때만 작동한다.

HASH 파티션은 특정 파티션에 데이터가 몰리는 현상이 생길 수 있따.

7. subpartition

```sql
CREATE TABLE 주문(주문번호 NUMBER, 주문일자 VARCHAR2(8), 고객ID VARCHAR2(5), ...)

PARTITION BY RANGE(주문일자)
SUBPARTITION BY HASH(고객ID) SUBPARTITIONS 8
(
  PARTITION P2020_Q1 VALUES LSEE THAN('20200401'),
  PARTITION P2020_Q1 VALUES LSEE THAN('20200701'),
  PARTITION P2020_Q1 VALUES LSEE THAN('20201001'),
  PARTITION P2020_Q1 VALUES LSEE THAN('20210101'),
  PARTITION P2020_Q1 VALUES LSEE THAN('20210401'),
  PARTITION P2020_Q1 VALUES LSEE THAN(MAXVALUE),
)
SELECT * FROM 주문
WHERE 주문일자 BETWEEN '20200701' AND '20200930'
```

주문일자 기준으로 분기별 range 파티셔닝 했고, 각 파티션을 고객id 기준으로 8개씩 해시 파티셔닝 했다. 따라서 2020녀 3분기 에 속한 서브 파티션 세그먼트는 8개다

8. SUBPARTITION

```SQL
CREATE TABLE 주문(주문번호 NUMBER, 주문일자 VARCHAR2(8), 고객ID VARCHAR2(5), ...)

PARTITION BY RANGE(주문일자)
SUBPARTITION BY HASH(고객ID) SUBPARTITIONS 8
(
PARTITION P2020_Q1 VALUES LSEE THAN('20200401'),
PARTITION P2020_Q1 VALUES LSEE THAN('20200701'),
PARTITION P2020_Q1 VALUES LSEE THAN('20201001'),
PARTITION P2020_Q1 VALUES LSEE THAN('20210101'),
PARTITION P2020_Q1 VALUES LSEE THAN('20210401'),
PARTITION P2020_Q1 VALUES LSEE THAN(MAXVALUE),
)
SELECT \* FROM 주문
WHERE 고객ID = :CUST_ID;

```

주문일자 기준으로 분기별 range 파티셔닝 했고, 각 파티션을 고객id 기준으로 8개씩 해시 파티셔닝 했다.
6개 RANGE 파티션별로 :CUST_ID 값에 해당하는 해시 서브 파티션은 각 1개씩이다.
따라서 고객 id 조건에 대해 읽어야할 파티션 세그먼트는 총 6개다.

9. SUBPARTITION

```SQL
CREATE TABLE 주문(주문번호 NUMBER, 주문일자 VARCHAR2(8), 고객ID VARCHAR2(5), ...)

PARTITION BY RANGE(주문일자)
SUBPARTITION BY HASH(고객ID) SUBPARTITIONS 8
(
PARTITION P2020_Q1 VALUES LSEE THAN('20200401'),
PARTITION P2020_Q1 VALUES LSEE THAN('20200701'),
PARTITION P2020_Q1 VALUES LSEE THAN('20201001'),
PARTITION P2020_Q1 VALUES LSEE THAN('20210101'),
PARTITION P2020_Q1 VALUES LSEE THAN('20210401'),
PARTITION P2020_Q1 VALUES LSEE THAN(MAXVALUE),
)
SELECT \* FROM 주문
WHERE 고객ID = :CUST_ID
주문일자 BETWEEN '20200701' AND '20201231'

;

```

주문일자 기준으로 분기별 range 파티셔닝 했고, 각 파티션을 고객id 기준으로 8개씩 해시 파티셔닝 했다.

2020년 3분기 와 2020년 4분기에 속한 16개 서브 파티션 중 :cust_id 값에 해당하는 것은 분기별로 1개씩이므로 총 2개 파티션 세그먼트를 읽는다

10. PARTITOIN PLUNING

파티션을 통해 SQL 성능을 향상해 주는 핵심 원리는 PARTITION prunning or elimination 에 있으며, 이는 SQL 하드파싱이나 실행 시점에 SQL 조건절을 분석해서 읽지 않아도 되는 파티션 세그먼트를 액세스 대상에서 제외하는 기능이다.

11. PARTITION PLUNING

```SQL
SELECT /*+LEADING(A) USE_NL(B)*/
FROM A, B
WHERE A.NO = B.NO

--  OPERATION             NAME         PSTART   PSTOP
-- SELECT STATEMETN
--    NESTED LOOPS
--      TABLE ACCESS FULL A
--        PRATITION RANGE ITERATOR      KEY   KEY
--          TABLE ACCESS FULL B         KEY   KYE
```

기본 파티션 pruning에는 아래 두 가지가 있다.

\- 정적 파티션 Pruning

파티션 키 컬럼을 상수 조건으로 조회하는 경우 작동.
액세스할 파티션이 쿼리 최적화 시점에 미리 결정되는 것이 특징이다.
실행계획의 PSRART 와 PSTOP 컬럼에는 액세스할 파티션 번호가 출력된다.

\- 동적 파티션 PRUNING
파티션 키 컬럼을 바인드 변수로 조회하면 쿼리 최적화 시점에는 액세스할 파티션을 미리 결정할 수 없다.
실행 시점이 돼서야 사용자가 입력한 값에 따라 결정되며, 실행계획의 PSTOP 와 PSTOP 컬럼에
KEY라고 표시된다.

NL 조인 할때도 inner 테이블이 조인 컬럼 기준으로 파티셔닝 돼 있으면 동적 pruning이 작동한다.

실행계획의 PSTART / PSTOP 컬럼에 key라고 표시되었으므로 동적 파티션 pruning에 해당한다.

파티션 키 컬럼에 바인드 변수를 사용하거나 nL 조인의 inner 테이블이 파티셔닝 돼있을 때 동적 파티션 pruning이 작동한다.

12. 파티션 기능과 성능 향상

\- 파티션 키 컬럼을 가공하지 않는 것이 좋다.

인덱스 컬럼을 가공하면 인덱스 range scan이 불가능한 것처럼 파티션 컬럼을 가공하면
파티션 pRUNING이 불가능하다.

\- 가급적 실행계획에 PARTITION RANGE ALL 오퍼레이션이 나타나지 않도록 sQL을 작성한다.

파티션 pruning이 불가능할 때 실행계획에 PARTITION RANGE ALL 오퍼레이션이 나타난다.

\- 파티션 키가 문자형 일자 컬럼일때 LIKE 조건이던 BETWEEN 조건이던 성능 차이는 거의 없다.

파티션 키 컬럼이 LIKE 조건을 사용하면 불필요한 파티션을 읽는 현상이 생길 수 있으므로 읽어야할 범위를 정확히 명시하는 bETWEEN 조건을 사용하는 것이 좋다.

\- 정적 pruning 과 동적 pruing 간의 성능 차이는 거의 없다.

동적 PRUNING 하더라도 실행할 때마다 딕셔너리를 참조하면서 읽어야 할 파티션을 결정하는 것은 아니므로 정적 PRUNING 에 비해 성능 차이는 거의 없다.

13. PSTART, PSTOP

```sql

CREATE TABLE 주문 (
  주문번호 NUMBER
  , 주문일시 DATE
  , 고객ID VARCHAR2(5)
  , 주문금액 NUMBER
)

PARTITION BY RANGE(주문일시)
(
  PARTITION P2020_H1 VALUES LESS THEN(TO_DATE('20200701', 'YYYYMMDD'))
  ,PARTITION P2020_H2 VALUES LESS THEN(TO_DATE('20210101', 'YYYYMMDD'))
  ,PARTITION P2021_H1 VALUES LESS THEN(TO_DATE('20210701', 'YYYYMMDD'))
  ,PARTITION P2021_H2 VALUES LESS THEN(TO_DATE('20220101', 'YYYYMMDD'))
  ,PARTITION P9999_MX VALUES LESS THEN MAXVALUE
)

select count(*) from 주문
where 주문일자 between '20200701' and '20201231'

--  OPERATION             NAME         PSTART   PSTOP
-- SELECT STATEMENT
--  SORT AGGREGATE
--    PRATTITION RANGE INTERATOR
--      TABLE ACCESS FULL

```

파티션 키인 주문일자 검색 조건에 상수값을 사용했으므로 정적 파티션 pruning 이 작동한다.

여섯 개 파티션 중 세 번째와 네번째 파티션만 읽는다는것을 표시하기 위해 PSART 3 PSTOP 4가 나타난다.

14. PATITION RANGE ALL

```SQL
-- 읽게되는 파티션 개수
CREATE TABLE 주문(주문번호 NUMBER, 주문일자 VARCHAR2(8), 고객ID VARCHAR2(5), ...)

PARTITION BY RANGE(주문일자)
(
PARTITION P2020_Q1 VALUES LSEE THAN('20200401'),
PARTITION P2020_Q1 VALUES LSEE THAN('20200701'),
PARTITION P2020_Q1 VALUES LSEE THAN('20201001'),
PARTITION P2020_Q1 VALUES LSEE THAN('20210101'),
PARTITION P2020_Q1 VALUES LSEE THAN('20210401'),
PARTITION P2020_Q1 VALUES LSEE THAN(MAXVALUE),
)
SELECT \* FROM 주문
WHERE 고객ID = :CUST_ID
주문일자 BETWEEN 20201001 AND 20201231;

```

숫자형과 문자형을 비교할 때는 숫자형 기준으로 문자형이 자동 변환된다.
주문일자가 문자형인데 숫자형으로 검색하면 컬럼에 대한 자동 형변환이 발생한다.

```sql
WHERE TO_NUMBER(주문일자) BETWEEN 20201001 AND 20201231
```

파티션 컬럼을 가공하면 파티션 pRUNING이 불가능하다. 파티션 pruning이 불가능할 때 모든 파티션을 읽데 되며, 이를 표현하기위해 partition range all 오퍼레이션이 나타난다.

15. partitoin between

```SQL
CREATE TABLE 주문(주문번호 NUMBER, 주문일자 VARCHAR2(8), 고객ID VARCHAR2(5), ...)

PARTITION BY RANGE(주문일자)
(
PARTITION P2020_M2 VALUES LSEE THAN('20210201'),
PARTITION P2020_M3 VALUES LSEE THAN('20210301'),
PARTITION P2020_M4 VALUES LSEE THAN('20210401'),
PARTITION P2020_M5 VALUES LSEE THAN('20210501'),
PARTITION P2020_M6 VALUES LSEE THAN('20210601'),
PARTITION P2020_M7 VALUES LSEE THAN('20210701'),
PARTITION P2020_M999 VALUES LSEE THAN(MAXVALUE)
)
SELECT \* FROM 주문
WHERE
주문일자 lIKE '202103%';

```

문제에서 요규하는 데이터는 모두 m3 파티션에 저장돼 있다.

m2 파티션에 다음과 같은 데이터가 저장될 수 있따
20210300, 2021030+, 2021030- ...

이런 데이터는 M02에 저장되지만 조건을 만족한다. 따라서 실제 이런 데이터가 없더라도 m02 파티션 읽기를 생략할 수 없다.

between 조건을 사용하면, 위와 같은 데이터가 입력돼 있더라도 조건을 만족하지 않ㅇ므ㅡ로 정확히 m03 파티션만 읽는다.

불필요한 파티션을 읽는 부작용을 피하려면, 읽어야할 범위를 Between 조건으로 명확히 표현하는 것이 좋다.

16. LOCAL PARTITON INDEX의 장점

\- 인덱스 키와 파티션 키를 독립적으로 자유롭게 선택할 수 있다.

\- 테이블 파티션을 재구성 할때 인덱스가 unusable 상태로 변하지 않는다.
\- global 인덱스 보다 관리의 편의성이 높다.

테이블 파티션을 재구성(ADD DROP SPLIT EXCHANGE) 할때 비파티션 인덱스와 Global 파티션 인덱스는 unusable 상태로 변한다.
반면 lOCAL 파티션 인덱스는 unusable 상태로 변하지 않으며, 파티션도 자동으로 재구성되므로 관리의 편의성이 좋다.

\- 파티션 pruning에 의해 단일 파티션만 액세스 할 때, 비파티션 인덱스 보다 block i/o가 적개 발생한다.

루트에서 리프까지 dept가 낮기때문에 인덱스를 탐색할ㄷ 때 더 적은 블록을 읽는다.
local 인덱스는 테이블 파티션별로 인덱스를 생성하므로 비파티션 인덱스보다 크기가 작다.

17. partition index 유형

```SQL
CREATE TABLE 주문(주문번호 NUMBER, 주문일자 VARCHAR2(8), 고객ID VARCHAR2(5), ...)

PARTITION BY RANGE(주문일자)
(
  PARTITION P2020_Q1 VALUES LESS THAN(TO_DATE('20200401', 'YYYYMMDD')),
  PARTITION P2020_Q2 VALUES LESS THAN(TO_DATE('20200701', 'YYYYMMDD')),
  PARTITION P2020_Q3 VALUES LESS THAN(TO_DATE('20201001', 'YYYYMMDD')),
  PARTITION P2020_Q4 VALUES LESS THAN(TO_DATE('20210101', 'YYYYMMDD')),
  PARTITION P2020_MX VALUES LESS THAN(MAXVALUE)
)

CREATE INDEX 주문_X1 ON 주문(고객ID) LOCAL;
```

LOCAL 파티션 인덱스는 테이블 파티션 속성을 그대로 상속받는다.
따라서 테이블 파티션 키가 주문일시면 인덱스 파티션 키도 주문일시가 된다.
LOCAL 파티션 인덱스를 LOCAL 인덱스라고 줄여서 부르기도 한다.

LOCAL 파티션인덱스는 테이블과 정확히 1대1 대응을 갖도록 오라클 파티션을 자동으로 관리해 준다.

테이블 구성을 변경하더라도 인덱스를 사용자가 재생성할 필요가 없다

서비스를 중단하지 않고도 바로 작업할 수 있다. lOCAL 파티션 인덱스의 장점은 이처럼 관리 평의성에 있다.

주문\_x1은 local 인덱스이므로 파티션 키는 주문일시가 된다. 주문\_x1은 파티션 키(주문일자)가 인덱스 선두컬럼이 아니므로 LOCAL NONPREFIXED 파티션 INDEX 다

주문일시를 선두로 뒀다면 local prefixed 파티션 index이다.

18. partition index 유형

```SQL
-- 읽게되는 파티션 개수
CREATE TABLE 주문(주문번호 NUMBER, 주문일자 VARCHAR2(8), 고객ID VARCHAR2(5), ...)

PARTITION BY RANGE(주문일자)
(
  PARTITION P2020_Q1 VALUES LESS THAN(TO_DATE('20200401', 'YYYYMMDD')),
  PARTITION P2020_Q2 VALUES LESS THAN(TO_DATE('20200701', 'YYYYMMDD')),
  PARTITION P2020_Q3 VALUES LESS THAN(TO_DATE('20201001', 'YYYYMMDD')),
  PARTITION P2020_Q4 VALUES LESS THAN(TO_DATE('20210101', 'YYYYMMDD')),
  PARTITION P2020_MX VALUES LESS THAN(MAXVALUE)
)

CREATE INDEX 주문_X1 ON 주문(주문일시, 고객ID) GLOBAL;
PARTITION BY RANGE(주문일시)
(
  PARTITION P2020 VALUES LESS THEN ( TO_DATE('20200701', 'YYYYMMDD')),
  PARTITION P2020 VALUES LESS THEN ( TO_DATE('20210101', 'YYYYMMDD')),
  PARTITION P2020 VALUES LESS THEN ( MAXVALUE),
)
```

global 파티션 인덱스는 파티션을 테이블과 다르게 구성한 인덱스다.
구체적으로, 파티션 유형이 다르거나, 파티션 키가 다르거나, 파티션 기준 값 정의가 다른 겅우다.
비파티션 테이블이어도 인덱스는 파티셔닝할 수 있다.
글로벌 파티션 인덱스는 테이블 파티션 구성을 하는 순간 unusable 상태로 바뀌므로 곧바로 인덱스를 재생성해줘야한다. 그동안 해당 테이블을 사용하는 서비스를 중단해야한다

인덱스 파티션을 테이블 파티션과 다르게 정의하였으므로 GLOBAL 파티션 인덱스이다.
인덱스 파티션 키가 인덱스 선두 컬럼이므로 prefixed 파티션 인덱스이다.

19. partition index 유형

```SQL
-- 읽게되는 파티션 개수
CREATE TABLE 주문(주문번호 NUMBER, 주문일자 VARCHAR2(8), 고객ID VARCHAR2(5), ...)

PARTITION BY RANGE(주문일자)
(
  PARTITION P2020_Q1 VALUES LESS THAN(TO_DATE('20200401', 'YYYYMMDD')),
  PARTITION P2020_Q2 VALUES LESS THAN(TO_DATE('20200701', 'YYYYMMDD')),
  PARTITION P2020_Q3 VALUES LESS THAN(TO_DATE('20201001', 'YYYYMMDD')),
  PARTITION P2020_Q4 VALUES LESS THAN(TO_DATE('20210101', 'YYYYMMDD')),
  PARTITION P2020_MX VALUES LESS THAN(MAXVALUE)
)

CREATE INDEX 주문_X1 ON 주문(주문일시, 고객ID) GLOBAL
PARTITION BY RANGE(주문일시)
(
  PARTITION P2020_Q1 VALUES LESS THEN ( TO_DATE('20200401', 'YYYYMMDD')),
  PARTITION P2020_Q2 VALUES LESS THEN ( TO_DATE('20200701', 'YYYYMMDD')),
  PARTITION P2020_Q3 VALUES LESS THEN ( TO_DATE('20201001', 'YYYYMMDD')),
  PARTITION P2020_Q4 VALUES LESS THEN ( TO_DATE('20210101', 'YYYYMMDD')),
  PARTITION P9999_MX VALUES LESS THEN ( MAXVALUE),
)
```

인덱스를 테이블과 정확히 1:! 관계가 되도록 파티션하더라도 로컬 파티션은아니다.
오라클이 인덱스 파티션을 자동으로 관리하재주 않기때문이다. 모양은 로컬파티션이지만, 글로벌 파티션에 속한다.

인덱스 파티션 키가 인덱스 선두 컬럼이므로 PREFIXED 파티션 인덱스다. global 파티션 인덱스는 PREFIXED 만 지원한다. 주문 X1 인덱스를 고객\_ 주문일시로 순으로 구성하거나 고객id 단일 컬럼으로 구성하려고 한다면 애러가 발생한다.

20. partition index 유형

```SQL
-- 읽게되는 파티션 개수
CREATE TABLE 주문(주문번호 NUMBER, 주문일자 VARCHAR2(8), 고객ID VARCHAR2(5), ...)

PARTITION BY RANGE(주문일자)
(
  PARTITION P2020_Q1 VALUES LESS THAN(TO_DATE('20200401', 'YYYYMMDD')),
  PARTITION P2020_Q2 VALUES LESS THAN(TO_DATE('20200701', 'YYYYMMDD')),
  PARTITION P2020_Q3 VALUES LESS THAN(TO_DATE('20201001', 'YYYYMMDD')),
  PARTITION P2020_Q4 VALUES LESS THAN(TO_DATE('20210101', 'YYYYMMDD')),
  PARTITION P2020_MX VALUES LESS THAN(MAXVALUE)
)

CREATE UNIQUE INDEX 주문_PK ON 주문(주문번호);
ALTER TABLE 주문 add constraint 주문_pk primary key(주문번호) using index 주문_Pk;
```

인덱스를 파티셔닝하지 않았으므로 비파티션 인덱스다.
주문\_PK 인덱스를 테이블처럼 주문일시로 파티셔닝 할수없다.

UNIQUE 인덱스를 파티셔닝하려면, 파티션 키가 모두 인덱스 구성 컬럼이어야 한다,
주문\_PK를 파티셔닝하려면 구성 컬럼인 주문번호로 파티셔닝하는 수밖에 없다.

21. 인덱스 파티션 선택

```sql
CREATE TABLE 거래 (
  거래일자 VARCHAR2(8),
  계좌번호 NUMBER,
  주문매체코드 VARCHAR2(2),
  거래유형코드 VARCHAR2(4),
  거래량 NUMBER,
  거래금액 NUMBER
)
PARTITION BY RANGE(거래일자)
(
  PARTITION P2021_M01 VALUES LESS THAN ('20210201')
  ,PARTITION P2021_M02 VALUES LESS THAN ('20210301')
  ,PARTITION P2021_M03 VALUES LESS THAN ('20210401')
  ...
  ,PARTITION P2021_M012 VALUES LESS THAN ('20220101')
  ,PARTITION P9999_MX VALUES LESS THAN (MAXVALUE);
)

SELECT SUM(거래량), SUM(거래금액)
FROM 거래
WHERE 계좌번호 = :ACNT_NO
AND 거래일자 >= TO_CHAR(ADD_MONTHS(SYSDATE, -2), 'YYYYMMDD')
```

GLOBAL 파티션과 비파티션 인덱스는 테이블 가용성이 좋지 않다.
보관 기간을 초과한 과거파티션을 DROP 하면 UNUSABLE 상태로 전환되고, 인덱스를 재생성하는 동안 서비스를 중지해야 하기 때문이다.
따라서 성능에 문제가 되지 않느다면 가급적 LOCAL 파티션을 선택해야 한다

인덱스를 lOCAL PREFIXED 로 파티셔닝하려면 인덱스 키를 local prefixed로 파티셔닝하려면 인덱스 키를 [거래일자 + 계좌번호] 로 구성해야하는데 그럴 경우 인덱스 선두 컬럼이 부등호 조건이므로 인덱스 스캔 효율이 좋지 않다.
인덱스 키를 [계좌번호 + 거래일자] 로 구성해야 스캔 효율이 좋은데 이는 Local non prefixed 파티션에 해당한다.

22. 인덱스 파티션 선택

```sql
CREATE TABLE 거래 (
  거래일자 VARCHAR2(8),
  계좌번호 NUMBER,
  주문매체코드 VARCHAR2(2),
  거래유형코드 VARCHAR2(4),
  거래량 NUMBER,
  거래금액 NUMBER
)
PARTITION BY RANGE(거래일자)
(
  PARTITION P2021_M01 VALUES LESS THAN ('20210201')
  ,PARTITION P2021_M02 VALUES LESS THAN ('20210301')
  ,PARTITION P2021_M03 VALUES LESS THAN ('20210401')
  ...
  ,PARTITION P2021_M012 VALUES LESS THAN ('20220101')
  ,PARTITION P9999_MX VALUES LESS THAN (MAXVALUE);
)

SELECT SUM(거래량), SUM(거래금액)
FROM 거래
WHERE 계좌번호 = :ACNT_NO
```

테이블을 거래일자 기준으로 RANGE 파티셔닝했으므로 Local 파티션 인덱스의 파티션 키는 거래일자다.

문제 SQL을 위해 LOCAL PREFIXED 파티션 인덱스를 생성하려면, 인덱스 선두 컬럼이 거래일자여야함다. 이때 RANGE SCAN이 불가능하다.

LOCAL NONPREFIXED 파티션 인덱스를 생성하려면, 계좌번호 단일 컬럼 인덱스를 로컬 파티셔닝 하면 된다.

거래 일자를 뒤쪽에 추가해도 되지만, 조건절에 거래일자가 없으므로 불필요한 컬럼 추가에 해당한다.

인덱스 키를 계좌번호 단일 컬럼으로 구성하든, 계좌번호 + 거래일자로 구성하든, 파티션 키인 거래일자가 조건절에 없으므로 전체 인덱스 파티션을 스캔해야한다. 20년1월 부터 21년 12월 까지 24개 파티션에 MAXVALUE 파티션을 더하면 총 25개다.

인덱스를 파티셔닝하지 않으면 인덱스를 한번만 스캔하므로 성능측면에서 가장 최적이다.

GLOBAL PREFIXED 파티셔닝의 경우,
거래일자로 파티셔닝하는 GROBAL PREFIXED 파티션 인덱스는 거래일자가 선두 컬럼이므로 raNGE SCANDDL 불가능하다.

조건절 컬럼인 계좌번호로 파티셔닝하는 GLOBAL PREFIXED 파티션 인덱스는 계좌번호가 선두컬럼이므로 RANGE SCAN이 가능하다. 루트에서 리프까지 DEPT가 비파티션 인덱스보다 낮아지도록 여러 개로 파티셔닝하면 인덱스 수직 텀색과정에 블록 i/o를 한 번 정도 줄일 수있다. 반면 파티션 크기를 균일하게 유지하기 위해 주기적으로 파티션을 추가해 주는 관리적 부담이 생긴다.

23. 인덱스 파티션 선택

```SQL
CREATE TABLE 거래 (
  계좌번호 NUMBER,
  거래일자 DATE,
  상품코드 VARCHAR2(20),
  거래수량 NUMBER,
  거래금액 NUMBER,
  입금일자 VARCHAR2(8)
)
PARTITION BY RANGE(거래일시)
(
  PARTITION P2021_M01 VALUES LESS THAN (TO_DATE('20200201', 'YYYYMMDD')),
  PARTITION P2021_M01 VALUES LESS THAN (TO_DATE('20200201', 'YYYYMMDD')),
  ...
  ...
  PARTITION P2021_M12 VALUES LESS THAN (TO_DATE('20200201', 'YYYYMMDD')),
  PARTITION P9999_MAX VALUES LESS THAN (MAXVALUE)
)

CREATE UNIQUE INDEX 거래_PK on 거래(계좌번호, 거래일시) LOCAL;

ALTER TABLE 거래 add
constraint 거래_pk Primary key(계좌번호, 거래일시) local;

select /*+ordered use_nl(b)*/ *
from 계좌 a, 거래 b
where a.지점코드 = :brch_cd
and b.계좌번호 = a.계좌번호
and B.입금일자 = :pay_dt;
```

거래 테이블을 거래일시 가준으로 RANGE 파티셔닝 했으므로 LOCAL 파티션 인덱스의 파티션 키는 거래일시다. 문제 SQL을 위해 거래 테이블에 local prefixed 파티션 인댁스를 생성하려면 인덱스 선두 컬럼이 range 여야하는데 range scaN이 불가능하다.

LOCAL NONPREFIXED 파티션 인덱스를 생성하려면 인덱스 키를 계좌번호 + 입금일자로 구성해야 하는데, 파티션 키인 거래일시가 조건절에 없으므로 전체 인덱스 파티션을 스캔하게 된다. 20년 1월부터 21년 12월까지 24개 파티션에 MAXVLAUE 파티션을 더하면 총 25개다.

거래일시로 파티셔닝하는 GLOBAL PREFIXED 파티션 인덱스는 거래일자가 선두 컬럼으로 RANGE SCAN이 불가능하다.

인덱스를 파티셔닝하지 않으면 계좌 테이블에서 읽은 계좌번호별 인덱스를 한 번만 스캔하므로 성능 측면에서 가장 최적이다.

24.

````sql
-- 자료전송이력
-- 등록일시 기준 RANGE 월 파티션 (77개)
-- 상담 시 또는 상담완료 후 고객에게 자료를 발송한 내역을 관리

-- 인덱스 구성
-- 고객상담_PK(상담원_id + 상담일시)
-- 고객상담_N1(고객번호 + 상담일시)
-- 자료전송이력_PK(상담원_id + 등록일시) local```
-- 자료전송이력_N1(상담원_id + 상담일시) local```
-- 자료전송이력_PK(고객번호) local

SELECT A.*,
(
  SELECT NVL(MAX('Y'), 'N')
  FROM 자료전송이력
  WHERE 상담원ID = A.상담원ID
  AND 상담일시 = a.상담일시
  AND ROWNUM = 1
) 자료전송여부
FROM
(
  SELECT 상담원iD, 상담일시, 상담접촉구분코드
  , 연락전화번호, 통화자명, 호식별번호
  , 상담처리상태코드, 조짖ID
  FROM 고객상담
  WHERE 고객번호 = :cust_num
  ORDER BY 고객번호 DESC, 상담일시 DESC
) A
WHERE ROWNUM <= 10

-- SELECT STATEMENT
--  SORT AGGREGATE
--    COUNT STOPKEY
--      PARTITION RANGE ALL
--        INDEX RANGE SCAN 자료전송이력_N1
--   COUNT STOPKEY                                10
--      VIEW                                      10
--        table access by index rowid of 고객상담   10
--          index range scan descending 고객상담_N1 41
````

자료전송이력의 파티션 키에 대한 조건절이 없으므로 77개의 파티션 전체를 스캔하고 있다.
실행계획에서 PARTITION RANGE ALL 오퍼레이션을 확인하면 알 수 있다
자료전송이력은 상담 시 또는 상담완료 후 고객에게 자료를 발송한 내역을 관리하는 테이블이므로
등록일시는 상담일시보다 항상 크거나 같다.

자료 전송이력을 조회하는 스칼라 서브쿼리에 [등록일시 >= 상담일시] 조건절을 추가하면, 등록일시가 상담일시보다 큰 파티션만 스캔할 수 있다.

````sql
-- 자료전송이력
-- 등록일시 기준 RANGE 월 파티션 (77개)
-- 상담 시 또는 상담완료 후 고객에게 자료를 발송한 내역을 관리

-- 인덱스 구성
-- 고객상담_PK(상담원_id + 상담일시)
-- 고객상담_N1(고객번호 + 상담일시)
-- 자료전송이력_PK(상담원_id + 등록일시) local```
-- 자료전송이력_N1(상담원_id + 상담일시) local```
-- 자료전송이력_PK(고객번호) local

SELECT A.*,
(
  SELECT NVL(MAX('Y'), 'N')
  FROM 자료전송이력
  WHERE 상담원ID = A.상담원ID
  AND 상담일시 = a.상담일시
  AND 등록일시 >= 상담일시
  AND ROWNUM = 1
) 자료전송여부
FROM
(
  SELECT 상담원iD, 상담일시, 상담접촉구분코드
  , 연락전화번호, 통화자명, 호식별번호
  , 상담처리상태코드, 조짖ID
  FROM 고객상담
  WHERE 고객번호 = :cust_num
  ORDER BY 고객번호 DESC, 상담일시 DESC
) A
WHERE ROWNUM <= 10

-- SELECT STATEMENT
--  SORT AGGREGATE
--    COUNT STOPKEY
--      PARTITION RANGE ITERATOR
--        INDEX RANGE SCAN 자료전송이력_N1
--   COUNT STOPKEY                                10
--      VIEW                                      10
--        table access by index rowid of 고객상담   10
--          index range scan descending 고객상담_N1 41
````

25. 파티션 RANGE SCAN 유도

```sql
-- :CHG_DT 변수에는 어떤 값이든 입력할 수 있지만, 주로 당일 또는 전월 말일을 입력함ㄴ

-- 고객 : 1000만 명
-- 고객변경이력 : 변경일자 기준 월단위 RANGE 파티션

-- 고객_pk : 고객번호
-- 고객_N1 : 고객번호 + 고객상태코드 + 상태변경일자
-- 고객변경이력_PK : 고객번호 + 변경일자 + 변경구분코드 + 변경일련번호
-- 고객상태코드가 ai인 고객의 고객변경이력에서 최신 변경일자와 변경일자와 변경일련번호를 기준으로 한 최신 변경구분코드 중 변경일자가 :CHG_DT 이고 변경구분코드는 D1 인 레코드
SELECT *
FROM (
  SELECT
  고객번호
  , MAX(변경일자) 변경일자
  , MAX(변경구분코드) KEEP (DENSE_RANK LAST ORDER BY 변경일자, 변경일련번호) 변경구분코드
  FROM 고객변경이력 CH
  WHERE EXISTS (
    SELECT 'X'
    FROM 고객 C
    WHERE 고객번호 = CH.고객번호
    AND 상태변경일자 <= CH.변경일자
    AND 고객상태코드 = 'AI'
  )
  GROUP BY 고객번호
)
WHERE 변경일자 = :CHG_DT
AND 변경구분코드 = 'D1'

-- select statement
--  filter
--    sort group by
--      hash join
--        index range scan of 고객_N1
--        partition range all
--          index fast full scan of 고객변경이략_Pk
```

위 실행계획은 고객변경이력\_PK 인덱스의 파티션 전체를 스캔하고 있다.
PARTITION RANGE ALL 오퍼레이션을 해소할 방안을 찾아야 한다.

문제의 SQL은 인라인 뷰에서 찾은 고객별 최종 변경일자가 :CHG_DT 값과 일치하는지 확인하고 있다.

따라서 변경일자가 :CHG_DT 보다 작은 데이터는 인라인 뷰에서 애초에 조회할 필요가 없다.
예를들어 :CHG_DT에 20210331 입력하면 최종 변경일자가 20210331 보다 작은 고객번호는 어차피 인라인 뷰 바깥에서 버려진다.

이런 데이터 특성을 이용하기 위해 인라인 뷰 안쪽에 아래 조건절을 추가해보자

```sql
SELECT *
FROM (
  SELECT
  고객번호
  , MAX(변경일자) 변경일자
  , MAX(변경구분코드) KEEP (DENSE_RANK LAST ORDER BY 변경일자, 변경일련번호) 변경구분코드
  FROM 고객변경이력 CH
  WHERE EXISTS (
    SELECT 'X'
    FROM 고객 C
    WHERE 고객번호 = CH.고객번호
    AND 상태변경일자 <= CH.변경일자
    AND 고객상태코드 = 'AI'
  )
  AND 변경일자 >= :CHG_DT
  GROUP BY 고객번호
)
WHERE 변경일자 = :CHG_DT
AND 변경구분코드 = 'D1'

-- 아래는 조건절을 추가했을때의 실행계획이다.

-- select statement
--  filter
--    sort group by
--      hash join
--        index range scan of 고객_N1
--        partition RANGE ITERATOR
--          index fast full scan of 고객변경이략_Pk
```

변경일자 변수에 주로 당일 또는 전월 말일을 입력한다고 했으므로 위 실행계획은
성능 향상에 도움이 된다.

최종 변경일자가 :CHG_DT 값보다 큰 데이터도 애초에 읽을 필요가 없다고 생각할 수 있다.
예를 들어, :CMG_DT에 '20210331'을 입력하면 최종 변경일자가 '20210401' 인 고객번호도 인라인 뷰 바깥에서 버려지기 때문이다.

하지만 = 조건으로변경하면 최종 변경일자가 20210401 이고 직전 변경일자는 20210331일때 결과집합에 오류가 ㅂ생긴다.
최종 변경일자가 20210401인 고객번호는 인라인뷰 바깥에 있는 변경일자 조건에 의해 버려져야 한다. 그런데 인라인 뷰에 위 조건절을 추가하면 20210401 값을 읽지 않으므로 20210331이 최종변경일자로 선택되고 20210331 조건인 데이터가 선택된다.

# 대용량 배치 프로그램 튜닝

26. 배치프로그램

배치 프로그램은 DW/OLAP 시스템뿐만 아니라 OLTP 시스템에서도 많이 활용한다.
실시간에 가까운 정보 서비스 요구가 늘면서 ON-DEMAND 배치가 높고, 트랜잭션을 일정량 모았다가 지연 처리하는 배치 프로그램의 활용도 느는 추세다.

27. 배치 프로그램 튜닝

야간 배치 프로그램을 튜닝할 때는 개별 프로그램 수행시간을 단축하기보단 전체 프로그램 수행시간을 단축하는데 더 큰 목표를 둬야 한다.

병렬 프로세싱을 활용할 때는 필요 이상의 병렬도를 지정하지 않아야 한다.

배치 윈도우를 조절해 프로그램 수행시간대를 적절히 분산하면 개별 프로그램을 튜닝할 때보다
더 큰 효과를 얻을 수도 있다.

배치 프로그램은 항상 전체 처리속도 최적화에 목표를 두고 튜닝해야 한다.
개별 서비스 또는 프로그램을 가장 빠른 속도로 최적화하더라도 전체 배치 프로그램 수행시간을 단축하지 못하면 무의미하다. 튜닝 대상을 선정할 때도 이런 기준을 갖고 선별해야 한다.

자원에 대한 경합이 극심한 상황에선 프로그램들이 정상적으로 진행하기 어렵다.
따라서 병렬처리없이 처리하는 것이 오히려 나을 수 있다. 시스템 자원을 독점적으로 사용하도록 설정된 프로그램을 찾아 병렬도를 제한하고 , 동시에 수행되는 프로그램 수도 적절히 유지해야 한다.

같은 시각에 많은 프로그램들이 집중적으로 수행되면 자원과 LOCK 에 대한 심한 경합이 발생한다.

그러면 프로세스가 실제 일한 시간보다 대기하는 시간이 더 많아지므로 총 수행시간이 늘어난다.
배치 윈도우를 적절히 조절하는 것만으로도 배치 프로그램 수십개를 튜닝한 것과 같은 효과가 난다

28. 배치 프로그램 튜닝

배치 프로그램은 아래 두 가지 스타일로 대별한다.

\- 절차형으로 작성된 프로그램
\- ONE SQL 위주로 작성된 프로그램

절차형으로 작성된 프로그램은 SQL 결과집합을 루프 내에서 한 건씩 fetch 하면서 또 다른 SLQ을 반복적으로 수행하는 형태를 말한다. 이런 형태의 배치 프로그램에서는 인덱스 구성이 주요하다.

29. 배치 프로그램 QC의 역할

병렬 서버 집합을 할당한다.

각 병렬 프로세스에 작업을 할당한다.

병렬도를 지정하지 않은 테이블을 직접 읽는다.

다른 병렬 서버들이 작업 완료하기를 기다리면서 대기 중인 병렬 프로세스를 찾아 자원을 OS에 반환한다 (x)

---

병렬 처리에 사용한 병렬 프로세스는 모든 처리를 종료 (SELECT 문장은 커서를 닫거나 결과집합을 모두 FERTCH) 한 후 일괄 해제하고 자원을 OS에 반환한다.

30. INTRA-OPERATION-PARALLELISM

병렬 처리에서 서로 배타적인 범위를 독립적으로 동시적으로 처리하는 것을 INTRA-OPERATION-PARALLELISM 이라고 한다.

한편의 서버집합에 속한 프로세스들이 읽은 데이터를 반대편 서버집합 또는 QC에 전송하는 작업을 병렬로 동시에 진행하는 것을
INTER-OPERATION PARALLELISM 이라고 한다.

31. P-P 오퍼레이션

\- 프로세스 간 통신이 발생한다.

\- 서버 프로세스가 병렬도의 2배수로 생성된다.

\- 테이블 큐가 필요하다.

---

parallel_to_parallel 오퍼레이션은 데이터를 재분배하는 오퍼레이션이다.
실행계획에 p-p 오퍼레이션이 나타나는 구간은 두 개의 서버 집합이 처리한다. 따라서 사용자가 지정한 병렬도의 2배수만큼 병렬 프로세스가 필요하다.
데이터 재분배 과정에서 테이블 큐를 사용한다.

데이터를 정렬 또는 그룹핑 하거나 조인을 위해 동적을 파티셔닝할때 사용하며, 첫 번째 병렬 서버 집합이 읽거나 가공한 데이터를 두 번째 병렬 서버 집합에 전송하는 과정에서 병렬 프로세스간 통신이 발생하므로 INTER-OPERATION PARALLELISM에 속한다.

32. 프로세스 통신 발생 오퍼레이션

\- PARALLEL_FROM_SERIAL

QC가 읽은 데이터를 테이블 큐를 통해 병렬 서버 프로세스에게 전송

\- PARALLEL_TO_SERIAL

각 병렬 서버 프로세스가 처리한 데이터를 QC에게 전송

\- PARALLEL_TO_PARALLEL

한 서버 집합이 반대편 서버 집합에 데이터를 전송

\- PARALLEL_COMBINED_WITH_PARENT

한 병렬 프로세스가 현재 스텝과 부모 스텝을 모두 처리

\- PARALLEL_COMBINED_WITH_CHILD

한 병렬 프로세스가 현재 스텝과 자식 스텝을 모두 처리

PARALLEL_COMBINED_WITH_PARENT 와 PARALLEL_COMBINED_WITH_CHILD
오퍼레이션에서는 프로세스 간 통신이 발생하지 않는다.

33. DATA REDISTRIBUTION

\- RANGE

ORDER BY 또는 SORT GROUP BY 를 병렬로 처리할 때

\- HASH

조인이나 HASH GROUP BY를 병렬로 처리할 때

\- BROADCAST

대량 데이터를 분배할 때

\- ROUND-ROBIN

BROADCAST는 QC 또는 첫 번째 서버 집합에 속한 프로세스들이 각각 읽은 데이터를 두 번째 서버 집합에 속한 모든 병렬 프로세스에게 전송하는 방식이다.
병렬 조인에서 크가기 매우 작은 테이블이 있을때 사용된다.

34. DOP

데이터를 병렬로 처리할 때 일의 최소 단위를 Granule 이라고 하며, 병렬 서버는 한 번에 하나의 granule 씩만 처리한다.

블록 기반 granuel

QC 가 테이블로 부터 읽어야 할 일정 범위의 블록을 각 병렬 프로세스에게 할당한다.
병렬 프로세스가 한 granule에 대한 일을 끝마치면 이어서 다른 granule을 할당한다. 따라서 프로세스 간 처리량에 편차가 거의 발생하지 않는다.
파티션 여부, 파티션 개수와 무관하게 병렬도를 지정할 수 있다.

파티션 기반 GRAnuel

한 파티션에 대한 작업을 한 프로세스가 모두 처리하며, 아래와 같은 작업을 수행할 때 사용된다.

\- partition-wise 조인 시
\- 파티션 인덱스를 병렬로 스캔할때 (index range scan, index, full scan)
\- 파티션 인덱스를 병렬로 갱신할 때
\- 파티션 테이블 또는 파티션 인덱스를 병렬로 생성할 때

한 파티션을 두 개 프로세스가 함께 처리할 수 없으므로 병렬도를 파티션 개수보다 크게 지정하면 서버 리소스를 낭비하게 된다.
병렬도를 파티션 개수 이하로 지정할 때는 블록 기반 granule과 마찬가지로 먼저 일을 마친 프로세스에게 다음 파티션을 할당한다.
더 처리할 파티션이 없을 때 먼저 일을 끝마친 프로세스는 다른 프로세스가 일을 마칠 때까지 기다리게 되므로 파티션간 데이터양의 편차가 심할때 리소스를 낭비하게 된다.

```SQL
-- 데이터 1000만 건
-- 파티션간 데이터 편차 없음

-- table partition
-- 주문일시 기준 Range 파티션 (16)

-- 주문_PK : 계좌번호 + 주문일시 (local 파티션)

SELECT /*+index(o, 주문_pk) parallel_index(o, 주문_pk, )*/
count(*)
FROM 주문 o
WHERE 계좌번화 = 'ABC123';
```

INDEX RANGE SCAN을 병렬로 처리 때는 파티션 GRANUEL이므로 파티션 개수보다 많은 병렬도를 지정하면 서버 리소스를 낭비하게 된다.
병렬도가 4 보다는 8일때 8보다는 16일 때 일을 더 빨리 마칠 수 있다.

35. DOP

```SQL
-- 데이터 1000만 건
-- 파티션간 데이터 편차 없음

-- table partition
-- 주문일시 기준 Range 파티션 (8)

-- 주문_PK : 계좌번호 + 주문일시 (local 파티션)

SELECT /*+index_FFS(o, 주문_pk) parallel_index(o, 주문_pk, )*/
TO_CHAR(주문일시, 'YYYYMM') 주문월, COUNT(*) 주문건수
FROM 주문 o
GROUP BY TO_CHAR(주문일시, 'YYYYMM')
```

테이블을 FULL SCAN 하거나 인덱스를 fast full scan 할 때는 블록기반 granuel 이므로 파티션보다 많은 병렬 프로세스를 사용할 수 있다.
프로세스가 많을수록 빨리 일을 마칠 수 있고, 일정량 블록 단위로 작업을 할당하므로 프로세스 간 일량에 편차가 발생하지 않아 효율적이다.
단, 작은 테이블에 너무 많은 병렬 프로세스를 사용하면 서버 리소스를 낭비하는 결과를 초래한다.

36. 병렬 SQL 튜닝 핵심 원리

\- 병렬 프로세스간 통신을 최소화 한다.
\- 데이터 병렬로 처리하는 중애 생기는 병목 구간을 해소한다.
\- 성능 향상 효과를 체감할 수 있는 최소한의 병렬 프로세스를 할당한다.

---

\- 인덱스를 활용해 소트 연산을 생략하게 한다.

인덱스를 활용해 소트 연산을 생략하게 하는 튜닝 기법의 주 목적은 부분범위 처리 활용이다.

병렬 SQL은 대용량 배치 프로그램 튜닝에 주로 사용하므로 부분범위 처리를 활용할 이유가 없다.
게다가 소트연산을 인덱스로 대체하려면 INDEX RANGE SCAN 또는 INDEX FULL SCAN을 사용해야하는데
이는 일반적으로 병렬 처리에 효과적이지 못한 스캔 방식이다.

병렬 처리에는 table full scan 또는 index fast full scan이 효과적이다.

37. 병렬 sql 튜닝

- 병렬로 FULL TABLE SCAN 할 때 파티션 개수보다 큰 병렬도를 지정했는지 확인한다.

---

병렬 FULL TABLE SCAN은 블록 기반 granule 이므로 파티션 개수보다 큰 병렬도를 지정해도 상관없다.
병렬로 처리하는 중간 단계에 PARALLEL_TO_SERIAL 오퍼레이션이 나타나는지 확인한다.

---

병렬로 처리하는 중간 단계에 PARALLEL_TO_SERIAL 오퍼레이션이 나타나면 병목 구간으로 작용한다.

- 큰 테이블을 PARALLEL_FROM SERIAL 방식으로 읽는지 확인한다.

---

병렬로 처리하는 과정에 큰 테이블을 단일 프로세스로 읽으면 병목 구간이 될 수 있다.
작은 테이블은 단일 프로세스로 읽어도 성능에 큰 영향을 주지 않는다.

- 대형 테이블을 BROADCAST 방식으로 분배하는지 확인한다.

---

대형 테이블을 BROADCAST 방식으로 분배하면 프로세스 간 통신에 따른 부담이 클 뿐만 아니라
읽은 데이터를 프로세스 개수만큼 복제하는 결과를 초래하므로 메모리와 디스크 자원을 많이 사용한다.

38. 병렬 프로세스

\- 병렬 ORDER BY 및 병렬 GROUP BY

\- BRAODCAST 방식의 데이터 분배

\- FULL PARTITION WISE 조인

\- PARTITION PARTITION WISE 조인

---

FULL PARTITION WISE 조인은 같은 기준으로 파티션된 두 테이블을 조인할 때 사용하는 병렬 조인 방식이다.

양쪽 테이블을 같은 파티션하기 위해 데이터를 재분배할 필요가 없으므로 병렬 프로세스를 2배수로 할당하지 않는다.

PARTITION PARTITION WISE 조인은 한쪽 테이블을 다른 쪽 테이블과 같은 기준으로 동적 파티셔닝한 후에 병렬로 조인하는 방식이다.

동적 파티션 과정에 데이터 재분배가 필요하므로 병렬 프로세스를 2배수로 할당한다.

39. BROADCAST 방식의 데이터 재분배

```sql
--  결제구분 : 5개의 결제구분코드를 관리
--  상품 : 100만개의 상품을 관리
--  고객 : 1000만 명의 고객정보를 관리
--  주문 : 1억건의 주문 데이터를 관리 (주문일시 기준 RANGE 파티션)
--  배송 : 1억건의 배송정보를 관리 (배송일자 기준 RANGE 파티션)
```

BROADCAST는 QC 또는 첫 번째 서버 집합에 속한 프로세스들이 각각 읽은 데이터를 두 번째 서버 집합에 속한 모든 병렬 프로세스에 전송하는 방식이므로
데이터 크기가 작을수록 효과적이다.

40. HASH 방식의 데이터 재분배

```sql
--  결제구분 : 5개의 결제구분코드를 관리
--  상품 : 10만개의 상품을 관리
--  고객 : 1000만 명의 고객정보를 관리
--  주문 : 1억건의 주문 데이터를 관리 (주문일시 기준 RANGE 파티션)
--  주문상품 : 5억건의 주문상품 정보를 관리 (주문일시 기준 RANGE 파티션)
```

1000만 명 고객과 1억 건 주문 데이터를 조인할 때는 HASH 방식의 데이터 재분배가 효과적이다.

상품과 주문상품을 상품번호로 조인할 때도 hash 방식으로 데이터를 재분배할 수 있지만,
상품 10만건과 주문상품 5억건을 조인하는 경우라면 BROADCAST 방식으로 재분배하는 것이 훨씬 효과적이다.
주문과 주문상품을 조인할 때는 full partition wise 조인이 가장 효과적이다.

41. 병렬 쿼리 유도 힌트

```sql
-- 병렬도는 2로 지정
SELECT
/*+
  LEADING(A) USE_HASH(B)
  FULL(A) FULL(B) PARALLEL(A 2) PARALLEL(B 2)
  PQ_DISTRIBUTE(B, BROADCAST, NONE)
*/
*
FROM 상품 A , 주문상품 B
WHERE A.상품번호 = B.상품번호

-- SELECT STATEMENT
--    PX COORDINATOR
--      PX SEND QC(RANDOM) :TQ10001
--        HASH JOIN
--          PX RECIEVE
--            PX SEND BROADCAST : TQ10000
--              PX BLOCK ITERATOR
--                TABLE ACCESS FULL 상품
--            PX BLOCK ITERATOR
--               TABLE ACCESS FULL 주문상품
```

옵티마이저가 인덱스 스캔을 선택하면 PArallel 힌트는 무시된다.

따라서 PARALLEL 힌트를 사용할 때는 full 힌트를 습관적으로 같이 사용하는 것이 좋다.

반대로, PARALLEL_INDEX 힌트를 사용할 때는 INDEX_FFS 힌트를 같이 사용해야 한다.

42. BLOADCAST 방식의 병렬 조인

\- BRAODCAST 되는 테이블에는 반드시 PARALLEL 힌트를 지정한다.

---

BROADCAST 되는 데이터 집합이 작을수록 유용한 병렬 조인방식이다. 따라서 작은 데이터를 broadcast 할 때는 굳이 parallel 힌트를 쓰지 않아도 상관없다.

\- BROADCAST 되는 데이터 집합은 전체범위처리가 불가피하지만, 반대쪽 테이블은 부분범위 처리가 가능하다.

\- 매우 큰 데이터 집합을 BROADCAST 하면 TEMP 테이블스페이스 공간을 많이 사용하게 되므로 성능이 느려질 수 있다.

\- BROADCAST를 완료하고 난 후의 조인 방식은 nl 조인, 소트머지 조인, 해시 조인 중 어떤 것이든 사용할 수 있다.

43. 병렬 쿼리 유도 힌트

```sql
SELECT
/*+
  LEADING(A) USE_HASH(B)
  FULL(A) FULL(B) PARALLEL(A 2) PARALLEL(B 2)
  PQ_DISTRIBUTE(B, HASH, HASH)
*/
*
FROM 고객 A, 주문 B
WHERE A.고객번호 = B.고객번호

-- SELECT STATEMENT
--    PX COORDINATOR
--      PX SEND QC(RANDOM) :TQ10002
--        HASH JOIN BUFFERED
--          PX RECIEVE
--            PX SEND HASH : TQ10000
--              PX BLOCK ITERATOR
--                TABLE ACCESS FULL 고객
--          PX RECIEVE
--            PX SEND HASH :TQ10001
--              PX BLOCK ITERATOR
--               TABLE ACCESS FULL 주문

```

PARALLEL 힌트를 사용할 때는 FULL 힌트를 습관적으로 같이 사용해야 한다.
양쪽 테이블을 동적으로 해시파티셔닝한 후에 조인하는 병렬 조인 실행계획이므로
PQ_DISTRIBUTE(INNER_TABLE, HASH, HASH) 힌트를 사용한다.

44. 해시 병렬 조인

\- 두 개의 서버집합이 필요하다.
\- 두 테이블을 파티셔닝하는 과정에 temp 테이블스페이스 공간을 많이 사용한다.
\- 조인 컬럼의 데이터 분포가 균일하지 않을 때 병렬 처리 효과가 크게 반감된다.

\- 파티셔닝 할 때는 해시 방식을 상요하므로 조인 방식도 해시 조인만 사용할 수 있다.

---

큰 두개의 테이블을 조인하는데, 두 테이블 모두 파티션되지 않았거나 서로 다른 기준으로
파티션 됐을때 주로 사용한다. 양쪽 모두 큰 테이블일 때 사용하므로 두 테이블을 파티셔닝 하는 과정에 많은
TEMP 테이블스페이스 공간을 사용한다.
파티셔닝할 때는 해시 방식을 사용하지만 조인방식은 nl, 소트머지, 해시 조인 중 어떤 것이든 사용할 수 있다.

45. 병렬 조인 유도

```sql
-- 병렬도는 2로 지정
SELECT *
FROM 상품 A , 주문상품 B
WHERE A.상품번호 = B.상품번호

-- SELECT STATEMENT
--    PX COORDINATOR
--      PX SEND QC(RANDOM) :TQ10001
--        PX PARTITION RANGE ALL
--          HASH JOIN
--            TABLE ACCESS FULL 주문
--            TABLE ACCESS FULL 주문상품
```

HASH JOIN 오퍼레이션 위쪽에 PX PARTITION RANGE ALL 오퍼레이션이 나타난다면 FULL PARTITION WISE JOIN 할 때의 실행계획이다.

46. FULL PARTITION WISE JOIN

\- 두 개의 서버 집합이 필요하다

-- 다른 병렬 조인은 두 개의 서버집합이 필요한 반면, FULL PARTITION WISE JOIN에서는 하나의 서버 집합만 필요하다.

\- 파티션 개수보다 작거나 같은 개수의 DOP를 지정해야한다.
\- 테이블 파티션 방식은 RANGE, LIST, HASH 어떤 것이든 상관없이 작동한다.
\- 조인 방식으로 일반적으로 해시조인을 사용하지만, nl 조인이든 또는 소트머지 조인도 사용할 수 있다.

47. 병렬조인 유도

```sql

select
/*+
  LEADING(B) USE_HASH(A) PARALLEL(A 4) PARALLEL(B 4) PQ_DISTRIBUTE(A, PARTITON , NONE)
*/
*
from 주문 a, 배송 B
where a.주문번호 = b.주문번호
and a.주문일자 = B.주문일자

-- SELECT STATEMENT
--    PX COORDINATOR
--      PX SEND QC(RANDOM) :TQ10001
--        HASH JOIN
--          PX RECEIVE
--            PX SEND PARTITION KEY :TQ1000
--              PX BLOCK ITERATOR
--                TABLE ACCESS FULL 배송
--              PX PARTITION RANGE ALL
--                TABLE ACCESS FULL 주문상품 주문
```

PARTIAL PARTITION WISE JOIN 실행계획이다.

PX SEND PARTITION (KEY) , PQ DISTRIBUTE 열에 PART KE가 표시돈 것을 통해 배송 테이블을 주문 테이블 기준으로 파티셔닝 한다는 사실을 알 수 있다.

48. 배치 프로그램 튜닝

```sql
-- 등록 고객 수 = 300만명

-- 월 평균 주문 레코드 = 100만건
-- 주 파티션 : 주문일자 기준 range
-- 서브 파티션 : 고객번호 기준 hash

SELECT
/*+ORDERED USE_HASH(B) FULL(A) FULL(B) PARALLEL(A 16) PARALLEL(B 16) PQ_DISTRIBUTE(B, PARTITON, NONE)*/
to_char(b.주문일시 , 'YYYYMMDD') 주문일자,
MIN(DISTICT a.고객번호) 고객수
, CONUT(*) 주문수량,
, SUM(B.주문금액) 주문금액
FROM 고객 A, 주문 B
WHERE B.고객번호 = A.고객번호
AND B.주문일자 between '20200101' and '20200131'
AND A.등록일자 < '20200101'
GROUP BY TO_CHAR(b.주문일자 , 'YYYYMMDD')
ORDER BY 1

-- SELECT STATEMENT
--  PX COORINATOR
--    PX SEND QC ORDER              :TQ10003
--      SORT GROUP BY
--        PX RECIEVE
--          PX SEND RANGE           :TQ10002
--            HASH GROUP BY
--              FILTER
--                HASH JOIN
--                  PX RECIEVE
--                    PX SEND HASH  :TQ10000
--                      PX BLOCK ITERATOR
--                        TABLE ACCESS FULL 고객
--                   PX RECIEVE
--                      PX SEND HASH : TQ10001
--                        PX BLOCK ITERATOR
--                          TABLE ACCESS FULL 주문
```

주문 테이블이 고객번호를 기준으로 해시 서브 파티셔닝 돼 있으므로 고객 데이터를 같은 기준으로 파티셔닝한 후에 조인하는
PARTIAL PARTITON WISE JOIN을 활용하는 것이 유리하다.

고객 테이블을 broadcast 하는 것도 고려해볼수 있으나 병렬도가 16인 점을 고려해야 한다.
300만 고객 데이터를 16개 병렬 프로세스에 BROADCAST하는 과정에 많은 프로세스간 통신이 발생하고, 메모리 자원이 부족하면 Temp
테이블스페이스를 사용하게 될 수도 있다.

49. 병렬처리

\- 병렬 DML을 활성화하고 병롤로 INSERT/UPDATE/DELETE 할 때는 별도의 힌트를 지정하지 않아도 DIREC PATH WIRTE 가 작동한다.

\- 파티션 인덱스가 아니면 INDEX RANGE SCAN, INDEX FUL LSCAN은 병렬처리가 불가능하다.

\- NL 조인은 병렬 처리가 불가능하다.

---

파티션 인덱스는 병렬로 INDEX RANGE SCAN 또는 INDEX FULL SCAN이 가능하다.
단, 파티션 GRANULE 이므로 파티션 개수를 초과하는 병렬도를 지정해선 안된다.
NL 조인도 병렬로 처리할 수 있다.

\- 쿼리문에 ROWNUM을 사용하면 병렬처리 과정에 병목현상이 발생한다.

50. 병렬처리

\- 온라인 트랜잭션을 처리하는 시스템에서는 주간 업무 시간대의 병렬 처리를 제한하거나 최소화 해야한다.

\- 온라인 트랜잭션이 발생하는 테입르에 병렬 DML을 사용해선 안된다.

\- PARALLEL 힌트를 사용하면 어차피 테이블을 full scan하므로 full 힌트를 사용할 필요 없다.

\- 쿼리 툴에서 대량 데이터를 병렬로 조회후 끝까지 fetch 하지 않았다면, 작은 테이블을 조회하는 쿼리를 수행함으로써
기존 병렬 쿼리가 닫히도록 조치해야 한다.

병렬 DML 수행 시 exclusive 모드 테이블 lock 이 걸리므로 업무 트랜잭션이 발생하는 주간에 사용하는 것은 금물이다.

PARALLEl 힌트를 사용하할 때는 full 힌트도 함께 사용하는 것이 바람직하다. 옵티마이저가 인덱스 스캔을 선택하는 경우
Parallel 힌트가 무시되어 배치 프로그램 수행 성능이 감소한다

마찬가지로 Parallel_index 힌트를 사용할 때는 반드시 INDEX 또는 INDEX_FFS 힌트를 함께 사용하는 것이 바람직하다

쿼리 툴에서 대량 데이터를 병렬로 조회할 후 끝깢 ㅣfetch 하지 않고 놔두면, 자원을 해제하지 않은 채 프로세스가 계속 더 있게 된다.

따라서 작은 테이블을 조회하는 쿼리를 수행해 기존 병렬 쿼리 커서가 닫히도록 조치해야 한다.

51. 병행 쿼리 튜닝

```sql
  CREATE TABLE 주문_T
  PARALLEL 4
  AS
  SELECT ROWNUM AS 주문일련번호, 주문일자, 주문순번
  FROM (
    SELECT /*+PARALLEL(주문 4)*/
    고객번호, 주문일자, 상품번호, 주문량, 주문금액
    FROM 주문
    ORDER BY 고객번호, 주문일자, 주문순번
  )

  -- CREATE TABLE STATEMENT
  --    PX COORDINATOR
  --      PX SEND QC(RANDOM) :TQ20001
  --       LOAD AS SELECT 주문_T
  --        PX RECEIVE
  --          PX SEND ROUND-ROBIN :TQ20000
  --            COUNT
  --              PX COORDINATOR
  --                PX SEND QC (ORDER)
  --                  VIEW
  --                    SORT ORDER BY
  --                      PX RECEIVE
  --                        PX SEND RANGE :TQ10000
  --                          PX BLOCK ITERATOR
  --                            TABLE ACCESS FULL 주문
```

ROWNUM을 병렬 프로세스들이 처리하면 중복 값이 생긴다. 따라서 쿼리문에 rownum을 사용하면 중복 없이 UNIQUE한 값을 생성하기 위해 QC가 처리하며, 이는 병렬처리과정에 병목구간으로 작용한다.

ROWNUM 대신 ROW_NUMBER 함수를 사용하면 값의 크기에 따라 RANGE 방식으로 분배한 후에 각 병렬 프로세스가 독립적으로 일련번호를 부여한다.

데이터 재분배 과정을 수반하지만, 병목 없이 각 프로세스가 독립적으로 일을 처리하므로 전체 소요 시간은 단축된다.

```sql
CREATE TABLE 주문_T
PARALLEL 4
AS
SELECT
ROW_NUMBER() OVER(ORDER BY 고객번호, 주문일자, 주문순번) AS 주문일련번호
, 고객번호, 주문일자, 상품번호, 주문량, 주문금액
FROM 주문;

  -- CREATE TABLE STATEMENT
  --    PX COORDINATOR
  --      PX SEND QC(RANDOM) :TQ10001
  --       LOAD AS SELECT 주문_T
  --        PX RECEIVE
  --          PX SEND RANGE :TQ10000
  --            PX BLOCK ITERATOR
  --              TABLE ACCESS FULL 주문
```

52. 병행 쿼리 튜닝

```sql
-- 주문 테이블 PK : 고객번호 + 주문일자 + 주문순번

ALTER SESSION ENABLE PARALLEL DML;

UPDATE /*+parallel(주문 4)*/ 주문
SET 주문일련번호 = ROWNUM
WHERE 주문일자 = TO_CHAR(SYSDATE, 'YYYYMMDD');

-- UPDATE STATEMENT
--  PX COORDINATOR
--    PX SEND QC (RANDOM) : TQ20001
--      UPDATE
--        BUFFER SORT
--          PX RECIEVE
--            PX SEND HASH(BLOCK ADDRESS) :TQ20000
--              COUNT
--                PX COORDINATOR
--                  PX SEND QC (RANDOM)
--                    PX BLOCK ITERATOR
--                      TABLE ACCESS FULL 주문
```

ROWNUM을 병렬 프로세스들이 처리하면 중복 값이 생긴다. 따라서 쿼리문에 rownum을 사용하면 중복 없이 UNIQUE한 값을 생성하기 위해 QC가 처리하며, 이는 병렬처리과정에 병목구간으로 작용한다.

UPDATE 문을 MERGE 문으로 변환하면 ROWNUM 대신 ROW_NUMBER 함수를 사용할 수 있다.

ROWNUM 대신 ROW_NUMBER 함수를 사용하면 값의 크기에 따라 RANGE 방식으로 분배한 후에 각 병렬 프로세스가 독립적으로 일련번호를 부여한다.

```sql
MERGE /*+FULL(T1) PARALLEL(T1 4)*/ INTO 주문T1
USING (
  SELECT  /*+FULL(주문) PARALLEL(주문 4)*/
  고객번호, 주문순번, ROW_NUMBER() OVER(ORDER BY 고객번호, 주문순번) AS 주문일련번호
  FROM 주문
  WHERE 주문일자 = TO_CHAR(SYSDATE, 'YYYYMMDD')
) T2
ON (
  T1.주문일자 = TO_CHAR(SYSDATE, 'YYYYMMDD')
  AND T1.고객번호 = T2.고객번호
  AND T1.주문순번 = T2.주문순번
)
WHEN MATCHED THEN UPDATE
  SET T1.주문일련번호 = T2.주문일련번호;

-- OR

MERGE /*+FULL(T1) PARALLEL(T1 4)*/ INTO 주문T1
USING (
  SELECT /*+FULL(주문) PARALLEL(주문 4)*/
    ROWID AS RID
    ,ROW_NUMBER() OVER(ORDER BY 고객번호, 주문순번) AS 주문일련번호
  FROM 주문
  WHERE 주문일자 = TO_CHAR(SYSDATE, 'YYYYMMDD')
) T2
ON (
  T1.주문일자 = TO_CHAR(SYSDATE, 'YYYYMMDD')
  AND T1.ROWID = T2.ROWID
)
WHEN MATCHED THEN UPDATE
  SET T1.주문일련번호 = T2.주문일련번호;

```

53. 병행 쿼리 튜닝

```sql
-- TABLE PARTITION INFO
-- 고객 : 비파티션 테이블
-- 주문 : 주문일자 기준 RANGE PARTITION + 고객번호 기준 HASH SUBPARTITION
-- 배송 : 주문일자 기준 RANGE PARTITION

SELECT /*+
  LEADING (C O D)
  FULL(C) FULL(O) FULL(D)
  USE_HASH(O) USE_HASH(D) NO_SWQP_JOIN_INPUTS(D)
  PARALLEL(C 4) PARALLEL(O 4) PARALLEL(D 4)
  PQ_DISTRIBUTE( O BROADCAST NONE)
  PQ_DISTRIBUTE( D HASH HASH)
*/
FROM 고객 C, 주문 O, 배송 D
WHERE O.고객번호 = C.고객번호
AND D.고객번호 = O.고객번호
AND D.주문일자 = O.주문일자
AND D.주문순번 = O.주문순전

-- SELECT STATEMENT
--   PX COORDINATOR
--    PX SEND QC (RANDOM)
--      HASH JOIN BUFFERED :TQ10003
--        PX RECEIVE
--          PX SEND HASH :TQ10001
--            HASH JOIN
--              PX RECEIVE
--                PX SEND BROADCAST :TQ10000
--                  PX BLOCK ITERATOR
--                    TABLE ACCESS FULL 고객
--                PX BLOCK ITERATOR
--                    TABLE ACCESS FULL 주문
--         PX RECEIVE
--          PX SEND HASH :TQ10002
--            PX BLOCK ITERATOR
--              TABLE ACCESS FULL 배송
```

54. 병렬 쿼리 튜닝

```sql
-- 데이터
-- 상폼기본 : 1000만 건
-- 상품상세 : 1000만 건
-- 상품기본이력임시 : 1000만 건
-- 코드 상세 : 2000 건

INSERT /*+append*/ INTO 상품기본이력 (...)
SELECT /*+parallel(a,32) parallel(b,32) parallel(c,32) parallel(d,32)*/
FROM 상품기본이력임시 a, 상품기본 b, 코드상세 c, 상품상세 d
WHERE a.상품번호 = b.상품번호
AND ...
/
```

1시간 40분간 수행되던 SQL이 임시 세그먼트를 확장할 수 없다는 오류 메시지를 던지면서 멈췄다.

임시 테이블인 상품기본이력임시 테이블에 통계 정보가 없으면 이런 현상이 발생할 수 있다.

실제 천만건에 이르큰 클 테이블인데, 통계 정보가 없어 옵티마이저가 5,248의 작은 테이블로 판단핸 것을 볼 수 있다.

이 큰 테이블을 32개 병렬 서버에게 모두 브로드 케스트 하는동안 과도한 프로세스 간 통신이 발생했고, 결국 TEMP 테이블스페이스를 모두 소진하고서 머췄다.
pq_distribute 를 통해 데이터 분배 방식을 조정하고나도 다시 수항해면 병렬도를 16으로 줄여도 수 분 만에 작업을 완료하게 된다.

```sql
-- 데이터
-- 상폼기본 : 1000만 건
-- 상품상세 : 1000만 건
-- 상품기본이력임시 : 1000만 건
-- 코드 상세 : 2000 건

INSERT /*+append*/ INTO 상품기본이력 (...)
SELECT /*+
ORDERED FULL(A) FULL(B) FULL(C) FULL(D)
parallel(a,16) parallel(b,16) parallel(c,16) parallel(d,16)
PQ_DISTRIUTE(B, NONE, PARTITON)
PQ_DISTRIUTE(C, NONE, BROADCAST)
PQ_DISTRIUTE(D, HASH, HASH)

*/
FROM 상품기본이력임시 a, 상품기본 b, 코드상세 c, 상품상세 d
WHERE a.상품번호 = b.상품번호
AND ...
/

--select statement
--   px coordinator
--    px send qc(Random)
--      hash join buffered
--        px receive
--          px send hash
--            hash join buffered
--              px receive
--                px send broadcast
--                  px block iterator
--                    table access full 코드상세
--              hash join
--                px partition hash all
--                  table access full   상품기본이력암시
--                px recieve
--                  px send partition (key)
--                    px block iterator
--                      table access full 상품기본
--          PX RECEIVE
--            PX SEND HASH
--              PX BLOCK ITERATOR
--                TABLE ACCESS FULL 상품상세

```

# 고급 SQL 활용

55. 데이터 복제 기법

```SQL
SELECT
DEPTNO 부서번호
,(CASE
  WHEN GROUPING(EMPNO) = 1
    THEN '부서계'
  ELSE TO_CHAR(EMPNO)
  END
) 사원번호
, SUM(SAL) 급여합
, ROUND(AVG(SAL)) 급여평균
FROM EMP
GROUP BY DEPTNO, ROL89ㅑㅐㅕㅏㅣLUP(EMPNO)
ORDER BY 1, 2

-- 데이터 복제
SELECT DEPTNO 부서번호
, DECODE(NO , 1, TO_CHAR(EMPNO, 2, '부서계')
FROM EMP A,
(SELECT ROWNUM NO FROM DUAL CONNECT BY LEVEL <= 2)
GROUP BY DEPTNO, NO, DECODE(NO, 1, TO_CHAR(EMPNO), 2, '부서계')
ORDER BY 1, 2;
```

56. UNPIVOT

```SQL
-- 고객구분코드가 VIP인 고객의 연락처 정보를 unpivot (열 데이터를 행 데이터로 전환)

-- UNPIVOT 구문 활용
SELECT 고객번호, 고객명, 컬럼명 as 연락처구분, 컬럼값 as 연락처번호
FROM 고객 unpivot(컬럼값 for 컬럼명 in(집전화번호, 사무실전화번호, 휴대전화번호)) a
WHERE 고객구분코드 = 'VIP
'
SELECT a.고객번호, a.고객명
, (
  case b.no
    when 1 then '집전화번호'
    when 2 then '사무실전화번호'
    when 3 then '휴대폰번호'
  end
) 연락처구분코드
, (
  case b.no
    when 1 then a.집전화번호
    when 2 then a.사무실전화번호
    when 3 then a.휴대폰번호
  end
) 연락처번호
FROM 고객 A
, (SELECT ROWNUM NO FROM DUAL CONNECT BY LEVEL <= 3 ) B
WHERE A.고객구분코드 = 'VIP'
AND b.no in (
   (case when a.집전화번호 is not null then 1 end)
  ,(case when a.사무실전화번호 is not null then 2 end)
  ,(case when a.휴대폰번호 is not null then 3 end)
)
```

57. pivot

```SQL
-- 고객구분코드가 VIP인 고객을 고객연락처와 조인해서 연락처 정보를 pivot(열 데이터를 열 데이터로 전환)

-- 연락처구분코드가 고객연락처 테이블의 식별자를 구성하므로 고객별 언락처는 최대 구분코드 개수로 고정돼 있다.

SELECT A.고객번호, MIN(A.고객명) 고객명
, MIN(CASE WHEN B.연락처구분코드 = 'HOM' then b.연락처번호 end) 집
, MIN(CASE WHEN B.연락처구분코드 = 'OFC' then b.연락처번호 end) 사무실
, MIN(CASE WHEN B.연락처구분코드 = 'MBL' then b.연락처번호 end) 휴대폰
FROM 고객 A, 고객연락처 B
WHERE A.고객구분코드 = 'VIP'
AND B.고객번호 = A.고객번호
GROUP BY B.고객번호

SELECT A.고객번호, A.고객명, B.집, B.사무실, B.휴대폰
FROM 고객 A,
고객연락처 pivot (min(연락처번호) for 연락처구분코드 in ('HOM' AS 집, 'OFC' as 사무실, 'MBL' as 휴대폰))B
WHERE A.고객구분코드 = 'VIP'
AND B.고객번호 = A.고객번호

-- 또는

SELECT A.고객번호, A.고객명, B.집, B.사무실, B.휴대폰
FROM 고객 A,
, (select 고객번호, 집, 사무실, 휴대폰
  from 고객연락처
  pivot (min(연락처번호) for 연락처구분코드 in ('HOM' AS 집, 'OFC' as 사무실, 'MBL' as 휴대폰))B
) b
WHERE A.고객구분코드 = 'VIP'
AND B.고객번호 = A.고객번호
```

58. Pivot
    연락처번호가 고객연락처 테이블의 식별자를 구성하므로 값이 중복되지만 않으면 입력할 수 있는 연락처 개수에 제한이 없다.

이처럼 값의 종류 개수에 제한이 없을 때는 Case문을 활용할 수가 없다.
이럴때 listagg 함수를 사용하면 효과적이다.

```SQL
-- 고객구분코드가 VIP인 고객을 고객연락처와 조인해서 연락처 정보를 pivot(열 데이터를 열 데이터로 전환)

SELECT
a.고객번호, min(a.고객명) 고객명
, listagg('('||b.연락처구분코드||')'||b.연락처번호, ',') within group (order by 연락처구분코드) 연락처
FROM 고객 a, 고객연락처 b
WHERE a.고객구분코드 = 'VIP'
AND  B.고객번호 = A.고객번호
GROUP BY a.고객번호
```

59. 배치프로그램 개선

```SQL
BEGIN

  INSERT INTO ERRLOG
  SELECT TO_CHAR(SYSDATE, 'YYYYMMDD') CH_DTH, 'E01' AS ERR_CD_RHO
  FROM RSTLOG
  WHERE ST01 = 'A'

  ...

  INSERT INTO ERRLOG
  SELECT TO_CHAR(SYSDATE, 'YYYYMMDD') CH_DTH, 'E10' AS ERR_CD_RHO
  FROM RSTLOG
  WHERE ST10 = 'J'

  DELETE FROM RSTLOG;

  COMMIT;

END

  -- 인덱스 구성
  RSTLOG_PK : RMO

  -- 데이터

  -- 1시간 단위로 삭제되는 RSTLOG 테이블에는 보통 10만 건 정도가 저장돼어있음
  -- 첫 번째 sQL의 STO1='A' 조건부터 마지막 SQL_ST10 = 'J' 조건까지의 10개 조건절을 만족하는 데이터는 0.1% 미만
```

문제의 프로그램은 INSERT/SELECT 문을 10번 실행하면서 같은 범위의 데이터를 반복 액세스 하고있다. 첫 번째 SQL의 ST01 = 'A' 조건부터 마지막 ST10 = 'J' 조건까지 10개의 조건절을 만족하는 데이터는 0.1% 미만이라고 했으므로 ST01 ~ ST10 까지 10개 컬럼에 인덱스를 생성하면 I/O 성능은 크게 개선될 것이다.

하지만 인덱슬르 10개 만들면 데이터를 입력하고 삭제하난 프로그램 성능이 느려진다.
인덱스를 생성하지 않고도 I/O 성능을 해결할 방법이 있는지 고민할 필요가 있다.

선으뿐 아니라 데이터 정합성에도 문제가 있다. 1시간 단위로 RSTLOG에서 읽은 데이터 중 일부를 ERRORLOG에 저장하고 RSTLOG 테이블을 초기화한다. 이를 통해 프로그램이 실행되는 동안에도 RSTLOG에 데이터가 입력되는 상황임을 짐작할 수 있다.

조회 대상집합이 계속 증가하는 상황에서 쿼리를 10번에 나눠 싫행하면 ERRLOG 테이블에 입력한 결과 집합의 일관성을 보장할 수 없다.

아래 모범답안처럼 10개 sql 을 한 문장으로 통합하면 문장 수준 일관성은 보장된다.
하지만, 트랜잭션 수준 일관성은 여전히 보장되지 않는다. 즉, INSRT문을 시작한 이후에
RSTLOG 테이블에 입력한 데이터는 조회 대상에서 제외되지만, DELETE 대상에는 포함된다.
트랜잭션 수준의 일관성을 확보하려면 트랜잭션 격리성을 SERIALIZABLE 수준으로 상향 조정해야 한다.

\- 문제점

1. 10만건의 같은 범위 데이터를 반복 엑세스
2. 조회 대상집합이 계속 증가하는 상황에서 데이터에 대한 쿼리를 10번에 나눠 실행해함으로써 ERRLOG 테이블에 입력한 결과집합의 일관성을 회손
3. SELECT와 DELETE 사이에 입력한 rstlog 데이터는 ERRLOG 입력 대상인지 확인하지 않은 채 삭제

```sql
SET TRANSACTION ISOLATION LEVEL SERIALIZABLE;

INSERT INTO ERRLOG
SELECT
FROM RSTLOG A
, (SELECT ROWNUM AS NO FROM DUAL CONNECT BY LEVLE <= 10)B
WHERE (
  ST01 = 'A' OR
  ST02 = 'B' OR
  ST03 = 'C' OR
  ST04 = 'D' OR
  ST05 = 'E' OR
  ST06 = 'F' OR
  ST07 = 'G' OR
  ST08 = 'H' OR
  ST09 = 'I' OR
  ST10 = 'F'
)
AND B.NO IN (
  (CASE WHEN A.ST01 = 'A' THEN 1 END)
  ,(CASE WHEN A.ST02 = 'B' THEN 2 END)
  ,(CASE WHEN A.ST03 = 'Ç' THEN 3 END)
  ,(CASE WHEN A.ST04 = 'D' THEN 4 END)
  ,(CASE WHEN A.ST05 = 'E' THEN 5 END)
  ,(CASE WHEN A.ST06 = 'F' THEN 6 END)
  ,(CASE WHEN A.ST07 = 'G' THEN 7 END)
  ,(CASE WHEN A.ST08 = 'H' THEN 8 END)
  ,(CASE WHEN A.ST09 = 'I' THEN 9 END)
  ,(CASE WHEN A.ST10 = 'J' THEN 10 END);
)

DELETE FROM RSTLOG;
COMMIT;
```

60. UNION ALL

```SQL
  SELECT NVL(A.고객ID, B.고객ID) 고객ID, A.입금액, B.출금액
  FROM
  ( SELECT 고객ID, SUM(입금액) 입금액 FROM 입금 GROUP BY 고객ID) A
  FULL OUTER JOIN
  ( SELECT 고객ID, SUM(출금액) 출금액 FROM 출금 GROUP BY 고객ID) B
  ON A.고객ID = B.고객ID


SELECT 고객ID, SUM(입금액) 입금액, SUM(출금액) 출금액
FROM (
  SELECT 고객id, 입금액, TO_NUMBER(NULL) 출금액
  FROM 입금
  UNION ALL
  SELECT 고객ID, TO_NUMBER(NULL) 입금액, 출금액
  FROM 출금
)
GROUP BY 고객ID
```

61. RUNNING TABLE

```SQL
SELECT  지점코드, 판매월, 매출금액
, SUM(매출금액) OVER (PARTITION BY 지점코드 oRDER BY 판매월
  RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW
) 누적 매출
FROM 월별지점매출

SELECT
FROM 월별지점매출 T1, 월별지점매출 T2
WHERE T2.지점코드 = T1.지점코드
AND T2.판매월 <= T1.판매월
GROUP BY T1.지점코드, T1.판매월
ORDER BY T1.지점코드, T1.판매월
```

62. 최정 변경일자/ 최종 변경순번 조회

100만 개 장비를 모두 출력해야 하므로 부분범위 처리를 위한 인덱스 활용은 고려할 필요가 없다. 전체 데이터를 빠르게 처리하려면 full scan과 해시 조인을 효과적으로 이용할 수 있는 형태로 쿼리를 작성 해야한다.

최종이력을 찾는데는 윈도우 함수를 활용할 수 있다. ROW_NUMER 또는 RANK 함수가 효과적이며, KEEP 절을 이용할 수도 있다.

```sql
SELECT
P.장비번호, P.장비명, P.장비구분코드, H.변경일자, H.변경순번, H.상태코드
FROM 장비 P
, (
  SELECT
  장비번호, 변경일자, 변경순번, 상태코드
  ,ROW_NUMBER() OVER (PARTITION BY 장비번호 ORDER BY 변경일자 DESC) RNUM
  FROM 상태변경이력
) H
WHERE H.장비번호 = P.정비번호
AND H.RNUM = 1;

SELECT
P.장비번호, P.장비명, P.장비구분코드, H.변경일자, H.변경순번, H.상태코드
FROM 장비 P
, (
  SELECT
  장비번호
  , MAX(변경일자) 변경일자
  ,MAX(변경순번 ) KEEP(DENSE_RANK LAST ORDER BY 변경일자, 변경순번) 변경순전
  ,MAX(상태코드) KEEP(DENSE_RANK LAST ORDER BY 변경일자, 변경순번) 상태코드
  FROM 상태변경이력
  GROUP BY 장비번호
) H
WHERE H.장비번호 = P.정비번호
```

63. WITH 구문

WITH 절을 처리하는 DBMS 내부 실행 방식에는 2가지가 있다.

\- MATERIALIZE 방식
내부적으로 임시 테이블을 생성함으로써 반복 재사용

\- INLINE 방식
물리적으로 임시 테이블을 생성하지 않고 참조된 횟수만큼 런타임 시 반복수행.
SQL 문에서 반복적으로 참조되는 집합을 미리 선언함으로써 코드를 단순화
(인라인 뷰와는, 메인 쿼리에서 여러 번 참조가 가능하다는 점에서 다르다)

MATERIALIZE
내에서 다른 WITH 절을 참조할 수 있다.

베치프로그램에서 특정 데이터 집합을 반복적으로 사용하거나, 전체 처리 흐름을 단순화시킬 목적으로 임시 테이블을 자주 사용하는데, 그럴 때 MATERIALIZE 방식의 WITH 절을 이용하면 명시적으로 오브젝트를 생성하지 않고도 같은 처리를 할 수 있다.

```sql
WITH EMP_T AS (
  SELECT /*+*/
  DEPTNO, COUNT(*) CNT
  , ROUND(AVG(SAL)) AVG_SAL, MIN(SAL) MIN_SAL, MAX(SAL) MAX_SAL
  FROM EMP
  GROUP BY DEPTNO
)
SELECT D.DEPTNO, D.NAME, E.CNT, E.AVG_SAL, E.MIN_SAL, E.MAX_SAL
FROM DEPT D, EMP_T E
WHERE E.DPETNO = D.DEPTNO

--- SELECT STATEMENT
--    TEMP TABLE TRANSFORAMTION
--      LOAD AS SELECT
--        HASH GROUP BY
--          TABLE ACCESS FULL EMP
--      HASH JOIN
--        VIEW
---         TABLE ACCESS FULL SYS_TEMP_ADF98
--         TABLE ACCESS FULL DEPT
```

WITH 절을 한 번만 ㅊ마조하면 옵티마이저는 기본적으로 INLINE 방식을 선택하는데, 문제의 실행계획에서는 MATERIALIZE 방식이 사용됐다. 'TEMP TABLE TRANSTFORMATION' 오퍼레이션을 통해 알 수 있다.

이 방식으로 유도하고자할 때 materialize 방식을 사용한다.

내부적으로 GLOBAL TEMPORARY 테이블을 생성해서 TEMP 테이블스페이스에 데이터를 기록한다.

오라클은 GLOBAL TEMPORARY 데이터를 읽을 때 버퍼 캐시를 경유한다. 따라서 원본 데이터를 작은 집합으로 가공하지 않고 그대로 저장했다가 읽는 경우, MATERIALIZE 방식은 성능 개선에 도움이 되지 않는다.

64. WITH 절

```sql
WITH EMP_T AS (
  SELECT /*+*/
  DEPTNO, COUNT(*) CNT
  , ROUND(AVG(SAL)) AVG_SAL, MIN(SAL) MIN_SAL, MAX(SAL) MAX_SAL
  FROM EMP
  GROUP BY DEPTNO
)
SELECT D.DEPTNO, D.NAME, E.CNT, E.AVG_SAL, E.MIN_SAL, E.MAX_SAL
FROM DEPT D, EMP_T E
WHERE E.DPETNO = D.DEPTNO
UNION ALL
SELECT NULL, '전체', ROUND(AVG(CNT)), ROUND(AVG(AVG_SAL)), MIN(MIN_SAL), MAX(MAX_SAL)
FROM EMP_T

-- SELECT STATEMENT
--  UNION-ALL
--    HASH JOIN
--      VIEW
--        HASH GROUP BY
--          TABLE ACCESS FULL EMP
--      TABLE ACESS FULL DEPT
--     SORT AGGREGATE
--      VIEW
--        HASH GROUP BY
--          TABLE ACCESS FULL EMP
```

WITH 절 집합은 두 번이상 참조하면 옵티마이저는 기본적으로 MATERIALIZE 방식을 선택하는데, 문제의 실행계획에서는 iNLINE 방식이 사용되었다.

실행계획에 'TEMP TABLE TRANSTFORMATION' 오퍼레이션이 없는 것을 보고 알 수 있다.

EMP 테이블이 두 번 나타난 사실을 통해서도 알 수 있다.

이 방식으로 유도하고자 할때 inline 힌트를 사용한다.

65. WITH

\- WITH 절에서 참조하는 원본 집홥과 결과집합의 크기 차이가 없을 때, MATERIALIZE 방식으로 수행하면 성능에 도움이 되지 않는다

\- with 절에서 처리하는 원본 집합이 작고 동시에 수행빈도가 높을때 MATERIALIZE 방식으로 수행하면 성능에 좋다.

\- 매우 많은 데이터를 읽어 GROUP BY,조인 등을 통해 집합의 크기를 많이 줄일 수 있을때 좋다.

\- 절차적 프로그램 패턴을 집합적인 처리 패텬으로 전환하고자할때 성슨에 큰 도움이 된다.

WITH 절을 MATERIALIZE 방식으로 수행하면 중간 집합을 만든느 과정에서 dist i/o가 수반된다.

따라서 with 절에서 처리하는 원본 집합이 작고 동시에 수행빈도가 높을때 MATERIALIZE 방식으로 수행하면 성능에 매우 좋지 않다.

수행빈도가 높지 않더라도 WITH 절에서 참조하는 원본 집합과 결과집합의 크기 차이가 없을 때 MATERIALIZE 방식으로 수행하면 오히려 성능이 나빠질 수 있다.
원본 집합을 읽어 TEMP 공간에 기록하는 과정을 수반하며, 읽을 때도 일반 테이블처럼 버퍼 캐시 경유하기 때문이다. 반대로 매우 많은 데이터를 읽어 GROUP BY, 조인등을 통해 집합 크기를 많이 줄일 수 있을 때는 성능에 큰 도움이 된다.
