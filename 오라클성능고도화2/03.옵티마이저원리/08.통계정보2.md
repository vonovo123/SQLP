### 전략적인 통계수집 정책의 중요성

#### CBO 능력을 최대로 끌어올리는 핵심요소

통계정보가 CBO에 미치는 영향은 절대적이다.

통계정보에 이상이 있다면 옵티마이저가 최선의 판단할 수 없다.

#### 통계정보 수집 시 고려사항

\- 시간 : 부하가 없는 시간대에 가능한 빠르게 수집을 완료해야 함
\- 샘플크기 : 가능한 적은 양의 데이터를 읽어야 함
\- 정확성 : 전수 검사할 때의 통계치에 근접해야 함
\- 안정성 : 데이터에 큰 변화가 없는데 매번 통계치가 바뀌지 않아야 함.

가장 짧은 시간 내에 꼭 필요한 만큼만 데이터를 읽어 충분한 신뢰수준을 갖춘 안정적인 통계정보를 옵티마이저에게 제공하려면 전략이 자신이 관리하는 시스템 여건에 맞는 전략이 필요하다.

어떤 테이블은 여러 파티션에 골고루 갱신이 이루어지고, 어떤 테이블은 특정 파티션에만 갱신이 이루어진다.

유지보수를 위한 서비스 다운타임이 매일 확보되는 시스템이 있는가하면 풀타임으로 가용성이 요구되는 시스템도 있다.

OLTP냐 DW냐에 따라 다른 전략을 사용해야한다.

데이터 자체 특성에 따라서도 다른 전략이 필요하다.

만약 샘플크기를 최소화하더라도 정확성, 안정성을 확보할 수 있다면 시간을 크게 줄일 수 있지만 그렇지 않다면 시간이 오래 걸리더라도 전수 검사를 해야한다.

#### 주기적으로 통계 수집하면서 안정적이어야 최적

통계정보의 중요성은 좋은 실행계획을 통해 쿼리 성능을 높이는데 있다.

따라서 정확성이 무엇보다 중요하며, OLAP처럼 비정형 쿼리가 많은 시스템에선 시스템 성능을 결정짓는 중요한 변수로 작용한다.

하지만 절대적인 최적의 성능을 구현하기보다는 안정적인 운영을바라는 OLTP 시스템이라면 통계정보의 안정성이 더 중요할 수 있다.

그런 연유로, 통계정보 수집을 꺼리는 DB 관리자도 있다.

통계정본를 주기적으로 수집하면서도 안정적으로 운영되는 시스템이야말로 최적이며, 이를 위해선 시스템 환경에 맞는 통계수집이 반드시 필요하다.

#### 통계 수집 정책 수립은 필수

통계를 수집할 필요가 없는 오브잭트에 대해서는 LOCK 옵션으로 통계정보를 고정할 수 있다.

통계정보의 영향을 받아선 안되는 중요 일부 핵심 프로그램의 경우 옵티마이저 힌트를 이용해 실행계획을 고정하는 것이 최선이다.

운영 DB에 수집한 통계정보를 개발 DB에도 반영한 상태에서 개발을 진행해야하며, 배포 전 충분한 테스트를 거쳐야 한다.

운영 서버와 테스트 서버 간 오브젝트 통계뿐 아니라 시스템 통계도 일치해야 한다. 옵티마이저 관련 파라미터도 일치해야한다.

통계정보의 변화 때문에 앱 성능에 문제가 발생했을때를 대비해 가장 안정적인 통계정보를 백업해둬야 한다.

오브젝트별 통계수집 주기와 샘플링 비율을 표로 정리해둬야 한다

데이터베이스 설계 시 주요 태스크로 진행해야 하고, 이를 기준으로 스크립트를 작성해 시스템 오픈 전에 적정성 여부를 테스트해야한다.

시스템 환경에 따라 최적 통계수집 정책을 수집하기 위해 다음과 같은 옵션을 선택할 수 있다.

### DBMS_STATS

통계정보 수집을 위해 DBMS_STATS 패키지를 사용한다.

---

#### 아직 deprecated 되지 않는 Analyze 명령어

- Freelist 블록 정보 수집 : avg_space_freelist_blocks, num_freelist_blocks

\- 체인이 발생한 로우 개수 확인 : chain_cnt

\- list chained rows : 로우 체인 또는 마이그레이션이 발생한 로우 식별

analyze emp list chained rows into chained_rows;

\- validate : 정합성이 깨진 데이터 블록이나 로우가 있는지 검증

analyze table emp validate structure;

테이블별 로우체인 발생 현환은 주기적으로 진단할 필요가있다.

dbms_stats 패키지로 통계정보를 수집할 때, 기존에 chain_Cnt 항목이 구해져 있으면 그대로두고 Null 이면 0으로 입력한다.

따라서 Dba/user/all_tables 뷰에서 이 항목이 0으로 조회된다고 해서 체인이 젼혀 발생하지 않은것이 아니다.

아래 쿼리를 통해 체인에 의한 로우 액세스 발생 현황을 주기적으로 점검하다가 계속 수치가 증가한다고 판단되면 analyze 문장의 list chained rows 기능을 이용해

체인이 많이 발생한 테이블을 찾아야한다.

```sql
select *
from  v$sysstat
where name in ('table fetch by rowid', 'table fetch continued row')
```

---

dbms_stats.gater_table_stats 프로시저의 인자는 다음과 같다.

\- ownname : 테이블에 속한 스키마명
\- tabname : 테이블명
\- partname : 파티션명
\- estinate_percent :

샘플링 크기를 퍼센트로 지정
0.000001에서 100까지 지정가능, null은 전수검사를 의미, dbms_stats.auto_sample_size를 지정하면 오라클이 지정한 크기로 샘플링

\- block_sample : true 면 블록 단위 샘플링, false 면 로우 단위 샘플링, 블록 단위 샘플링이 더 효율적이지만 정확성은 떨어짐, 기본 값은 false
compute 모드에서는 이 옵션을 지정해도 무시된다.

\- method_opt : 컬럼 통계 및 히스토그램과 관련한 옵션 지정

for all columns size 75
for columns col1 size 10, col2 size 20
for column size 20 col1,col2

size에는 히스토그램 개수를 지정하는 정수 값 외에도 다음곽 같은 옵션을 지정할 수 있다.

size(integer | repeat | auto | skowonly)

repeat : 히스코그램이 기존에 생성돼 있떤 컬럼에만 히스토그램 수집
skewonly : 데이터 분포를 분석해 균일하지 않을 때만 히스토그램 생성
auto : 컬럼이 조건절에 사용되는 비중과 데이터 분포를 기준으로 오라클이 결정

기본 값은 For all columns size auto

\- degree : 병렬도를 지정함으로써 여러 프로세스가 동시에 통계정보를 수집하도록함

\- granularity : 파티션 테이블일 때, 통계 수집 레벨을 결정

global : 글로벌 통계만
partition : 파티션 레벨 통계만
subpartition : 서브파티션 레벨 통계만
global and partition : 글로벌과 파티션 레벨 통계만
all : 글로벌, 파티션, 서브파티션 모두
auto : 파티셔닝 유형에 따라 오라클이 결정

\- cascade : 테이블에 속한 모든 인덱스에도 통계를 수집. 각 인덱스마다 Gather_index_stats 프로시저를 따로 수행하는 것과 일량이 같음

\- no_invalidate : 라이브러리 캐시에 캐싱된 커서를 무효화할지 결정

True : 연관된 커서를 무효화하지 않는다.
false: 연관된 커스를 무효화

9i 는 true, 10G는 true가 기본

### 컬럼 히스토그램 수집

히스토그램을 가지면 더 나은 실행계획을 수립하는데 도움이 되지만 수집하고 관리하는 비용이 크다.

따라서 필요한 컬럼에만 히스토그램을 수집해야 하며, 조건절에 자주 사용되면서 편중된 데이터 분포를 갖는 컬럼이 주 대상이다.

인덱스 컬럼에만 히스토그램이 필요하다고 생각하기 쉬운데 그렇지 않다.

테이블을 엑세스하고 나서의 최종 선택도를 계산할 때는 인덱스가 없는 조건절 컬럼의 선택도도 인자로 사용하고, 그렇게 구해진 선택도에 따라 다른 집합과의

조인 순서 및 조인 방식이 결정되기 때문에 히스토그램이 필요하다.

아래와 같은 컬럼에는 히스토그램이 붎리요하다.

\- 컬럼 데이터 분포가 균일
\- Unique하고 항상 등치조건으로만 검색되는 컬럼
\- 항상 바인드 변수로 검색되는 컬럼

dmbs_stats.gather_table_stats에서 컬럼 히스토그램 수집과 관련된 인자는 method_opt이다.

for all coumns size auto 는 오라클이 모든 컬럼에대해 skew 여부를 조사해서 버킷 개수를 결정하라는 뜻이다.

auto와 skewonly와 다른 점은 해당 컬럼이 조건절에 사용되는 비중까지 고려해 결정한다는 점이다.

이를 위해 오라클은 sys.col_usage$ 뷰를 참조한다.

10g에서 dbms_stats의 기본 동작 방식이 바뀐 것이다.

없던 히스토그램이 생기면서 주요 sql의 실행계획이 오히려 나쁜 쪽으로 바뀌는 예도있고 수집 시간이 늘어나는 문제도 간과할 수없다.

큰 테이블일수록 디스크 소트 부하 때문에 시간이 오래걸린다.

통계수집에 걸리는 시간이 짧은 테이블은 기본 값으로 둬도 상관없지만 대용량 테이블일 경우 관리자가 직접 히스토그램 수집을 해 주는것이 바람직하다

```sql
method_opt => 'for columns col1 size 20 col2 size 254 col3 size 100'
```

10g부터는 기본 값을 table-driven 방식으로 관리하므로 만약 기본 동작 방식이 문제를 일으미켬 dbms_stats.set_param 프로시절르 통해 기본 값을 이전처럼 돌려 놓을 수 있따.

### 데이터 샘플링

샘풀링 비율을 높일수록 정확도는 높아지지만 수집에 더 많은 시간이 소요된다.

반대로 샘플링 비율을 낮추면 정확도는 떨어지지만 효율적이고 빠른 통계를 수집할 수 있다.

#### 샘플링 비율

dbms_stats 패키지에서 샘플링 비율을 조정하기위해 estimate_percent 인자를 사용한다.

각 테이블별로 적정 샘플링 비율을 조사할 필요가 있는데 모든 테이블을 조사 대상으로 삼기는 쉽지 않으므로 가장 큰 몇몇 테이블만 그렇게 하더라도 상당한 효과가 있다.

5%에서 시작해 값을 늘려가며 두세번만 통계를 수집해 보면 적정 크기를 정할 수 있다.

#### 블록단위샘플링

block_sample 인자를 통해 블록 단위 샘플링 할지 로우 단위 샘플링할지 결정한다. 블록 단위가 빠르고 효율적이지만 데이터 분포가 고르지 않을 때 정확도가 떨어진다.

#### 안정적인 통계정보의 필요성

샘플링 방식은 매번 통계치가 다르게 나올 수 있다.

특히 컬럼에 null이 많거나 데이터 분포가 고르지 않을 때 그렇다.

선택도를 구하는 공식의 세가지 구성요소가 null 값을 제외한 로우수, distinc value 개수, 총 레코드 개수이다.

총 레코드 개수를 제외한 나머지 두 통계치는 컬럼 분포가 고르지 않ㅇ르 때 샘플링에 의해 영향을 크게 받는다.

#### 해시 기반 알고리즘으로 NDV 계산

컬럼 히스토그램을 사용할 수 없을때는 the number of distinct values 로 선택도를 계산하므로

이 값의 정확도가 매우 중요하다. 분포가 고르지 않은 상황에서 샘플링 방식을 사용하면 이 값이 매번 다르게 구해진다.

해시 기반의 새로운 알고리즘은 대용량 파티션 또는 테이블 전체를 스캔하더라도 기존에 샘플링 방식을 사용할 때보다 오히려 빠른 속도를 낼 수 있다.

소트를 수행하지 않기 때문이며, 전체를 대상으로 NDV를 구하므로 정확도는 당연히 빠르고 안정적이다.

### 파티션 테이블 통계 수집

파티션 테이블일 때 오라클은 테이블 레벨 통계와 파티션 레벨 통계를 따로 관맇나다.

\- 파티션 레벨 통계 : Static Partition Pruning 이 작동할 때 사용된다.
결합 파티션일 때는 서브파티션 레벨로 통계를 관리할 수 있다.

\- 테이블 레벨 통계 : Dynamic Partition Pruning 이 작동할 때 사용된다.
쿼리에 바인드변수가 사용됐거나 파티션 테이블이 NL 조인에서 Inner 쪽 테이블이면 액세스해야 할 대상 파티션 목록을 쿼리 최적화 시점에 정할 수 없기 때문이다.
또한 파티션 키에 대한 조건절이 없을 때도 테이블 레벨 통계가 사용된다.

analyze 명령을 이용해 통계정보를 구하는 것은 deprecated 된 기능인데, 파티션 테이블일때 특히 그렇다.

dbms_stats는 Global 통계를 위한 쿼리를 별도로 수행하는 반면, analyze는 파티션 통계를 갖고 global 통계를 유추하므로 부정확하다.

dbms_stats 패키지를 이용해 파티션 테이블의 통계를 수집할 때는 granualrity 옵션을 신중하게 선택해줘야한다.

\- global : 테이블 레벨 통계 수집
\- partition : 파티션 레벨 통계 수집
\- subpartition : 서브 파티션 레벨 통계 수집
\- global and partition : 테이블과 파티션 레벨 통계 수집
\- all : 테이블, 파티션, 서브파티션 레벨 통계 수집
\- auto : 파티션 유형에 따라 오라클이 결정

global은 테이블 레벨 통계를 수집하고 partition은 파티션 레벨 통계를 수집한다.

파티션 레벨 통계를 수집할 때 테이블 레벨 통계가 미리 수집돼 있으면 그대로 두지만, 그렇지 않을 때는 파티션 레벨 통계로부터 추정된 값으로 테이블 레벨 통계를 설정ㅎ나다.

dba/all/user_tables에서 볼 수 있는 항목 중 global_Stats는 테이블 레벨 통계 수치들이 어떻게 구해졌는지 알려준다.

테이블 레벨 통계를 따로 수집했다면 YES, 파티션 통계를 이용해 추정했다면 no로 표시된다.

같이 수집하려면 global and partiton 을 선택하면 된다.

내부적으로 global 통계를 위한 쿼리를 한 번 더 수행하므로 각각 수집할때와 속도차ㅣ이는 없다.

파티션 통계를 이용해 테이블 전체 통계를 구하지않는이유는 NDV 때문이다. 어떤 컬럼의 NDV가 파티션 P1과 P2에서 각각 10개와 20개일 때 테이블 레벨 NDV를 추정할 수 없다.

Range 파티션 테이블은 새 파텨신을 추가하면 그 곳에만 데이터가 입력되는데 통계를 수집하려고 대용량 파티션 테이블 전체를 두 번 스캔하는 것은 문제가있다.

반대로 데이터가 입력되는 파티션만 통계정보를 계속 갱신한다면 테이블 통계는 어느 순간 부정확한 상태가 된다.

NDV는 물론 low_value/high_valeu와 히스토그램이 특히 그렇다.

10g 이하 버전에서는 최근 파티션만 통계를 수집하고 테이블 전체 통계를 한 번 더 수행하는 것이 효과적이다.

#### NDV를 제외한 Incremental Global 통계

10.2.04. 버번 부터 granularity 인자에 선택할 수 있는 값으로 approx_global and partition이 추가됐다.

global and partition 과 다른 점은 테이블 통계를 위한 쿼리를 따로 수행하지 않고 파티션 레벨 통계로부터 집계한다는데 있다.

테이블 레벨 컬럼 히스토그램도 파티션 레벨로부터 집계한다.

단, 컬럼 NDV와 인덱스 Distinct Key의 수는 제외된다.

이와 같이 하면 파티션 통계만 수집하고 NDV를 제외한 나머지 테이블 레벨 통계는 방금 수집한 새 파티션 통계와 다른 파티션의 기존 통계를 이용해 구한다.

기본적으로 테이블 레벨 NDV는 갱신하지 않고 그대로 두지만 경우에 따라서는 갱신이 이루어지기도 한다.

파티션 통계로부터 이 값을 정확히 구할 수 있는 경우로, Unique 인덱스를 가진 컬럼이나 파티션 키 컬럼이 여기 해당한다.

Unique 인덱스를 가진 컬럼은 전체 레코드 개수가 NDV와 일치하고, 파티션 키 컬럼은 파티션 레벨 NDV를 더한 테이블 레벨 NDVrk dlfclgksek.

NDV가 자주바뀌는 통계치는 아니므로 매번 갱신하지 않아도 문제는 없다.

새로운 값이 계속 입력되는 컬럼은 NDV보다 주로 Low_value/high_value 때문에 문제가 발생한다.

통계정보에 저장된 최대최소 값을 초과하는 값으로 조회하면 카디널리티가 무조건 1로 계산되기 때문이다.

따라서 매일 갱신해야하는데 이 두 통계치는 기존 파티션 통계와 추가된 파티션 통계로부터 정확한 테이블 레벨 통계를 구할 수 있다.

#### NDV를 포함한 완벽한 Incremental Global 통계

전체 데이터를 읽지만 소트 없이 해시방식으로 빠르게 NDV를 구하고, 파티션 레벨 NDV를 이용해 Global NDV를 정확히 구하는 방법이다.

오라클은 NDV를 포함한 Incremental Global 통계 수집기능을 제공하려고 파티션 레벨 컬럼별로 synopsis라고 하는 별도의 메타 데이터를 관리한다.

synopsis는 Distinct value에 대한 샘플이다.

모든 파티션마다 각 컬럼이 갖는 값의 집합을 보관했다가 이를 머지함으로써 Global NDV를 구한다.

아래와 같이 프로시저를 호출해 필요한 테이블별로 활성화한다.

```sql
begin
  dbms_stats.set_table_prefs('obs', 'order', 'incremental', 'true')
end;

begin
  dbms_stats.gather_Table_stats('ods','order', granularity => 'global and partition', estimate_perent=>20)
```

기존 방식대로 global and partition 옵션을 지정했지만 테이블 전체를 두 번 읽지는 않으며, 통계정보가 누락되었거나 stale 상태에 있는 파티션만 통계를 수집한다.

그리고 나서 파티션 레벨 통계와 synopsiss를 이용해 테이블 레벨 Global 통계를 갱신한다.

### 인덱스 통계 수집과

테이블 통계를 수집하면서 cascade ㅐㅔ샤ㅐㅜdmf TRUE로 설정하면 테이블에 속한 모든 인덱스 통계도 같이 수집된다.

문제는 대용량 테이블이어서 샘플링 비율을 지정하면 인덱스 통계까지도 같은 비율이 적용되는데 있다.

인덱스 통계 수집에 걸리는 시간은 매우 짧아서 샘플링 방식이 필요 없다.

그럴 때 아래와 같이 테이블 통계만 샘플링을 사용하고, 인덱스는 전수 검사하도록 각기 통계를 수집하는 것이 좋다.

```sql
-- 테이블 통계는 estimate mode
begin
dbms_stats.gather_Table_Stats(user, 'big_table', cascade=>false
,estimate_percent => 10);

-- 인덱스 통계는 compute mode
dbms_stats.gather_index_stats(user, 'big_table_pk' ,estimate_percent => 100);
dbms_stats.gather_index_stats(user, 'big_table_x1' ,estimate_percent => 100);

```

10g 부터는 인덱스를 처음 생성하거나 재생성할 때 인덱스 통계가 자동 수집되며, \_optimizser_compute_index_stats 파라미터를 통해 설정을 변경할 수 있다.

### 캐싱된 커서 invalidation

no_invalidate 옵션을 어떻게 지정하느냐에 따라 통계를 수집한 테이블과 관련한 SQL, 커서 무효화 시점이 달라진다.

\- false : 통계정보 변경 시 관련된 SQL 커서들이 즉시 무효화된다. 곧이어 첫 번째 수행하는 세션에 의해, 새로 갱신된 통계정보를 이용한 실행계획이 로드(하드파싱)된다.
\- true : 통계정보 변경 시 관련된 SQL 커서들을 무효화하지 않는다. SQL 커서가 자동으로 Shared Pool에서 밀려났다가 다시 로드될 때 비로소 새로 갱신된 통계정보를 사용한다.
\- dbms_stats.autu_invalidate : 통계정보 변경 시 관련된 SQL 커서들을 한꺼번에 무효화하지 않고 정해진 시간동안 조금씩 무효화한다.
무효화된 수많은 커서가 동시에 수행되면서 하드파싱에 의한 라이브러리 캐싱 경합이 발생하는 현상을 방지한다.

중요한 것은, 9i에서 false이던 기본 값이 10g에서 dbms_stats.auto_invalidate로 바뀌었다는 사실이다.

따라서 기존 통계 수집 스크립트를 그대로 사용하면 관련 sql 커서들이 곧바로 무효화되지 않는 현상이 발생한다.

이 기능을 제어하는 파라미터는 \_optimizer_invalidation_period이고 ,기본 값은 18,000초이다. 늦어도 5시간 이내에는 관련 sql 커서가 무효화된다.

### 자동 통계 수집

오라클 10g 부터 기본적으로 매일 밤 10시부터 다음날 아침 6시까지 모든 사용자 오브젝트에 대한 통계를 자동 수집하도록 job이 등록돼있다.

이 기능은 gather_stats_job에 의해 자동 수행되며, 통계정보가 없거나 통계정보 수집 후 dml이 많이 발생한 모든 오브잭트를 대상으로 한다.

#### gather_stats_job

데이터베이스 생성 시 자동으로 등록되며, Maintenance 윈도우 그룹에 등록된 윈도우가 열릴 때마다 스캐줄러에 의해 수행된다.

Maintenance 윈도우 그룹에는 아래 두 개 윈도우가 등록돼 있다.

\- weeknighat_window : 월요일부터 금요일까지 5일 동안, 매일 밤 10시부터 다음날 아침 6시까지 8시간 동안 열림
\- weekend_window : 토요일 새벽 0시부터 2일동안 열림

자동 통계 수집 기능을 사용하지 않으려면 스캐줄러 job을 제거한다.

#### 통계정보 갱신 대상 식별

오라클은 통계정보 수집이 필요한 오브젝트인지를 판별하기 위해 테이블 모니터링 기능을 제공한다.

9i에서는 nomonitoring 옵션이 기본이었꼬 필요한 테이블에만 관리자가 monitoring 옵션을 지정했지만 10G에서는 이 옵션이 아예 deprecate 돼 모든 사용자 테이블이 모니터링되고 있다.

alter table emp monitoring;

statistics_level이 typical 또는 all일 때 오라클은, monitoring 옵션이 지정된 테이블에 발행하는 DML 발생량을 모니터링한다.

수집된 테이블별 DML 발생량은 \*\_tab_modifications 뷰를 통해 조회해 볼 수 있으며, insert, updates, deletes 컬럼에 표시된 수치는 마지막 통계정보가 수집된 이후 DML 발생량이다.

오라클은 모니터링 대상 테이블에 10% 이상 변경이 발생했을 때 해당 테이블을 stale 상태( \*\_tab_modifications 뷰에서 stale_Stats = 'YES')로 바꾼다.

그러고 나서 gather_database_stats 또는 gather_schema_Stats 프로시저를 호출하면서 option 인자에 gather stale 또는 gather auto를 지정하면 stale 상태인 테이블들에 대한 통계정보를 새로 수집한다.

11g에서는 stale 상태로 바뀌는 임계치를 오브젝트별로 조정할 수 있다.

#### 자동 통계 수집 기능 활용 가이드

중대형 DB의 경우 Maintenance 윈도우 이내의 통계 수집이 완료되지 않는 경우가 생기면 시스템이 불안정해질 수 있다.

될 수 있으면 오브젝트별 전략을 세우고 가장 짧은 시간 내에 정확하고 안정적ㅇ니 통계정보를 수집할 수 있도록 스크립트를 준비해야한다.

11G 부터 자동 통계 수집 기능이 좋아졌다고 하더라도 오브젝트별 수집 전략을 여전히 필요하다.

개별 오브젝트 별 선택사양을 입력해 두면 자동 수집 기능이 작동할 때 오라클이 그 내용에 따라 통계정보를 수집해 준다.

### Statistic Preference

오라클 10g의 경우 자동 통계 수집 기능을 그대로 사용하는데 무리가 있다. Gather_stats_job을 제거하고 시스템 환경과 앱특성에 맞게 설계된 별도의 프로시저를 작성해서 job에 등록해주는 것이 바람직하다.

기본설정을 적용하고 싶지 않읂 오브젝트에만 Lock을 설정(dbms_stats.lock_table_tats procedure) 한 상태에서 전체 통계를 수집하는 방법이 있다.

전체 통계 수집이 끝나면 lock을 설정했던 오브젝트에 lock을 풀고 통계를 수집하는 별도의 Job을 수행하면 된다.

11G에서는 Statistics Preference 라고 불리는 기능을 제공하는데 gather_Stats_job을 그대로 활성화한 상태에서

테이블 또는 스키마 별로 통계 수집 방식을 따로 설정할 수 있게 한다.

그러면 자동 통계 수집 기능이 작동할 때마다 해당 테이블 또는 스키마에 대해서는 기본 설정 값을 무시하고 사용자 지시사항에 따라 통계정보를 수집한다

```sql
begin
  dbms_stats.set_table_prefs('ods','order', 'method_opt', 'for all indexed columns size auto');
  dbms_stats.set_table_prefs('ods','order', 'estimate_percent', dbms_stats.auto_sample_size);
end;
/

exec dbms_stats.gather_schema_stats('ods');
```

아래 뷰를 통해 테이블 별로 preference가 어떻게 설정돼 있는지 조회할 수 있다.

select \* from dba_tab_stat_prefs;
