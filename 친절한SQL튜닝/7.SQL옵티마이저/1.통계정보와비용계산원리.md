SQL 튜닝뿐 아니라 데이터베이스를 안정적으로 관리하기 위해서도 옵티마이저에 대한 정확한 이유가 필요하다.
옵티마이저가 통계정보를 어떻게 활요하는지는 간략하게라도 알고있는 것이 좋다.

---

# 선택도와 카디널리티

선택도란, 전체 레코드 중에서 조건절에 의해 선택되는 레코드 비율을 말한다.

'=' 조건으로 검색할 때의 선택도만 살펴보면, 컬럼 값 종류 개수(NDV) 를 이용해 아래와 같이 구한다.

선택도 = 1 / NDV(NUMBER OF DISTINCT VALUES)

카디널리티란, 전체 레코드 중에서 조건절에 의해 선택되는 레코드 개수이며, 아래 공식으로 구한다.

카디널리티 = 총 로우 수 \* 선택도 = 총 로우 수 / NDV

예를 들어, 상품분류 컬럼에 '가전', '의류', '식음료', '생활용품' 네 개의 값이 있을 때, 아래 조건절에 대한 선택도는 25% 이다.
만약 전체 레코드(로우 수) 가 10만 건이면, 카디널리티는 2만 5천이다.

WHERE 상품분류 = '가전'

옵티마이저는 이렇게 카디널리티를 구하고, 그만큼의 데이터를 엑세스하는 데 드는 비용을 계산해 테이블 액세스 방식, 조인 순서, 조인 방식 등을 결정한다.

공식을 통해 알 수 있듯, 비용을 계산하는 출발점은 선택도다. 선택도를 잘못 계산하면, 카디널리티와 비용도 잘못 계산하고, 결과적으로 비효율적인 엑세스 방식과 조인 방식을 선택하게 된다.

선택도를 계산할 때 NDV를 사용하므로 통계정보 수집 과정에서 이 값을 정확히 구하는 것이 매우 중요하다.

통계정보 수집주기, 샘플링 비율 등을 잘 결정해야 하는 이유다.

---

# 통계정보

통계정보에는 오브젝트 통계와 시스템 통계가 있다. 오브젝트 통계는 다시 테이블 통계, 인덱스 통계, 칼럼 통계로 나뉜다.

## 테이블 통계

테이블 통계를 수집하는 명령은 다음과 같다.

```SQL
EXECUTE DBMS_STATS.GATHER_TABLE_STATS('SYSTEM', 'T_USR60');
```

수집된 테이블 통계정보는 아래와 같이 조회할 수 있고, all_tab_statistics 뷰에서도 같은 정보를 확인할 수 있다.

```sql
-- NUM_ROWS : 테이블에 저장된 총 레코드 개수
-- BLOCKS : 테이블 블록 수 = '사용된' 익스텐트(데이터가 한 건이라도 입력된 적이 있는 모든 익스텐트)에 속한 총 블록 수
-- AVG_ROW_LEN : 레코드당 평균 길이
-- SMAPLE_SIZE : 샘플링한 레코드 수
-- LAST_ ANALYZED : 통계정보 수집일시
select num_rows, blocks, avg_row_len, sample_size, last_analyzed
from all_tables
where owner = 'SYSTEM'
AND table_name = 'T_BBM60'
```

## 인덱스 통계

인텍스 통계를 수집하는 명령어는 다음과 같다

```sql
-- 인덱스 통계만 수집
EXECUTE dbms_stats.gather_index_stats(ownname => 'SYSTEM', indname => 'IDX_T_BBM60');

-- 테이블 통계를 수집하면서 인덱스 통계도 같이 수집
EXECUTE dbms_stats.gather_table_stats('SYSTEM', 'T_BBM60', CASCADE=>TRUE);

```

수집된 인덱스 통계정보는 아래와 같이 조회할 수 있으며, ALL_IND_STATISTICS 뷰에서도 같은 정보를 확이날 수 있다.

```sql
-- BLEVEL : 브랜치 레벨의 약자, 인덱스 루트에서 리프 블록에 도달하기 직전까지 읽게 되는 블록수(인덱스 수직저 탐색 비용 계산)
-- LEAF_BLOCKS : 인덱스 리프 블록 총 개수 (인덱스 수평적 탐색 비용 계산)
-- NUM_ROWS : 인덱스에 저장된 레코드 개수 (인덱스 수평적 탐색 비용 계산)
-- DISTINT_KEYS : 인덱스 키 값의 조합으로 만들어지는 값의 종류 개수 (인덱스 수평적 탐색 비용 계산)
-- AVG_LEAF_BLOCKS_PER_KEY : 인덱스 키값을 모두 '=' 조건으로 조회할 때 읽게 될 리프 블록 개수 (인덱스 수평적 탐색 비용 계산)
-- AVG_DATA_BLOCKS_PER_KEY : 인덱스 키값을 모두 = 조건으로 조회할 때 읽게 될 테이블 블록 수 (테이블 액세스 비용 계산)
-- CLUSTERNG_FACTOR : 인덱스 키값 기준으로 테이블 데이터가 모여 있는 정도, 인덱스 전체 레코드를 스캔하면서 테이블 레코드를 찾아 갈때 읽게 된 테이블 블록 수를
-- 미리 계산해 놓은 수치이다. (테이블 액세스 비용 계산)

SELECT BLEVEL, LEAF_BLOCKS, NUM_ROWS, DISTINCT_KEYS
,AVG_LEAF_BLOCKS_PER_KEY, AVG_DATA_BLOCKS_PER_KEY, CLUSTERING_FACTOR
,SAMPLE_SIZE, LAST_ANALYZED
FROM ALL_INDEXES
WHERE OWNER = 'SYSTEM'
AND TABLE_NAME = 'T_BBM60'
AND INDEX_NAME = 'IDX_T_BBM60';

--    BLEVEL LEAF_BLOCKS NUM_ROWS DISTINCT_KEYS AVG_LEAF_BLOCKS_PER_KEY AVG_DATA_BLOCKS_PER_KEY CLUSTERING_FACTOR SAMPLE_SIZE LAST_ANAL
---------- ----------- ---------- ------------- ----------------------- ----------------------- ----------------- ----------- ---------
--	 2	      3470	    1000000	    631922 		              1 		                1 	                999928     1000000 28-JUL-23


```

\- DISTINCT_KEYS : 인덱스 키값의 조합으로 만들어지는 값의 종류 개수, 예를 들어, c1+C2로 구성된 인덱스에서 C1 칼럼에 3개, C2 컬럼에 4개 값이 있으면 최대 12개 값의 종류가 만들어진다.
인덱스에 저장된 데이터를 기준으로 실제 입력된 갑의 종류 개수를 구해 놓은 수치이다.
인덱스 키값을 모두 = 로 조회할때의 선택도를 계산하는데 쓰인다

## 컬럼 통계

컬럼 통계는 테이블 통계 수집할 때 함께 수집된다. 수집된 컬럼 통계정보는 아래와 같이 조회할 수 있다. all_tab_col_statstcs 뷰에서도 같은 정보를 확인할 수 있다.

```sql
-- NUM_DISTINCT : 컬럼 값의 종류 개수
-- DENSITY : '=' 조건으로 검색할 때의 선택도를 미리 구해 놓은 값. 히스토그램이 없거나 있더라도 100% 균일한 분포를 갖는다면, 1/NUM_DISTINT 값과 일치
-- AVG_COL_LEN : 컬럼 평균 길이
-- LOW_VALUE : 최소 값
-- HIGH_VALUE : 최대 값
-- NUM_NULLS : 값이 NULL 인 레코드 수
SELECT NUM_DISTINCT, DENSITY, AVG_COL_LEN, LOW_VALUE, HIGH_VALUE, NUM_NULLS,LAST_ANALYZED, SAMPLE_SIZE
FROM ALL_TAB_COLUMNS
WHERE OWNER  = 'SYSTEM'
AND TABLE_NAME = 'T_BBM60'
AND COLUMN_NAME = 'BBM_NO'
```

### 컬럼 히스토그램

'=' 조건에 대한 선택도는 1/NUM_DISTINC 공식으로 구하거나 미리 구해 놓은 DENSITY 값을 이용하면 된다.
일반적인 컬럼에는 이 공식이 비교적 잘 들어맞지만, 데이터 분포가 균일하지 않은 컬럼에는 그렇지 못하다.
선택도를 잘못 구하면 데이터 액세스 비용을 잘못 산정하게 되고, 결국 최적이 아닌 실행계획으로 이어진다. 그래서 옵티마이저는 일반적인 컬럼 통계 외에 히스토그램을 추가로 활용한다

히스토그램은 컬럼 값별로 데이터 비중 또는 빈도를 미리 계산해 놓은 통계정보이다. 실제 데이터를 읽어서 계산해 둔 값이므로 데이터 분포가 많이 변하지 않는 한 거의 정확하다.

오라클 12C에서 사용하는 히스토그램 유형으로는 네가지가 있다.

\- 도수분포 : 값별로 빈도수 저장

\- 높이균형 : 각 버킷의 높이가 동일하도록 데이터 분포 관리

\- 상위도수분포 : 많은 레코드를 가진 상위 N개 값에 대한 빈도수 저장

\- 하이브리드 : 도수분포와 높이균형 히스토그램의 특성 결합

히스토그램을 수집하려면, 테이블 통계 수집할 때 아래와 같이 Method_opt 파라미터를 지정하면 된다.

```sql
execute dbms_stats.gather_table_stats("system", "T_BBM60" , cascade => false, method_opt => 'for columns ename size 10, deptno size 4');

EXECUTE DBMS_STATS.GATHER_TABLE_STATS("SYSTEM", "T_BBM60", CASCADE=>FALSE, METHOD_OPT=> 'FOR ALL COLUMNS SIZE 75');

EXECUTE DBMS_STATS.GATHER_TABLE_STATS("SYSTEM", "T_BBM60", CASCAE=>FALSE, METHOD_OPT=>'FOR ALL COLUMNS SIZE AUTO');
```

수집된 컬럼 히스토그램은 아래와 같이 조회할 수 있다. all_tab_histograms 뷰에서도 같은 정보를 확인할 수 있다.

```sql
SELECT ENDPOINT_VALUE, ENDPOINT_NUMBER
FROM ALL_HISTOGRAMS
WHERE OWNER = 'SYSTEM'
AND TABLE_NAME = 'T_BBM60'
AND COLUMN_NAME = 'BBM_NO'
ORDER BY ENDPOINT_VALUE;
```

### 시스템 통계

시스템 통계는 애플리케이션 및 하드웨어 성능 특성을 측정한 것이며, 아래 항목을 포함한다.

\- CPU 속도
\- 평균적인 SINGE BLOCK I/O 속도
\- 평균적인 MULTOBLOCK I/O 속도
\- 평균적인 MULTOBLOCK I/O 개수
\- I/O 서브시스템의 최대 처리량
\- 병렬 SLAVE 의 평균적인 처리량

과거에는 옵티마이저가 이들 항목을 고려하지 않았다. 옵티마이저 개발팀이 사용한 하드웨어 사양에 맞춰진 고정 상수값으로 처리한 세미다. 그러다 보니 실제 오라클이 설치된 운영 시스템 사양이 옵티마이저가 최적이 아닌 실행계획을 수립할 가능성이 생긴다.
시스템 사양뿐만 아니라 애플리케이션의 특성(OLTP, DW) 및 동시 트랜잭션 발생량에 따라서도 이들 성능 특서ㅣ 달라진다. 이에 옵티마이저가 보다 합리적으로 자동할 수 있게 하려고 시스템 통계 수집 기능을 도입했다.

```sql
select sname, pname, pval1, pval2, from sys.aux_stats$;
```

---

# 비용계산원리

단일 테이블을 인덱스로 액세스할 때의 비용 계산 원리를 간단히 살펴보자.

비용 = 인데스 수직적 탐색 비용 + 인덱스 수평적 탐색 비용 + 테이블 랜덤 액세스 비용

인덱스 키값을 모두 = 조건으로 검색할 때는 아래와 같이 인덱스 통계만으로도 쉽게 비용을 계산할 수 있다.

비용 = BLEVEL + AVG*LEAF_BLOCK_PER_KEY * AVG_DATA_BLOCK_PER_KEY

인덱스 키값이 모두 = 조건이 아닐 때는 아래와 같이 컬럼 통계까지 활용한다.

비용 = BLEVEL + LEAFBLOCKS \* 유효 인덱스 선택도 + CLUSTERINGFACTOR \* 유효 테이블 선택도

BLEVEL, LEAF_BLOCKS, CLUSTERING_FACTOR는 인덱스 통계에서 얻을 수 있고, 유효 인덱스 선택도와 유효 테이블 선택도를 컬럼 통계 및 히스토그램을 이용해 계산한다.

유효인덱스선택도란, 전체 인덱스 레코드 중 엑세스 조건에 의해 선택될 것으로 예상도는 레코드 비중으 의미한다.

유효테이블선택도란, 전체 인덱스 레코드 중 인덱스 컬럼에 대한 모든 조건절에 의해 선택될 것으로 예상되는 레코드 비중을 의미한다.

이들 조건에 의해 테이블 액세스 여부가 결정된다.

## 비용의 정확한 의미

위의 비용 계산식은 I/O COST MODEL 기준이다. 여기서 cost 는 '예상 I/O CALL 횟수' 를 의미한다.

반면, 최신 CPU 비용 모델에서 COST는 SINGLE BLOCK I/O를 기준으로 한 상대적 시간을 표현한다.

예를 들어 cost가 100으로 표시되면 , 우리 시스템에서 SINGLE BLOCK I/O를 100번 하는 정도의 상대적 시간개념으로 정의한다.

CPU 비용 모델을 개발한 이유는, 같은 실행계획으로 같은 양의 데이터를 익어도 에플리케이션 및 하드웨어 특성에 따라 절대 소요시간이 다를 수 있기 때문이다.
